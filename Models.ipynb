{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9-qAi1-VaGF",
    "outputId": "b2c47ae1-25ed-4583-f9ee-b83540da91cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SimpleITK in c:\\python39\\lib\\site-packages (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python39\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5O_u_2VEVaxu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZDM9TeHSpdz"
   },
   "source": [
    "#DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvAOESUMZ3vC"
   },
   "source": [
    "###GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UEuSwGAuUIDE"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import  List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M_bEIIkaTMVc"
   },
   "outputs": [],
   "source": [
    "BUY_file_paths: List[str] =  sorted(glob(\"./BUY/*.nii.gz\"))  #68 files\n",
    "#EAT_file_paths: List[str] =  sorted(glob(\"/content/drive/MyDrive/Integradora/Data/EAT/*.nii.gz\"))  #files\n",
    "GAMBLE_file_paths: List[str] =  sorted(glob(\"./GAMBLE/*.nii.gz\"))  #7 files\n",
    "SEX_file_paths: List[str] =  sorted(glob(\"./SEX/*.nii.gz\"))  #42 files\n",
    "\n",
    "PD_file_paths: List[str] =  sorted(glob(\"./PD/*.nii.gz\"))  #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhjKHY1eUK8T",
    "outputId": "b3e7fe30-d891-486d-d291-af6046269e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 ['./BUY\\\\3536.nii.gz', './BUY\\\\3565.nii.gz', './BUY\\\\3863.nii.gz']\n",
      "7 ['./GAMBLE\\\\3536.nii.gz', './GAMBLE\\\\3565.nii.gz', './GAMBLE\\\\3863.nii.gz']\n",
      "42 ['./SEX\\\\3062.nii.gz', './SEX\\\\3068.nii.gz', './SEX\\\\3073.nii.gz']\n",
      "100 ['./PD\\\\S101968.nii.gz', './PD\\\\S101973.nii.gz', './PD\\\\S103294.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(len(BUY_file_paths), BUY_file_paths[:3])\n",
    "#print(len(EAT_file_paths), EAT_file_paths[:3])\n",
    "print(len(GAMBLE_file_paths), GAMBLE_file_paths[:3])\n",
    "print(len(SEX_file_paths), SEX_file_paths[:3])\n",
    "\n",
    "print(len(PD_file_paths), PD_file_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIEPs4fyi_Do"
   },
   "source": [
    "##SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smYhVSm3REZT",
    "outputId": "4e5fb0de-9dbb-4e64-f4ac-07e3dd37abe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset = []\n",
    "y_dataset = []\n",
    "\n",
    "X_dataset.extend(PD_file_paths), y_dataset.extend([1] * len(PD_file_paths))\n",
    "X_dataset.extend(BUY_file_paths), y_dataset.extend([2] * len(BUY_file_paths))\n",
    "#X_dataset.extend(EAT_file_paths), y_dataset.extend([3] * len(EAT_file_paths))\n",
    "X_dataset.extend(GAMBLE_file_paths), y_dataset.extend([4] * len(GAMBLE_file_paths))\n",
    "X_dataset.extend(SEX_file_paths), y_dataset.extend([5] * len(SEX_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Uqc7y2bki-jm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size = 0.2, stratify=y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulHtkPzaYDdz",
    "outputId": "68995ed6-84a9-4e22-c0d2-0326b3d42b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 217 217\n",
      "Train: 173 173\n",
      "Test: 44 44\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset:\", len(X_dataset), len(y_dataset))\n",
    "print(\"Train:\", len(X_train), len(y_train))\n",
    "print(\"Test:\", len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5gQU1FEGLxm"
   },
   "source": [
    "##PREPROSSESING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tmO7ktYZjyzg"
   },
   "outputs": [],
   "source": [
    "def get_category(category, is_binary = True):\n",
    "  result = np.zeros(2 if is_binary else 5)\n",
    "  if is_binary:\n",
    "    return 1 if category == 1 else 0\n",
    "  elif category == 1:\n",
    "    result[0] = 1\n",
    "  else:\n",
    "    result[category-1] = 1\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dodkXvulaU6J"
   },
   "outputs": [],
   "source": [
    "def get_categories(y_data):\n",
    "  categories = None\n",
    "  is_first = True\n",
    "  for category in y_data:\n",
    "    if is_first:\n",
    "      categories = np.array([get_category(category)])\n",
    "      is_first = False\n",
    "    else:\n",
    "      categories = np.concatenate((categories,[get_category(category)]))\n",
    "  return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVlfjfF3NfXM",
    "outputId": "393185e6-679c-4a30-8782-66dea49fdeec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0. 0. 1.]\n",
      "1 [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(get_category(5, True), get_category(5, False))\n",
    "print(get_category(1, True), get_category(1, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_slices_3d(path, category):\n",
    "    img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    #normalize the matrix, numbers between 0.0 - 1.0\n",
    "    arr = arr / arr.max()\n",
    "    \n",
    "    slices = np.array([arr])\n",
    "    slices = slices.reshape(1, -1, slices.shape[1], slices.shape[2], 1)\n",
    "    slices_cat = np.array([get_category(category)])\n",
    "    \n",
    "    return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_3d(paths, categories):\n",
    "    group = None\n",
    "    group_cat = None\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        if i == 0:\n",
    "            group, group_cat = get_slices_3d(path, categories[i])\n",
    "        else:\n",
    "            new_group, new_group_cat = get_slices_3d(path, categories[i])\n",
    "            group = np.concatenate((group, new_group))\n",
    "            group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "        print(\"-> [%d/%d] Image processed.\" %(count,len(paths)))\n",
    "        count+=1\n",
    "    return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 181, 181, 217, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_3d(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/3] Image processed.\n",
      "-> [2/3] Image processed.\n",
      "-> [3/3] Image processed.\n",
      "(3, 181, 181, 217, 1)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "slices, slices_cat = get_slices_per_group_3d(X_dataset[:3], y_dataset[:3])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwSGlhsb0Iaw"
   },
   "source": [
    "## AXIAL\n",
    "arr[ xxx , : , : ] axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9cwlnfteXPLb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_slices_axial(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[i, : , : ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lQz7bYsHENEt"
   },
   "outputs": [],
   "source": [
    "def get_slices_per_group_axial(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_axial(path, categories[i])\n",
    "    else:\n",
    "      new_group, new_group_cat = get_slices_axial(path, categories[i])\n",
    "      group = np.concatenate((group, new_group))\n",
    "      group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhXSxy0Y1eEp",
    "outputId": "e71253d0-380d-44c8-80d8-d9ed159c0840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 224, 224)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_axial(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_DZGnMbC13P"
   },
   "source": [
    "## CORONAL\n",
    "arr[ : , xxx , : ] coronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "JCnw2xZj_PT7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# type: the number of the group\n",
    "# group_n: the count of diferent groups\n",
    "# for example,we can have the groups \n",
    "#    1) [EAT, GAMBLE, SEX, BUY, PURE] and the image is from GAMBLE\n",
    "#     -> type = 2\n",
    "#     -> group_n = 5\n",
    "#    2) or [PURE, ICD] and the image is from PURE\n",
    "#     -> type = 1\n",
    "#     -> group_n = 2\n",
    "#output:\n",
    "#     -> normalized array of the slices \n",
    "#     -> the category of each image in one-hot encoded.\n",
    "# for example\n",
    "#   1) [0,1,0,0,0], and \n",
    "#   2) [1,0]\n",
    "def get_slices_coronal(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[:, i , : ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "9-LKeV1d_PT-"
   },
   "outputs": [],
   "source": [
    "def get_slices_per_group_coronal(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_coronal(path, categories[i])\n",
    "    else:\n",
    "      new_group, new_group_cat = get_slices_coronal(path, categories[i])\n",
    "      group = np.concatenate((group, new_group))\n",
    "      group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eE7lOFb_PT_",
    "outputId": "6209c074-fd58-4e2e-d6e5-64602a10d748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 224, 224)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_coronal(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3ERsrLfC87J"
   },
   "source": [
    "## SAGITAL\n",
    "arr[ : , : , xxx ] sagital "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# type: the number of the group\n",
    "# group_n: the count of diferent groups\n",
    "# for example,we can have the groups \n",
    "#    1) [EAT, GAMBLE, SEX, BUY, PURE] and the image is from GAMBLE\n",
    "#     -> type = 2\n",
    "#     -> group_n = 5\n",
    "#    2) or [PURE, ICD] and the image is from PURE\n",
    "#     -> type = 1\n",
    "#     -> group_n = 2\n",
    "#output:\n",
    "#     -> normalized array of the slices \n",
    "#     -> the category of each image in one-hot encoded.\n",
    "# for example\n",
    "#   1) [0,1,0,0,0], and \n",
    "#   2) [1,0]\n",
    "def get_slices_sagital(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[:, : , i ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_sagital(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_sagital(path, categories[i])\n",
    "    else:\n",
    "      new_group, new_group_cat = get_slices_sagital(path, categories[i])\n",
    "      group = np.concatenate((group, new_group))\n",
    "      group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 224, 224)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_sagital(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNzzq4hUs2ww"
   },
   "source": [
    "# MODEL (BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/20] Image processed.\n",
      "-> [2/20] Image processed.\n",
      "-> [3/20] Image processed.\n",
      "-> [4/20] Image processed.\n",
      "-> [5/20] Image processed.\n",
      "-> [6/20] Image processed.\n",
      "-> [7/20] Image processed.\n",
      "-> [8/20] Image processed.\n",
      "-> [9/20] Image processed.\n",
      "-> [10/20] Image processed.\n",
      "-> [11/20] Image processed.\n",
      "-> [12/20] Image processed.\n",
      "-> [13/20] Image processed.\n",
      "-> [14/20] Image processed.\n",
      "-> [15/20] Image processed.\n",
      "-> [16/20] Image processed.\n",
      "-> [17/20] Image processed.\n",
      "-> [18/20] Image processed.\n",
      "-> [19/20] Image processed.\n",
      "-> [20/20] Image processed.\n",
      "-> [1/5] Image processed.\n",
      "-> [2/5] Image processed.\n",
      "-> [3/5] Image processed.\n",
      "-> [4/5] Image processed.\n",
      "-> [5/5] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_train, y_3d_train = get_slices_per_group_3d(X_train[:20], y_train[:20])\n",
    "X_3d_test, y_3d_test = get_slices_per_group_3d(X_test[:5], y_test[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (20, 181, 181, 217, 1) 20\n",
      "Test: (5, 181, 181, 217, 1) 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\",X_3d_train.shape, len(y_3d_train))\n",
    "print(\"Test:\",X_3d_test.shape, len(y_3d_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import imageio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_16 (Conv3D)           (None, 181, 181, 217, 20) 560       \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 181, 181, 217, 64) 34624     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 181, 181, 217, 64) 0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 90, 90, 108, 64)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 90, 90, 108, 128)  221312    \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 90, 90, 108, 128)  442496    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 90, 90, 108, 128)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 45, 45, 54, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 45, 45, 54, 256)   884992    \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 45, 45, 54, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 45, 45, 54, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 45, 45, 54, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 45, 45, 54, 256)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 22, 22, 27, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 22, 22, 27, 512)   3539456   \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 22, 22, 27, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 22, 22, 27, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 22, 22, 27, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 22, 22, 27, 512)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 11, 11, 13, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_28 (Conv3D)           (None, 11, 11, 13, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_29 (Conv3D)           (None, 11, 11, 13, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 11, 11, 13, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 11, 11, 13, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 11, 11, 13, 512)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 5, 5, 6, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 76800)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              314576896 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 395,437,633\n",
      "Trainable params: 395,437,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(input_shape=(181,181,217,1),filters=20,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_3d.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "in user code:\n\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:628 apply_gradients\n        self._create_all_weights(var_list)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:815 _create_all_weights\n        self._create_slots(var_list)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:119 _create_slots\n        self.add_slot(var, 'v')\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:901 add_slot\n        weight = tf.Variable(\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:250 _variable_v2_call\n        return previous_getter(\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:746 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:294 __init__\n        initial_value = initial_value()\n    c:\\python39\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:145 __call__\n        return tf.zeros(shape, dtype)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2915 wrapped\n        tensor = fun(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2976 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:240 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3367 fill\n        _ops.raise_from_not_ok_status(e, name)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[76800,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Fill]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12668/1241791065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_3d_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_3d_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: in user code:\n\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:791 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:522 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:628 apply_gradients\n        self._create_all_weights(var_list)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:815 _create_all_weights\n        self._create_slots(var_list)\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:119 _create_slots\n        self.add_slot(var, 'v')\n    c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:901 add_slot\n        weight = tf.Variable(\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:268 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:250 _variable_v2_call\n        return previous_getter(\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3547 creator\n        return next_creator(**kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:746 variable_capturing_scope\n        v = UnliftedInitializerVariable(\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:270 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:294 __init__\n        initial_value = initial_value()\n    c:\\python39\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:145 __call__\n        return tf.zeros(shape, dtype)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2915 wrapped\n        tensor = fun(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:2976 zeros\n        output = fill(shape, constant(zero, dtype=dtype), name=name)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:240 fill\n        result = gen_array_ops.fill(dims, value, name=name)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:3367 fill\n        _ops.raise_from_not_ok_status(e, name)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6941 raise_from_not_ok_status\n        six.raise_from(core._status_to_exception(e.code, message), None)\n    <string>:3 raise_from\n        \n\n    ResourceExhaustedError: OOM when allocating tensor with shape[76800,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Fill]\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_3d_train, y_3d_train, batch_size=10,epochs=30,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(X_3d_test, y_3d_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTMlHtqbcTsm"
   },
   "source": [
    "## AXIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6KuVpJFev4t",
    "outputId": "c6f3ceb6-6a1b-437d-c93e-14c47265bf01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/173] Slices processed 30.\n",
      "-> [2/173] Slices processed 58.\n",
      "-> [3/173] Slices processed 88.\n",
      "-> [4/173] Slices processed 118.\n",
      "-> [5/173] Slices processed 146.\n",
      "-> [6/173] Slices processed 173.\n",
      "-> [7/173] Slices processed 200.\n",
      "-> [8/173] Slices processed 224.\n",
      "-> [9/173] Slices processed 251.\n",
      "-> [10/173] Slices processed 278.\n",
      "-> [11/173] Slices processed 308.\n",
      "-> [12/173] Slices processed 335.\n",
      "-> [13/173] Slices processed 362.\n",
      "-> [14/173] Slices processed 387.\n",
      "-> [15/173] Slices processed 417.\n",
      "-> [16/173] Slices processed 446.\n",
      "-> [17/173] Slices processed 475.\n",
      "-> [18/173] Slices processed 502.\n",
      "-> [19/173] Slices processed 532.\n",
      "-> [20/173] Slices processed 551.\n",
      "-> [21/173] Slices processed 579.\n",
      "-> [22/173] Slices processed 604.\n",
      "-> [23/173] Slices processed 605.\n",
      "-> [24/173] Slices processed 632.\n",
      "-> [25/173] Slices processed 657.\n",
      "-> [26/173] Slices processed 686.\n",
      "-> [27/173] Slices processed 716.\n",
      "-> [28/173] Slices processed 746.\n",
      "-> [29/173] Slices processed 770.\n",
      "-> [30/173] Slices processed 799.\n",
      "-> [31/173] Slices processed 827.\n",
      "-> [32/173] Slices processed 857.\n",
      "-> [33/173] Slices processed 887.\n",
      "-> [34/173] Slices processed 911.\n",
      "-> [35/173] Slices processed 938.\n",
      "-> [36/173] Slices processed 968.\n",
      "-> [37/173] Slices processed 993.\n",
      "-> [38/173] Slices processed 1021.\n",
      "-> [39/173] Slices processed 1051.\n",
      "-> [40/173] Slices processed 1079.\n",
      "-> [41/173] Slices processed 1108.\n",
      "-> [42/173] Slices processed 1138.\n",
      "-> [43/173] Slices processed 1167.\n",
      "-> [44/173] Slices processed 1196.\n",
      "-> [45/173] Slices processed 1224.\n",
      "-> [46/173] Slices processed 1254.\n",
      "-> [47/173] Slices processed 1282.\n",
      "-> [48/173] Slices processed 1309.\n",
      "-> [49/173] Slices processed 1339.\n",
      "-> [50/173] Slices processed 1369.\n",
      "-> [51/173] Slices processed 1399.\n",
      "-> [52/173] Slices processed 1427.\n",
      "-> [53/173] Slices processed 1452.\n",
      "-> [54/173] Slices processed 1478.\n",
      "-> [55/173] Slices processed 1506.\n",
      "-> [56/173] Slices processed 1535.\n",
      "-> [57/173] Slices processed 1560.\n",
      "-> [58/173] Slices processed 1590.\n",
      "-> [59/173] Slices processed 1612.\n",
      "-> [60/173] Slices processed 1642.\n",
      "-> [61/173] Slices processed 1672.\n",
      "-> [62/173] Slices processed 1702.\n",
      "-> [63/173] Slices processed 1729.\n",
      "-> [64/173] Slices processed 1757.\n",
      "-> [65/173] Slices processed 1784.\n",
      "-> [66/173] Slices processed 1813.\n",
      "-> [67/173] Slices processed 1842.\n",
      "-> [68/173] Slices processed 1865.\n",
      "-> [69/173] Slices processed 1893.\n",
      "-> [70/173] Slices processed 1923.\n",
      "-> [71/173] Slices processed 1952.\n",
      "-> [72/173] Slices processed 1980.\n",
      "-> [73/173] Slices processed 2010.\n",
      "-> [74/173] Slices processed 2040.\n",
      "-> [75/173] Slices processed 2067.\n",
      "-> [76/173] Slices processed 2097.\n",
      "-> [77/173] Slices processed 2124.\n",
      "-> [78/173] Slices processed 2151.\n",
      "-> [79/173] Slices processed 2179.\n",
      "-> [80/173] Slices processed 2209.\n",
      "-> [81/173] Slices processed 2239.\n",
      "-> [82/173] Slices processed 2266.\n",
      "-> [83/173] Slices processed 2293.\n",
      "-> [84/173] Slices processed 2323.\n",
      "-> [85/173] Slices processed 2352.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_3568/1751870067.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [86/173] Slices processed 2533.\n",
      "-> [87/173] Slices processed 2560.\n",
      "-> [88/173] Slices processed 2584.\n",
      "-> [89/173] Slices processed 2612.\n",
      "-> [90/173] Slices processed 2642.\n",
      "-> [91/173] Slices processed 2669.\n",
      "-> [92/173] Slices processed 2699.\n",
      "-> [93/173] Slices processed 2729.\n",
      "-> [94/173] Slices processed 2759.\n",
      "-> [95/173] Slices processed 2789.\n",
      "-> [96/173] Slices processed 2817.\n",
      "-> [97/173] Slices processed 2847.\n",
      "-> [98/173] Slices processed 2865.\n",
      "-> [99/173] Slices processed 2890.\n",
      "-> [100/173] Slices processed 2916.\n",
      "-> [101/173] Slices processed 2945.\n",
      "-> [102/173] Slices processed 2972.\n",
      "-> [103/173] Slices processed 3001.\n",
      "-> [104/173] Slices processed 3029.\n",
      "-> [105/173] Slices processed 3059.\n",
      "-> [106/173] Slices processed 3085.\n",
      "-> [107/173] Slices processed 3111.\n",
      "-> [108/173] Slices processed 3141.\n",
      "-> [109/173] Slices processed 3171.\n",
      "-> [110/173] Slices processed 3198.\n",
      "-> [111/173] Slices processed 3225.\n",
      "-> [112/173] Slices processed 3255.\n",
      "-> [113/173] Slices processed 3285.\n",
      "-> [114/173] Slices processed 3315.\n",
      "-> [115/173] Slices processed 3345.\n",
      "-> [116/173] Slices processed 3374.\n",
      "-> [117/173] Slices processed 3402.\n",
      "-> [118/173] Slices processed 3432.\n",
      "-> [119/173] Slices processed 3461.\n",
      "-> [120/173] Slices processed 3491.\n",
      "-> [121/173] Slices processed 3521.\n",
      "-> [122/173] Slices processed 3551.\n",
      "-> [123/173] Slices processed 3581.\n",
      "-> [124/173] Slices processed 3611.\n",
      "-> [125/173] Slices processed 3637.\n",
      "-> [126/173] Slices processed 3667.\n",
      "-> [127/173] Slices processed 3697.\n",
      "-> [128/173] Slices processed 3727.\n",
      "-> [129/173] Slices processed 3757.\n",
      "-> [130/173] Slices processed 3783.\n",
      "-> [131/173] Slices processed 3813.\n",
      "-> [132/173] Slices processed 3843.\n",
      "-> [133/173] Slices processed 3870.\n",
      "-> [134/173] Slices processed 3900.\n",
      "-> [135/173] Slices processed 3930.\n",
      "-> [136/173] Slices processed 3960.\n",
      "-> [137/173] Slices processed 3989.\n",
      "-> [138/173] Slices processed 4018.\n",
      "-> [139/173] Slices processed 4046.\n",
      "-> [140/173] Slices processed 4075.\n",
      "-> [141/173] Slices processed 4105.\n",
      "-> [142/173] Slices processed 4130.\n",
      "-> [143/173] Slices processed 4160.\n",
      "-> [144/173] Slices processed 4189.\n",
      "-> [145/173] Slices processed 4212.\n",
      "-> [146/173] Slices processed 4242.\n",
      "-> [147/173] Slices processed 4272.\n",
      "-> [148/173] Slices processed 4302.\n",
      "-> [149/173] Slices processed 4329.\n",
      "-> [150/173] Slices processed 4358.\n",
      "-> [151/173] Slices processed 4386.\n",
      "-> [152/173] Slices processed 4411.\n",
      "-> [153/173] Slices processed 4441.\n",
      "-> [154/173] Slices processed 4470.\n",
      "-> [155/173] Slices processed 4496.\n",
      "-> [156/173] Slices processed 4526.\n",
      "-> [157/173] Slices processed 4555.\n",
      "-> [158/173] Slices processed 4580.\n",
      "-> [159/173] Slices processed 4610.\n",
      "-> [160/173] Slices processed 4637.\n",
      "-> [161/173] Slices processed 4663.\n",
      "-> [162/173] Slices processed 4687.\n",
      "-> [163/173] Slices processed 4715.\n",
      "-> [164/173] Slices processed 4745.\n",
      "-> [165/173] Slices processed 4775.\n",
      "-> [166/173] Slices processed 4805.\n",
      "-> [167/173] Slices processed 4835.\n",
      "-> [168/173] Slices processed 4865.\n",
      "-> [169/173] Slices processed 4895.\n",
      "-> [170/173] Slices processed 4919.\n",
      "-> [171/173] Slices processed 4944.\n",
      "-> [172/173] Slices processed 4974.\n",
      "-> [173/173] Slices processed 5004.\n",
      "-> [1/44] Slices processed 28.\n",
      "-> [2/44] Slices processed 56.\n",
      "-> [3/44] Slices processed 84.\n",
      "-> [4/44] Slices processed 114.\n",
      "-> [5/44] Slices processed 138.\n",
      "-> [6/44] Slices processed 168.\n",
      "-> [7/44] Slices processed 198.\n",
      "-> [8/44] Slices processed 228.\n",
      "-> [9/44] Slices processed 257.\n",
      "-> [10/44] Slices processed 282.\n",
      "-> [11/44] Slices processed 308.\n",
      "-> [12/44] Slices processed 338.\n",
      "-> [13/44] Slices processed 365.\n",
      "-> [14/44] Slices processed 394.\n",
      "-> [15/44] Slices processed 422.\n",
      "-> [16/44] Slices processed 452.\n",
      "-> [17/44] Slices processed 482.\n",
      "-> [18/44] Slices processed 511.\n",
      "-> [19/44] Slices processed 539.\n",
      "-> [20/44] Slices processed 568.\n",
      "-> [21/44] Slices processed 595.\n",
      "-> [22/44] Slices processed 622.\n",
      "-> [23/44] Slices processed 650.\n",
      "-> [24/44] Slices processed 680.\n",
      "-> [25/44] Slices processed 710.\n",
      "-> [26/44] Slices processed 737.\n",
      "-> [27/44] Slices processed 766.\n",
      "-> [28/44] Slices processed 791.\n",
      "-> [29/44] Slices processed 815.\n",
      "-> [30/44] Slices processed 843.\n",
      "-> [31/44] Slices processed 873.\n",
      "-> [32/44] Slices processed 903.\n",
      "-> [33/44] Slices processed 930.\n",
      "-> [34/44] Slices processed 959.\n",
      "-> [35/44] Slices processed 987.\n",
      "-> [36/44] Slices processed 1015.\n",
      "-> [37/44] Slices processed 1042.\n",
      "-> [38/44] Slices processed 1072.\n",
      "-> [39/44] Slices processed 1102.\n",
      "-> [40/44] Slices processed 1132.\n",
      "-> [41/44] Slices processed 1162.\n",
      "-> [42/44] Slices processed 1189.\n",
      "-> [43/44] Slices processed 1216.\n",
      "-> [44/44] Slices processed 1242.\n"
     ]
    }
   ],
   "source": [
    "X_axial_train, y_axial_train = get_slices_per_group_axial(X_train, y_train)\n",
    "X_axial_train = X_axial_train.reshape(-1, X_axial_train.shape[1], X_axial_train.shape[2], 1)\n",
    "\n",
    "X_axial_test, y_axial_test = get_slices_per_group_axial(X_test, y_test)\n",
    "X_axial_test = X_axial_test.reshape(-1, X_axial_train.shape[1], X_axial_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-36EzPmfjyA",
    "outputId": "e17efeb8-62c4-49ef-8446-1ec8863ff0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X:(5004, 224, 224, 1), y: 5004\n",
      "Test: X:(1242, 224, 224, 1), y: 1242\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_axial_train.shape[0],X_axial_train.shape[1],X_axial_train.shape[2],X_axial_train.shape[3], len(y_axial_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_axial_test.shape[0],X_axial_test.shape[1],X_axial_test.shape[2],X_axial_test.shape[3], len(y_axial_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7bK3grjmDsh"
   },
   "source": [
    "###VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GmsZwEJRpg-t"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import imageio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y7XVr5bl5MU",
    "outputId": "18ce578d-5d08-4ce3-f8cc-aad0bd5b537b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 143,667,089\n",
      "Trainable params: 143,667,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-ixtI5Tpsv0",
    "outputId": "07ba67f2-d3ea-4cd9-8074-212236f6b3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "401/401 [==============================] - 3665s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.51648, saving model to vgg19_1.h5\n",
      "Epoch 2/30\n",
      "401/401 [==============================] - 3659s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.51648\n",
      "Epoch 3/30\n",
      "401/401 [==============================] - 3693s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.51648\n",
      "Epoch 4/30\n",
      "401/401 [==============================] - 3717s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.51648\n",
      "Epoch 5/30\n",
      "401/401 [==============================] - 3753s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.51648\n",
      "Epoch 6/30\n",
      "401/401 [==============================] - 3798s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.51648\n",
      "Epoch 7/30\n",
      "401/401 [==============================] - 3894s 10s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.51648\n",
      "Epoch 8/30\n",
      "401/401 [==============================] - 3902s 10s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.51648\n",
      "Epoch 9/30\n",
      "401/401 [==============================] - 3894s 10s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.51648\n",
      "Epoch 10/30\n",
      "401/401 [==============================] - 3792s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.51648\n",
      "Epoch 11/30\n",
      "401/401 [==============================] - 3459s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.51648\n",
      "Epoch 12/30\n",
      "401/401 [==============================] - 3513s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.51648\n",
      "Epoch 13/30\n",
      "401/401 [==============================] - 3429s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.51648\n",
      "Epoch 14/30\n",
      "401/401 [==============================] - 3437s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.51648\n",
      "Epoch 15/30\n",
      "401/401 [==============================] - 3405s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.51648\n",
      "Epoch 16/30\n",
      "401/401 [==============================] - 3406s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.51648\n",
      "Epoch 17/30\n",
      "401/401 [==============================] - 3382s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.51648\n",
      "Epoch 18/30\n",
      "401/401 [==============================] - 3371s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.51648\n",
      "Epoch 19/30\n",
      "401/401 [==============================] - 3391s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.51648\n",
      "Epoch 20/30\n",
      "401/401 [==============================] - 3376s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.51648\n",
      "Epoch 21/30\n",
      "401/401 [==============================] - 3375s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.51648\n",
      "Epoch 22/30\n",
      "401/401 [==============================] - 3364s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.51648\n",
      "Epoch 23/30\n",
      "401/401 [==============================] - 3373s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.51648\n",
      "Epoch 24/30\n",
      "401/401 [==============================] - 3373s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.51648\n",
      "Epoch 25/30\n",
      "401/401 [==============================] - 3529s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.51648\n",
      "Epoch 26/30\n",
      "401/401 [==============================] - 4062s 10s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.51648\n",
      "Epoch 27/30\n",
      "401/401 [==============================] - 3526s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.51648\n",
      "Epoch 28/30\n",
      "401/401 [==============================] - 3409s 9s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.51648\n",
      "Epoch 29/30\n",
      "401/401 [==============================] - 3323s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.51648\n",
      "Epoch 30/30\n",
      "401/401 [==============================] - 3403s 8s/step - loss: nan - accuracy: 0.5528 - val_loss: nan - val_accuracy: 0.5165\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.51648\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_axial_train, y_axial_train, batch_size=10,epochs=30,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "seDApqQk5FtY",
    "outputId": "fc45785c-eb2f-465f-eef0-94b3ffe8452c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAuJ0lEQVR4nO3deZwV1Z338c9XFhEBBSGECAYyERdomqUBE1lETWIisogLRMWOEbdHGbP4SJZRh8QZk+Cjo0lMFNcEAcNEhLgwgiJm3GgILqBE1HYA0bCMCEGWpn/PH7e6c2l7uZRcmobv+/W6L26dqnPqnL7N/fU5p+qUIgIzM7PddVB9V8DMzBomBxAzM0vFAcTMzFJxADEzs1QcQMzMLBUHEDMzS8UBxKwWku6T9NMcjy2VdGq+62S2r3AAMTOzVBxAzA4AkhrXdx1s/+MAYg1eMnR0jaRXJP1d0t2S2kt6XNImSXMltc46fpikpZI+lDRf0nFZ+3pJWpzkmw40q3KuoZKWJHmfk9QjxzqeLukvkj6StFLSDVX2D0jK+zDZX5ykHyLpZknvStoo6c9J2kmSVlXzczg1eX+DpBmSfi/pI6BYUj9JzyfnWCPpl5KaZuXvJulJSRskfSDph5I+K2mLpCOyjustaa2kJrm03fZfDiC2vxgFfAXoCpwBPA78EGhH5vd8PICkrsBU4Opk32PAbElNky/TmcDvgDbAH5JySfL2Au4BLgWOAH4LzJJ0cA71+zswFjgcOB24XNKIpNzPJ/W9PalTT2BJkm8S0Af4clKn/wuU5/gzGQ7MSM45BdgJfAdoC3wJOAW4IqlDS2Au8ATwOeCLwLyIeB+YD5yTVe4FwLSI2JFjPWw/5QBi+4vbI+KDiFgNPAu8GBF/iYitwMNAr+S4c4FHI+LJ5AtwEnAImS/oE4AmwK0RsSMiZgALs85xCfDbiHgxInZGxP3AtiRfrSJifkS8GhHlEfEKmSA2ONn9TWBuRExNzrs+IpZIOgi4CPjniFidnPO5iNiW48/k+YiYmZzz44hYFBEvRERZRJSSCYAVdRgKvB8RN0fE1ojYFBEvJvvuB84HkNQIGEMmyNoBzgHE9hcfZL3/uJrtFsn7zwHvVuyIiHJgJXBksm917LrC6LtZ7z8PfC8ZAvpQ0odApyRfrST1l/R0MvSzEbiMTE+ApIy3qsnWlswQWnX7crGySh26SvqTpPeTYa1/y6EOAI8Ax0vqQqaXtzEiXkpZJ9uPOIDYgeY9MoEAAEki8+W5GlgDHJmkVTgq6/1K4MaIODzr1TwipuZw3geBWUCniDgM+A1QcZ6VwD9Vk2cdsLWGfX8Hmme1oxGZ4a9sVZfavgN4Azg6IlqRGeLLrsMXqqt40ot7iEwv5ALc+7CEA4gdaB4CTpd0SjIJ/D0yw1DPAc8DZcB4SU0knQn0y8p7F3BZ0puQpEOTyfGWOZy3JbAhIrZK6kdm2KrCFOBUSedIaizpCEk9k97RPcD/k/Q5SY0kfSmZc/kr0Cw5fxPgx0BdczEtgY+AzZKOBS7P2vcnoIOkqyUdLKmlpP5Z+x8AioFhOIBYwgHEDigRsZzMX9K3k/kL/wzgjIjYHhHbgTPJfFFuIDNf8sesvCXAOOCXwP8CK5Jjc3EFMFHSJuA6MoGsotz/Ab5BJphtIDOBXpjs/j7wKpm5mA3Az4CDImJjUuZkMr2nvwO7XJVVje+TCVybyATD6Vl12ERmeOoM4H3gTWBI1v7/JjN5vzgisof17AAmP1DKzHIh6SngwYiYXN91sX2DA4iZ1UlSX+BJMnM4m+q7PrZv8BCWmdVK0v1k7hG52sHDsrkHYmZmqbgHYmZmqRwQC6y1bds2OnfuXN/VMDNrUBYtWrQuIqreX1TpgAggnTt3pqSkpL6rYWbWoEiq9ZJtD2GZmVkqDiBmZpaKA4iZmaXiAGJmZqk4gJiZWSoOIGZmlooDiJmZpXJA3AeS1r/OXsqy9z6q72qYmaVy/Odacf0Z3fJWvnsgZmaWinsgtchn5DYza+jcAzEzs1QcQMzMLBUHEDMzS8UBxMzMUnEAMTOzVBxAzMwsFQcQMzNLxQHEzMxScQAxM7NUHEDMzCwVBxAzM0slrwFE0mmSlktaIWlCNfuLJa2VtCR5XZy1b2dW+qys9C6SXkzKnC6paT7bYGZm1ctbAJHUCPgV8HXgeGCMpOOrOXR6RPRMXpOz0j/OSh+Wlf4z4JaI+CLwv8C389UGMzOrWT57IP2AFRHxdkRsB6YBwz9NgZIEnAzMSJLuB0Z8mjLNzCydfAaQI4GVWdurkrSqRkl6RdIMSZ2y0ptJKpH0gqQRSdoRwIcRUVZHmUi6JMlfsnbt2k/XEjMz+4T6nkSfDXSOiB7Ak2R6FBU+HxFFwDeBWyX90+4UHBF3RkRRRBS1a9duz9XYzMyA/AaQ1UB2j6JjklYpItZHxLZkczLQJ2vf6uTft4H5QC9gPXC4pIoHYX2iTDMz2zvyGUAWAkcnV001BUYDs7IPkNQha3MY8HqS3lrSwcn7tsCJwLKICOBp4Kwkz4XAI3lsg5mZ1SBvj7SNiDJJVwJzgEbAPRGxVNJEoCQiZgHjJQ0DyoANQHGS/Tjgt5LKyQS5myJiWbLvWmCapJ8CfwHuzlcbzMysZsr8Ub9/KyoqipKSkvquhplZgyJpUTIXXa36nkQ3M7MGygHEzMxScQAxM7NUHEDMzCwVBxAzM0vFAcTMzFJxADEzs1QcQMzMLBUHEDMzS8UBxMzMUnEAMTOzVBxAzMwsFQcQMzNLxQHEzMxScQAxM7NUHEDMzCwVBxAzM0vFAcTMzFLJawCRdJqk5ZJWSJpQzf5iSWslLUleF1fZ30rSKkm/zEqbn5RZkecz+WyDmZlVr3G+CpbUCPgV8BVgFbBQ0qyIWFbl0OkRcWUNxfwEWFBN+nkR4Yecm5nVo3z2QPoBKyLi7YjYDkwDhueaWVIfoD3wX3mqn5mZfQr5DCBHAiuztlclaVWNkvSKpBmSOgFIOgi4Gfh+DWXfmwxf/YskVXeApEsklUgqWbt27adohpmZVae+J9FnA50jogfwJHB/kn4F8FhErKomz3kRUQAMTF4XVFdwRNwZEUURUdSuXbs8VN3M7MCWzwCyGuiUtd0xSasUEesjYluyORnok7z/EnClpFJgEjBW0k1JntXJv5uAB8kMlZmZ2V6Wt0l0YCFwtKQuZALHaOCb2QdI6hARa5LNYcDrABFxXtYxxUBRREyQ1Bg4PCLWSWoCDAXm5rENZmZWg7wFkIgok3QlMAdoBNwTEUslTQRKImIWMF7SMKAM2AAU11HswcCcJHg0IhM87spXG8zMrGaKiPquQ94VFRVFSYmv+jUz2x2SFkVEUU3763sS3czMGigHEDMzS8UBxMzMUnEAMTOzVBxAzMwsFQcQMzNLxQHEzMxScQAxM7NUHEDMzCwVBxAzM0vFAcTMzFJxADEzs1QcQMzMLBUHEDMzS8UBxMzMUnEAMTOzVBxAzMwsFQcQMzNLJa8BRNJpkpZLWiFpQjX7iyWtlbQkeV1cZX8rSask/TIrrY+kV5Myb5OkfLbBzMyq1zhfBUtqBPwK+AqwClgoaVZELKty6PSIuLKGYn4CLKiSdgcwDngReAw4DXh8j1XcbD+2Y8cOVq1axdatW+u7KrYPadasGR07dqRJkya7lS9vAQToB6yIiLcBJE0DhgNVA0i1JPUB2gNPAEVJWgegVUS8kGw/AIzAAcQsJ6tWraJly5Z07twZd94NICJYv349q1atokuXLruVN59DWEcCK7O2VyVpVY2S9IqkGZI6AUg6CLgZ+H41Za7KoUwkXSKpRFLJ2rVr07bBbL+ydetWjjjiCAcPqySJI444IlWvtL4n0WcDnSOiB/AkcH+SfgXwWESsqjFnHSLizogoioiidu3a7YGqmu0fHDysqrS/E/kMIKuBTlnbHZO0ShGxPiK2JZuTgT7J+y8BV0oqBSYBYyXdlOTvWFuZZrbvmzlzJpJ444036rsq9inkM4AsBI6W1EVSU2A0MCv7gGROo8Iw4HWAiDgvIo6KiM5khrEeiIgJEbEG+EjSCcnVV2OBR/LYBjPLg6lTpzJgwACmTp2at3Ps3Lkzb2VbRt4CSESUAVcCc8gEhociYqmkiZKGJYeNl7RU0svAeKA4h6KvINNbWQG8hSfQzRqUzZs38+c//5m7776badOmAZkv++9///t0796dHj16cPvttwOwcOFCvvzlL1NYWEi/fv3YtGkT9913H1de+Y8LN4cOHcr8+fMBaNGiBd/73vcoLCzk+eefZ+LEifTt25fu3btzySWXEBEArFixglNPPZXCwkJ69+7NW2+9xdixY5k5c2Zlueeddx6PPOK/T2uTz6uwiIjHyFxqm512Xdb7HwA/qKOM+4D7srZLgO57sp5mB6J/nb2UZe99tEfLPP5zrbj+jG61HvPII49w2mmn0bVrV4444ggWLVrESy+9RGlpKUuWLKFx48Zs2LCB7du3c+655zJ9+nT69u3LRx99xCGHHFJr2X//+9/p378/N998c6Y+xx/PdddlvnIuuOAC/vSnP3HGGWdw3nnnMWHCBEaOHMnWrVspLy/n29/+NrfccgsjRoxg48aNPPfcc9x///21ne6AV9+T6GZ2gJk6dSqjR48GYPTo0UydOpW5c+dy6aWX0rhx5m/aNm3asHz5cjp06EDfvn0BaNWqVeX+mjRq1IhRo0ZVbj/99NP079+fgoICnnrqKZYuXcqmTZtYvXo1I0eOBDL3QDRv3pzBgwfz5ptvsnbtWqZOncqoUaPqPN+Bzj8dswNUXT2FfNiwYQNPPfUUr776KpLYuXMnkiqDRC4aN25MeXl55Xb25afNmjWjUaNGlelXXHEFJSUldOrUiRtuuKHOS1XHjh3L73//e6ZNm8a99967m6078LgHYmZ7zYwZM7jgggt49913KS0tZeXKlXTp0oXCwkJ++9vfUlZWBmQCzTHHHMOaNWtYuHAhAJs2baKsrIzOnTuzZMkSysvLWblyJS+99FK156oIFm3btmXz5s3MmDEDgJYtW9KxY8fK+Y5t27axZcsWAIqLi7n11luBzPCX1a7OACLpjOTGPjOzT2Xq1KmVQ0cVRo0axZo1azjqqKPo0aMHhYWFPPjggzRt2pTp06dz1VVXUVhYyFe+8hW2bt3KiSeeSJcuXTj++OMZP348vXv3rvZchx9+OOPGjaN79+587Wtf26WX87vf/Y7bbruNHj168OUvf5n3338fgPbt23PcccfxrW99K38/hP2IKq5KqPEA6fdk7sv4T+CeiGhwF24XFRVFSUlJfVfDrN69/vrrHHfccfVdjX3Wli1bKCgoYPHixRx22GH1XZ29qrrfDUmLIqKopjx19iwi4nygF5lLZu+T9HyyTEjLT1thM7N9xdy5cznuuOO46qqrDrjgkVZOk+gR8ZGkGcAhwNXASOAaSbdFxO15rJ+Z2V5x6qmn8u6779Z3NRqUXOZAhkl6GJgPNAH6RcTXgULge/mtnpmZ7aty6YGMAm6JiF2eyxERWyR9Oz/VMjOzfV0uAeQGYE3FhqRDgPYRURoR8/JVMTMz27flcnnuH4DyrO2dSZqZmR3AcgkgjSNie8VG8r5p/qpkZvurIUOGMGfOnF3Sbr31Vi6//PIa85x00klUXIb/jW98gw8//PATx9xwww1MmjSp1nPPnDmTZcv+8UDU6667jrlz5+5G7Wt39dVXc+SRR+5yl/z+LpcAsjZr9VwkDQfW5a9KZra/GjNmTOUKvBWmTZvGmDFjcsr/2GOPcfjhh6c6d9UAMnHiRE499dRUZVVVXl7Oww8/TKdOnXjmmWf2SJnVqbhTf1+RSwC5DPihpP+RtBK4Frg0v9Uys/3RWWedxaOPPsr27ZlBjdLSUt577z0GDhzI5ZdfTlFREd26deP666+vNn/nzp1Zty7z9+uNN95I165dGTBgAMuXL6885q677qJv374UFhYyatQotmzZwnPPPcesWbO45ppr6NmzJ2+99RbFxcWVy5vMmzePXr16UVBQwEUXXcS2bdsqz3f99dfTu3dvCgoKanwA1vz58+nWrRuXX375Ls84+eCDDxg5ciSFhYUUFhby3HPPAfDAAw9U3nV/wQUXAOxSH8gsTV9R9sCBAxk2bFjl8iojRoygT58+dOvWjTvvvLMyzxNPPEHv3r0pLCzklFNOoby8nKOPPpqKx3qXl5fzxS9+kT31mO86J9Ej4i3gBEktku3Ne+TMZla/Hp8A77+6Z8v8bAF8/aYad7dp04Z+/frx+OOPM3z4cKZNm8Y555yDJG688UbatGnDzp07OeWUU3jllVfo0aNHteUsWrSIadOmsWTJEsrKyujduzd9+mQeaHrmmWcybtw4AH784x9z9913c9VVVzFs2DCGDh3KWWedtUtZW7dupbi4mHnz5tG1a1fGjh3LHXfcwdVXXw1k1tJavHgxv/71r5k0aRKTJ0/+RH2mTp3KmDFjGD58OD/84Q/ZsWMHTZo0Yfz48QwePJiHH36YnTt3snnzZpYuXcpPf/pTnnvuOdq2bcuGDRvq/LEuXryY1157jS5dugBwzz330KZNGz7++GP69u3LqFGjKC8vZ9y4cSxYsIAuXbqwYcMGDjroIM4//3ymTJnC1Vdfzdy5cyksLGRPPeY7pzWuJJ1O5kFO35V0naTr6spjZlad7GGs7OGrhx56iN69e9OrVy+WLl26y3BTVc8++ywjR46kefPmtGrVimHDKkfZee211xg4cCAFBQVMmTKFpUuX1lqf5cuX06VLF7p27QrAhRdeyIIF/7hr4cwzzwSgT58+lJaWfiL/9u3beeyxxxgxYgStWrWif//+lfM8Tz31VOX8TqNGjTjssMN46qmnOPvss2nbti2QCap16devX2XwALjtttsoLCzkhBNOYOXKlbz55pu88MILDBo0qPK4inIvuugiHnjgASATePbkOl919kAk/QZoDgwh8yTAs4Dql780s4ajlp5CPg0fPpzvfOc7LF68mC1bttCnTx/eeecdJk2axMKFC2ndujXFxcV1Lr1ek+LiYmbOnElhYSH33Xdf5dMK0zr44IOBTACobg5izpw5fPjhhxQUFACZ9bQOOeQQhg4dulvnyV6mvry8vHKYD+DQQw+tfD9//nzmzp3L888/T/PmzTnppJNq/Vl16tSJ9u3b89RTT/HSSy8xZcqU3apXbXLpgXw5IsYC/xsR/0pmYcWue6wGZnZAadGiBUOGDOGiiy6q7H189NFHHHrooRx22GF88MEHPP547U+qHjRoEDNnzuTjjz9m06ZNzJ49u3Lfpk2b6NChAzt27Njly7Jly5Zs2rTpE2Udc8wxlJaWsmLFCiCzUu/gwYNzbs/UqVOZPHkypaWllJaW8s477/Dkk0+yZcsWTjnlFO644w4g89jejRs3cvLJJ/OHP/yB9evXA1QOYXXu3JlFixYBMGvWLHbs2FHt+TZu3Ejr1q1p3rw5b7zxBi+88AIAJ5xwAgsWLOCdd97ZpVyAiy++mPPPP5+zzz678nkpe0IuAaQitG2R9DlgB9Ahl8IlnSZpuaQVkiZUs79Y0lpJS5LXxUn65yUtTtKWSrosK8/8pMyKPJ/JpS5mtu8YM2YML7/8cmUAKSwspFevXhx77LF885vf5MQTT6w1f+/evTn33HMpLCzk61//+i5Ltf/kJz+hf//+nHjiiRx77LGV6aNHj+YXv/gFvXr14q233qpMb9asGffeey9nn302BQUFHHTQQVx22WXkYsuWLTzxxBOcfvrplWmHHnooAwYMYPbs2fzHf/wHTz/9NAUFBfTp04dly5bRrVs3fvSjHzF48GAKCwv57ne/C8C4ceN45plnKp/nnt3ryHbaaadRVlbGcccdx4QJEzjhhBMAaNeuHXfeeSdnnnkmhYWFnHvuuZV5hg0bxubNm/f8MvURUesL+BfgcDJLmrxP5q70iTnka0RmBd8vkLlv5GXg+CrHFAO/rCZvU+Dg5H0LoBT4XLI9Hyiq6/zZrz59+oSZRSxbtqy+q2D1YOHChTFgwIBaj6nudwMoiVq+W2udA0keJDUvIj4E/lPSn4BmEbExh9jUD1gREW8nZU0DhgM1z4wlIuvGReBg/OREM7NUbrrpJu644449OvdRodYv5ogoB36Vtb0tx+ABcCSwMmt7VZJW1ShJr0iaIalTRaKkTpJeScr4WUS8l5Xn3mT46l8kqbqTJ88sKZFUsqeueTYza2gmTJjAu+++y4ABA/Z42bn8ZT9P0qiavqg/pdlA54joATwJ3F+xIyJWJulfBC6U1D7ZdV5EFAADk9cF1RUcEXdGRFFEFO2pa57NzOwfcgkgl5JZPHGbpI8kbZL0UQ75VgOdsrY7JmmVImJ9RGxLNicDfaoWkvQ8XiMTLIiI1cm/m4AHyQyVmZnZXpbLI21bRsRBEdE0Ilol261yKHshcLSkLpKaAqOBWdkHSMq+mmsY8HqS3jFZNh5JrYEBwHJJjSW1TdKbAEPJBBczM9vLcrmRcFB16VHlAVPV7C+TdCUwh8wVWfdExFJJE8nM7M8CxicLNZYBG8hclQVwHHCzpAAETIqIVyUdCsxJgkcjYC5wVw7tNDOzPSyXB0pdk/W+GZkho0XAyXVljIjHgMeqpF2X9f4HwA+qyfck8IlFcCLi71QzzGVmDUeLFi3YvNlL6u0PcllM8Yzs7eRKqVvzVSEzM2sY0txfsYrMEJOZWWoRwTXXXEP37t0pKChg+vTpAKxZs4ZBgwbRs2dPunfvzrPPPsvOnTspLi6uPPaWW26p59ob5DYHcjsQyeZBQE9gcR7rZGZ7wc9e+hlvbKj++RZpHdvmWK7td21Ox/7xj39kyZIlvPzyy6xbt46+ffsyaNAgHnzwQb72ta/xox/9iJ07d7JlyxaWLFnC6tWree21zDUz1T2V0Pa+XOZASrLelwFTI+K/81QfMztA/PnPf2bMmDE0atSI9u3bM3jwYBYuXEjfvn256KKL2LFjByNGjKBnz5584Qtf4O233+aqq67i9NNP56tf/Wp9V9/ILYDMALZGxE4ASY0kNY+ILfmtmpnlU649hb1t0KBBLFiwgEcffZTi4mK++93vMnbsWF5++WXmzJnDb37zGx566CHuueee+q7qAS+nO9GBQ7K2DyFz+ayZWWoDBw5k+vTp7Ny5k7Vr17JgwQL69evHu+++S/v27Rk3bhwXX3wxixcvZt26dZSXlzNq1Ch++tOfsnixR9H3Bbn0QJpF1mNsI2KzpOZ5rJOZHQBGjhzJ888/T2FhIZL4+c9/zmc/+1nuv/9+fvGLX9CkSRNatGjBAw88wOrVq/nWt75V+cClf//3f6/n2huAMiv21nKA9N/AVRGxONnuQ2YJ9i/thfrtEUVFRVFSUlL3gWb7uddff53jjvNFlPZJ1f1uSFoUEUU15cmlB3I18AdJ75G5K/yzwLm15jAzs/1eLjcSLpR0LHBMkrQ8Iqp/1qKZmR0w6pxEl/R/gEMj4rWIeA1oIemK/FfNzMz2ZblchTUueSIhABHxv8C4vNXIzMwahFwCSKPsh0lJakTmmeVmZnYAy2US/QlguqTfJtuXAo/nr0pmZtYQ5NIDuRZ4Crgseb3KrjcWmpnlZMiQIcyZM2eXtFtvvZXLL7+8xjwnnXQSFZfhf+Mb36h2HawbbriBSZMm1XrumTNnsmzZssrt6667jrlzP/090fPnz2fo0KGfupyGKJcnEpYDLwKlZJ4FcjLJkwPNzHbHmDFjmDZt2i5p06ZNY8yYMTnlf+yxxzj88MNTnbtqAJk4cSKnnnpqqrIso8YAIqmrpOslvQHcDvwPQEQMiYhf7q0Kmtn+46yzzuLRRx9l+/btAJSWlvLee+8xcOBALr/8coqKiujWrRvXX399tfk7d+7MunXrALjxxhvp2rUrAwYMYPny5ZXH3HXXXfTt25fCwkJGjRrFli1beO6555g1axbXXHMNPXv25K233qK4uJgZM2YAMG/ePHr16kVBQQEXXXQR27Ztqzzf9ddfT+/evSkoKOCNN3JfvXjq1KkUFBTQvXt3rr02s+5YTcvS33bbbRx//PH06NGD0aNH7+ZPtf7UNgfyBvAsMDQiVgBI+s5eqZWZ5d37//ZvbHt9zy7nfvBxx/LZH/6wxv1t2rShX79+PP744wwfPpxp06ZxzjnnIIkbb7yRNm3asHPnTk455RReeeUVevT4xINJAVi0aBHTpk1jyZIllJWV0bt3b/r0yTys9Mwzz2TcuMyFoj/+8Y+5++67ueqqqxg2bBhDhw7lrLPO2qWsrVu3UlxczLx58+jatStjx47ljjvu4Oqrrwagbdu2LF68mF//+tdMmjSJyZMn1/lzeO+997j22mtZtGgRrVu35qtf/SozZ86kU6dO1S5Lf9NNN/HOO+9w8MEHN6il6msbwjoTWAM8LekuSaeQuRM9Z5JOk7Rc0gpJE6rZXyxpraQlyeviJP3zkhYnaUslXZaVp4+kV5Myb8u+QszM9n3Zw1jZw1cPPfQQvXv3plevXixdunSX4aaqnn32WUaOHEnz5s1p1aoVw4YNq9z32muvMXDgQAoKCpgyZQpLly6ttT7Lly+nS5cudO3aFYALL7yQBQsWVO4/88wzAejTpw+lpaU5tXHhwoWcdNJJtGvXjsaNG3PeeeexYMGCXZalf+KJJ2jVqhUAPXr04LzzzuP3v/89jRvncm3TvqHGmkbETGCmpEOB4WSWNPmMpDuAhyPiv2orOLnc91fAV8g8xXChpFkRUfW3YnpEXFklbQ3wpYjYJqkF8FqS9z3gDjL3obxI5nnrp+Grwsx2W209hXwaPnw43/nOd1i8eDFbtmyhT58+vPPOO0yaNImFCxfSunVriouL2bp1a6ryi4uLmTlzJoWFhdx3333Mnz//U9X34IMPBqBRo0aUlZV9qrJat25d7bL0jz76KAsWLGD27NnceOONvPrqqw0ikOQyif73iHgweTZ6R+AvZK7Mqks/YEVEvB0R24FpZAJRnSJie0RsSzYPrqinpA5Aq4h4ITKrQD4AjMilTDPbN7Ro0YIhQ4Zw0UUXVfY+PvroIw499FAOO+wwPvjgAx5/vPa/CQcNGsTMmTP5+OOP2bRpE7Nnz67ct2nTJjp06MCOHTuYMmVKZXrLli3ZtGnTJ8o65phjKC0tZcWKFQD87ne/Y/DgwZ+qjf369eOZZ55h3bp17Ny5k6lTpzJ48OBql6UvLy9n5cqVDBkyhJ/97Gds3LiRzZs3132SfcBuhbjkLvQ7k1ddjgRWZm2vAvpXc9woSYOAvwLfiYiVAJI6AY8CXwSuiYj3JBUl5WSXeWR1J5d0CXAJwFFHHZVDdc1sbxkzZgwjR46sHMoqLCykV69eHHvssXTq1IkTTzyx1vy9e/fm3HPPpbCwkM985jP07du3ct9PfvIT+vfvT7t27ejfv39l0Bg9ejTjxo3jtttuq5w8B2jWrBn33nsvZ599NmVlZfTt25fLLrvsE+eszbx58+jYsWPl9h/+8AduuukmhgwZQkRw+umnM3z4cF5++eVPLEu/c+dOzj//fDZu3EhEMH78+NRXmu1tdS7nnrpg6SzgtIiomNe4AOifPVwl6QhgczJUdSlwbkScXKWczwEzgTOATsBNEXFqsm8gcG1E1HoRtpdzN8vwcu5WkzTLuedyI2Faq8l84VfomKRVioj1WUNVk4E+VQtJ5j1eAwYm+Ttm7f5EmWZmtnfkM4AsBI6W1EVSU2A0MCv7gGROo8IwkhsUJXWUdEjyvjUwgMwy8muAjySdkFx9NRZ4JI9tMDOzGuRtmj8iyiRdCcwBGgH3RMRSSROBkoiYBYyXNAwoAzYAxUn244CbJQWZS4cnRcSryb4rgPvILKfyOL4Cy8ysXuT1OrGIeIzMpbbZaddlvf8B8INq8j0JVHsHUUSUAN33bE3NDhwRgW+fsmxp58LzOYRlZvuYZs2asX79+tRfGLb/iQjWr19Ps2bNdjvvvn+nipntMR07dmTVqlWsXbu2vqti+5BmzZrtchlyrhxAzA4gTZo0oUuXLvVdDdtPeAjLzMxScQAxM7NUHEDMzCwVBxAzM0vFAcTMzFJxADEzs1QcQMzMLBUHEDMzS8UBxMzMUnEAMTOzVBxAzMwsFQcQMzNLxQHEzMxScQAxM7NUHEDMzCyVvAYQSadJWi5phaQJ1ewvlrRW0pLkdXGS3lPS85KWSnpF0rlZee6T9E5Wnp75bIOZmVUvbw+UktQI+BXwFWAVsFDSrIhYVuXQ6RFxZZW0LcDYiHhT0ueARZLmRMSHyf5rImJGvupuZmZ1y2cPpB+wIiLejojtwDRgeC4ZI+KvEfFm8v494G9Au7zV1MzMdls+A8iRwMqs7VVJWlWjkmGqGZI6Vd0pqR/QFHgrK/nGJM8tkg7eo7U2M7Oc1Pck+mygc0T0AJ4E7s/eKakD8DvgWxFRniT/ADgW6Au0Aa6trmBJl0gqkVSydu3afNXfzOyAlc8AshrI7lF0TNIqRcT6iNiWbE4G+lTsk9QKeBT4UUS8kJVnTWRsA+4lM1T2CRFxZ0QURURRu3Ye/TIz29PyGUAWAkdL6iKpKTAamJV9QNLDqDAMeD1Jbwo8DDxQdbK8Io8kASOA1/LVADMzq1nersKKiDJJVwJzgEbAPRGxVNJEoCQiZgHjJQ0DyoANQHGS/RxgEHCEpIq04ohYAkyR1A4QsAS4LF9tMDOzmiki6rsOeVdUVBQlJSX1XQ0zswZF0qKIKKppf31PopuZWQPlAGJmZqk4gJiZWSoOIGZmlooDiJmZpeIAYmZmqTiAmJlZKg4gZmaWigOImZml4gBiZmapOICYmVkqDiBmZpaKA4iZmaXiAGJmZqk4gJiZWSoOIGZmlooDiJmZpeIAYmZmqTiAmJlZKnkNIJJOk7Rc0gpJE6rZXyxpraQlyeviJL2npOclLZX0iqRzs/J0kfRiUuZ0SU3z2QYzM6te3gKIpEbAr4CvA8cDYyQdX82h0yOiZ/KanKRtAcZGRDfgNOBWSYcn+34G3BIRXwT+F/h2vtpgZmY1y2cPpB+wIiLejojtwDRgeC4ZI+KvEfFm8v494G9AO0kCTgZmJIfeD4zY0xU3M7O65TOAHAmszNpelaRVNSoZppohqVPVnZL6AU2Bt4AjgA8joqyOMpF0iaQSSSVr1679NO0wM7Nq1Pck+mygc0T0AJ4k06OoJKkD8DvgWxFRvjsFR8SdEVEUEUXt2rXbYxU2M7OMfAaQ1UB2j6JjklYpItZHxLZkczLQp2KfpFbAo8CPIuKFJHk9cLikxjWVaWZme0c+A8hC4OjkqqmmwGhgVvYBSQ+jwjDg9SS9KfAw8EBEVMx3EBEBPA2clSRdCDyStxaYmVmN8hZAknmKK4E5ZALDQxGxVNJEScOSw8Ynl+q+DIwHipP0c4BBQHHWJb49k33XAt+VtILMnMjd+WqDmZnVTJk/6vdvRUVFUVJSUt/VMDNrUCQtioiimvbX9yS6mZk1UA4gZmaWigOImZml4gBiZmapOICYmVkqDiBmZpaKA4iZmaXiAGJmZqk4gJiZWSoOIGZmlooDiJmZpeIAYmZmqTSu+5AD2OMT4P1X67sWZmbpfLYAvn5T3op3D8TMzFJxD6Q2eYzcZmYNnXsgZmaWigOImZml4gBiZmap5DWASDpN0nJJKyRNqGZ/saS1Wc89vzhr3xOSPpT0pyp57pP0TjXPSjczs70ob5PokhoBvwK+AqwCFkqaFRHLqhw6PSKurKaIXwDNgUur2XdNRMzYoxU2M7Pdks8eSD9gRUS8HRHbgWnA8FwzR8Q8YFO+KmdmZp9OPgPIkcDKrO1VSVpVoyS9ImmGpE45ln1jkucWSQdXd4CkSySVSCpZu3btblbdzMzqUt+T6LOBzhHRA3gSuD+HPD8AjgX6Am2Aa6s7KCLujIiiiChq167dnqqvmZkl8nkj4Wogu0fRMUmrFBHrszYnAz+vq9CIWJO83SbpXuD7deVZtGjROknv1lnj6rUF1qXMu6/a39rk9uz79rc27W/tgerb9PnaMuQzgCwEjpbUhUzgGA18M/sASR2yAsIw4PW6Cq3II0nACOC1uvJEROouiKSSiChKm39ftL+1ye3Z9+1vbdrf2gPp2pS3ABIRZZKuBOYAjYB7ImKppIlASUTMAsZLGgaUARuA4or8kp4lM1TVQtIq4NsRMQeYIqkdIGAJcFm+2mBmZjXL61pYEfEY8FiVtOuy3v+AzJxGdXkH1pB+8p6so5mZpVPfk+gNwZ31XYE82N/a5Pbs+/a3Nu1v7YEUbVJE5KMiZma2n3MPxMzMUnEAMTOzVBxAalHXYpANjaRSSa8mi1CW1Hd90pB0j6S/SXotK62NpCclvZn827o+67g7amjPDZJWZy0Y+o36rOPukNRJ0tOSlklaKumfk/SG/BnV1KYG+TlJaibpJUkvJ+351yS9i6QXk++76ZKa1lmW50CqlywG+VeyFoMExlSzGGSDIakUKIqIBnsDlKRBwGbggYjonqT9HNgQETclgb51RFS7QsG+pob23ABsjohJ9Vm3NCR1ADpExGJJLYFFZO7XKqbhfkY1tekcGuDnlNxDd2hEbJbUBPgz8M/Ad4E/RsQ0Sb8BXo6IO2oryz2Qmn2qxSAtPyJiAZl7hrIN5x/L4NxP5j93g1BDexqsiFgTEYuT95vI3Bx8JA37M6qpTQ1SZGxONpskrwBOBipWOc/pM3IAqVmui0E2JAH8l6RFki6p78rsQe2zVjR4H2hfn5XZQ65MFgy9pyEN92ST1BnoBbzIfvIZVWkTNNDPSVIjSUuAv5FZh/At4MOIKEsOyen7zgHkwDIgInoDXwf+TzJ8sl+JzJhsQx+XvQP4J6AnsAa4uV5rk4KkFsB/AldHxEfZ+xrqZ1RNmxrs5xQROyOiJ5k1CvuRWfVjtzmA1KzOxSAbmohYnfz7N+BhMr84+4MPknHqivHqv9VzfT6ViPgg+Q9eDtxFA/ucknH1/wSmRMQfk+QG/RlV16aG/jkBRMSHwNPAl4DDJVWsTpLT950DSM0qF4NMrkYYDcyq5zqlJunQZAIQSYcCXyWHhSgbiFnAhcn7C4FH6rEun1rFF21iJA3oc0omaO8GXo+I/5e1q8F+RjW1qaF+TpLaSTo8eX8ImQuFXicTSM5KDsvpM/JVWLVILsu7lX8sBnlj/dYoPUlfINPrgMwaaA82xPZImgqcRGbp6Q+A64GZwEPAUcC7wDkR0SAmpmtoz0lkhkUCKAUuzZo/2KdJGgA8C7wKlCfJPyQzZ9BQP6Oa2jSGBvg5SepBZpK8EZlOxEMRMTH5jphG5jlLfwHOj4httZblAGJmZml4CMvMzFJxADEzs1QcQMzMLBUHEDMzS8UBxMzMUnEAMdsDJO3MWpV1yZ5cvVlS5+zVes32FXl9JrrZAeTjZGkIswOGeyBmeZQ8g+XnyXNYXpL0xSS9s6SnkoX45kk6KklvL+nh5FkNL0v6clJUI0l3Jc9v+K/kDmKzeuUAYrZnHFJlCOvcrH0bI6IA+CWZlQ0Abgfuj4gewBTgtiT9NuCZiCgEegNLk/SjgV9FRDfgQ2BUXltjlgPfiW62B0jaHBEtqkkvBU6OiLeTBfnej4gjJK0j85CiHUn6mohoK2kt0DF7CYlkCfEnI+LoZPtaoElE/HQvNM2sRu6BmOVf1PB+d2SvSbQTz1/aPsABxCz/zs369/nk/XNkVngGOI/MYn0A84DLofKhP4ftrUqa7S7/FWO2ZxySPOGtwhMRUXEpb2tJr5DpRYxJ0q4C7pV0DbAW+FaS/s/AnZK+TaancTmZhxWZ7XM8B2KWR8kcSFFErKvvupjtaR7CMjOzVNwDMTOzVNwDMTOzVBxAzMwsFQcQMzNLxQHEzMxScQAxM7NU/j9DLsqm1KIFigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 210s 5s/step - loss: nan - accuracy: 0.5370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.5370370149612427]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = model.evaluate(X_axial_test, y_axial_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxGks6FB7W8"
   },
   "source": [
    "# CORONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9C4njiq6B7XG",
    "outputId": "4a93da83-0133-4de3-c371-91d13555ce4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/173] Slices processed 67.\n",
      "-> [2/173] Slices processed 134.\n",
      "-> [3/173] Slices processed 201.\n",
      "-> [4/173] Slices processed 268.\n",
      "-> [5/173] Slices processed 335.\n",
      "-> [6/173] Slices processed 402.\n",
      "-> [7/173] Slices processed 469.\n",
      "-> [8/173] Slices processed 536.\n",
      "-> [9/173] Slices processed 603.\n",
      "-> [10/173] Slices processed 670.\n",
      "-> [11/173] Slices processed 737.\n",
      "-> [12/173] Slices processed 804.\n",
      "-> [13/173] Slices processed 871.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_5444/1790016269.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [14/173] Slices processed 1052.\n",
      "-> [15/173] Slices processed 1119.\n",
      "-> [16/173] Slices processed 1186.\n",
      "-> [17/173] Slices processed 1253.\n",
      "-> [18/173] Slices processed 1320.\n",
      "-> [19/173] Slices processed 1387.\n",
      "-> [20/173] Slices processed 1454.\n",
      "-> [21/173] Slices processed 1521.\n",
      "-> [22/173] Slices processed 1588.\n",
      "-> [23/173] Slices processed 1655.\n",
      "-> [24/173] Slices processed 1722.\n",
      "-> [25/173] Slices processed 1789.\n",
      "-> [26/173] Slices processed 1856.\n",
      "-> [27/173] Slices processed 1923.\n",
      "-> [28/173] Slices processed 1990.\n",
      "-> [29/173] Slices processed 2057.\n",
      "-> [30/173] Slices processed 2124.\n",
      "-> [31/173] Slices processed 2191.\n",
      "-> [32/173] Slices processed 2258.\n",
      "-> [33/173] Slices processed 2325.\n",
      "-> [34/173] Slices processed 2392.\n",
      "-> [35/173] Slices processed 2459.\n",
      "-> [36/173] Slices processed 2526.\n",
      "-> [37/173] Slices processed 2593.\n",
      "-> [38/173] Slices processed 2660.\n",
      "-> [39/173] Slices processed 2727.\n",
      "-> [40/173] Slices processed 2794.\n",
      "-> [41/173] Slices processed 2861.\n",
      "-> [42/173] Slices processed 2928.\n",
      "-> [43/173] Slices processed 2995.\n",
      "-> [44/173] Slices processed 3062.\n",
      "-> [45/173] Slices processed 3129.\n",
      "-> [46/173] Slices processed 3196.\n",
      "-> [47/173] Slices processed 3263.\n",
      "-> [48/173] Slices processed 3330.\n",
      "-> [49/173] Slices processed 3397.\n",
      "-> [50/173] Slices processed 3464.\n",
      "-> [51/173] Slices processed 3531.\n",
      "-> [52/173] Slices processed 3598.\n",
      "-> [53/173] Slices processed 3624.\n",
      "-> [54/173] Slices processed 3691.\n",
      "-> [55/173] Slices processed 3758.\n",
      "-> [56/173] Slices processed 3825.\n",
      "-> [57/173] Slices processed 3892.\n",
      "-> [58/173] Slices processed 3959.\n",
      "-> [59/173] Slices processed 4026.\n",
      "-> [60/173] Slices processed 4093.\n",
      "-> [61/173] Slices processed 4160.\n",
      "-> [62/173] Slices processed 4227.\n",
      "-> [63/173] Slices processed 4294.\n",
      "-> [64/173] Slices processed 4361.\n",
      "-> [65/173] Slices processed 4428.\n",
      "-> [66/173] Slices processed 4495.\n",
      "-> [67/173] Slices processed 4562.\n",
      "-> [68/173] Slices processed 4629.\n",
      "-> [69/173] Slices processed 4696.\n",
      "-> [70/173] Slices processed 4763.\n",
      "-> [71/173] Slices processed 4830.\n",
      "-> [72/173] Slices processed 4897.\n",
      "-> [73/173] Slices processed 4964.\n",
      "-> [74/173] Slices processed 5031.\n",
      "-> [75/173] Slices processed 5098.\n",
      "-> [76/173] Slices processed 5165.\n",
      "-> [77/173] Slices processed 5232.\n",
      "-> [78/173] Slices processed 5299.\n",
      "-> [79/173] Slices processed 5366.\n",
      "-> [80/173] Slices processed 5433.\n",
      "-> [81/173] Slices processed 5500.\n",
      "-> [82/173] Slices processed 5567.\n",
      "-> [83/173] Slices processed 5634.\n",
      "-> [84/173] Slices processed 5701.\n",
      "-> [85/173] Slices processed 5704.\n",
      "-> [86/173] Slices processed 5771.\n",
      "-> [87/173] Slices processed 5838.\n",
      "-> [88/173] Slices processed 5905.\n",
      "-> [89/173] Slices processed 5972.\n",
      "-> [90/173] Slices processed 6039.\n",
      "-> [91/173] Slices processed 6106.\n",
      "-> [92/173] Slices processed 6173.\n",
      "-> [93/173] Slices processed 6240.\n",
      "-> [94/173] Slices processed 6307.\n",
      "-> [95/173] Slices processed 6374.\n",
      "-> [96/173] Slices processed 6441.\n",
      "-> [97/173] Slices processed 6508.\n",
      "-> [98/173] Slices processed 6575.\n",
      "-> [99/173] Slices processed 6642.\n",
      "-> [100/173] Slices processed 6709.\n",
      "-> [101/173] Slices processed 6776.\n",
      "-> [102/173] Slices processed 6843.\n",
      "-> [103/173] Slices processed 6910.\n",
      "-> [104/173] Slices processed 6977.\n",
      "-> [105/173] Slices processed 7044.\n",
      "-> [106/173] Slices processed 7111.\n",
      "-> [107/173] Slices processed 7178.\n",
      "-> [108/173] Slices processed 7245.\n",
      "-> [109/173] Slices processed 7312.\n",
      "-> [110/173] Slices processed 7379.\n",
      "-> [111/173] Slices processed 7446.\n",
      "-> [112/173] Slices processed 7513.\n",
      "-> [113/173] Slices processed 7580.\n",
      "-> [114/173] Slices processed 7647.\n",
      "-> [115/173] Slices processed 7714.\n",
      "-> [116/173] Slices processed 7781.\n",
      "-> [117/173] Slices processed 7848.\n",
      "-> [118/173] Slices processed 7915.\n",
      "-> [119/173] Slices processed 7982.\n",
      "-> [120/173] Slices processed 8049.\n",
      "-> [121/173] Slices processed 8116.\n",
      "-> [122/173] Slices processed 8183.\n",
      "-> [123/173] Slices processed 8250.\n",
      "-> [124/173] Slices processed 8317.\n",
      "-> [125/173] Slices processed 8384.\n",
      "-> [126/173] Slices processed 8451.\n",
      "-> [127/173] Slices processed 8518.\n",
      "-> [128/173] Slices processed 8585.\n",
      "-> [129/173] Slices processed 8649.\n",
      "-> [130/173] Slices processed 8716.\n",
      "-> [131/173] Slices processed 8783.\n",
      "-> [132/173] Slices processed 8850.\n",
      "-> [133/173] Slices processed 8917.\n",
      "-> [134/173] Slices processed 8984.\n",
      "-> [135/173] Slices processed 9051.\n",
      "-> [136/173] Slices processed 9118.\n",
      "-> [137/173] Slices processed 9185.\n",
      "-> [138/173] Slices processed 9252.\n",
      "-> [139/173] Slices processed 9319.\n",
      "-> [140/173] Slices processed 9386.\n",
      "-> [141/173] Slices processed 9453.\n",
      "-> [142/173] Slices processed 9520.\n",
      "-> [143/173] Slices processed 9587.\n",
      "-> [144/173] Slices processed 9654.\n",
      "-> [145/173] Slices processed 9721.\n",
      "-> [146/173] Slices processed 9788.\n",
      "-> [147/173] Slices processed 9855.\n",
      "-> [148/173] Slices processed 9922.\n",
      "-> [149/173] Slices processed 9989.\n",
      "-> [150/173] Slices processed 10056.\n",
      "-> [151/173] Slices processed 10123.\n",
      "-> [152/173] Slices processed 10190.\n",
      "-> [153/173] Slices processed 10257.\n",
      "-> [154/173] Slices processed 10324.\n",
      "-> [155/173] Slices processed 10391.\n",
      "-> [156/173] Slices processed 10458.\n",
      "-> [157/173] Slices processed 10525.\n",
      "-> [158/173] Slices processed 10592.\n",
      "-> [159/173] Slices processed 10659.\n",
      "-> [160/173] Slices processed 10726.\n",
      "-> [161/173] Slices processed 10793.\n",
      "-> [162/173] Slices processed 10860.\n",
      "-> [163/173] Slices processed 10927.\n",
      "-> [164/173] Slices processed 10994.\n",
      "-> [165/173] Slices processed 11061.\n",
      "-> [166/173] Slices processed 11128.\n",
      "-> [167/173] Slices processed 11195.\n",
      "-> [168/173] Slices processed 11262.\n",
      "-> [169/173] Slices processed 11329.\n",
      "-> [170/173] Slices processed 11396.\n",
      "-> [171/173] Slices processed 11463.\n",
      "-> [172/173] Slices processed 11530.\n",
      "-> [173/173] Slices processed 11597.\n"
     ]
    }
   ],
   "source": [
    "X_coronal_train, y_coronal_train = get_slices_per_group_coronal(X_train, y_train)\n",
    "X_coronal_train = X_coronal_train.reshape(-1, X_coronal_train.shape[1], X_coronal_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMncXN8hITS-",
    "outputId": "12c8b938-1747-4d6d-e030-acb66e2990f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/44] Slices processed 67.\n",
      "-> [2/44] Slices processed 134.\n",
      "-> [3/44] Slices processed 201.\n",
      "-> [4/44] Slices processed 268.\n",
      "-> [5/44] Slices processed 335.\n",
      "-> [6/44] Slices processed 402.\n",
      "-> [7/44] Slices processed 469.\n",
      "-> [8/44] Slices processed 536.\n",
      "-> [9/44] Slices processed 603.\n",
      "-> [10/44] Slices processed 670.\n",
      "-> [11/44] Slices processed 737.\n",
      "-> [12/44] Slices processed 804.\n",
      "-> [13/44] Slices processed 871.\n",
      "-> [14/44] Slices processed 938.\n",
      "-> [15/44] Slices processed 1005.\n",
      "-> [16/44] Slices processed 1072.\n",
      "-> [17/44] Slices processed 1139.\n",
      "-> [18/44] Slices processed 1206.\n",
      "-> [19/44] Slices processed 1273.\n",
      "-> [20/44] Slices processed 1340.\n",
      "-> [21/44] Slices processed 1407.\n",
      "-> [22/44] Slices processed 1474.\n",
      "-> [23/44] Slices processed 1541.\n",
      "-> [24/44] Slices processed 1608.\n",
      "-> [25/44] Slices processed 1675.\n",
      "-> [26/44] Slices processed 1742.\n",
      "-> [27/44] Slices processed 1809.\n",
      "-> [28/44] Slices processed 1876.\n",
      "-> [29/44] Slices processed 1943.\n",
      "-> [30/44] Slices processed 2010.\n",
      "-> [31/44] Slices processed 2077.\n",
      "-> [32/44] Slices processed 2144.\n",
      "-> [33/44] Slices processed 2211.\n",
      "-> [34/44] Slices processed 2278.\n",
      "-> [35/44] Slices processed 2345.\n",
      "-> [36/44] Slices processed 2412.\n",
      "-> [37/44] Slices processed 2435.\n",
      "-> [38/44] Slices processed 2502.\n",
      "-> [39/44] Slices processed 2569.\n",
      "-> [40/44] Slices processed 2636.\n",
      "-> [41/44] Slices processed 2703.\n",
      "-> [42/44] Slices processed 2770.\n",
      "-> [43/44] Slices processed 2837.\n",
      "-> [44/44] Slices processed 2904.\n"
     ]
    }
   ],
   "source": [
    "X_coronal_test, y_coronal_test = get_slices_per_group_coronal(X_test, y_test)\n",
    "X_coronal_test = X_coronal_test.reshape(-1, X_coronal_train.shape[1], X_coronal_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viljIspWB7XG",
    "outputId": "fd32e79d-f158-463e-8507-4ffd28f3a3bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X:(11597, 224, 224, 1), y: 11597\n",
      "Test: X:(2904, 224, 224, 1), y: 2904\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_coronal_train.shape[0],X_coronal_train.shape[1],X_coronal_train.shape[2],X_coronal_train.shape[3], len(y_coronal_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_coronal_test.shape[0],X_coronal_test.shape[1],X_coronal_test.shape[2],X_coronal_test.shape[3], len(y_coronal_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PURhal9KB7XG"
   },
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "O5ckKc9YB7XG"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import imageio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PknsV4akB7XG",
    "outputId": "a3b91a1b-36a8-4351-b9e3-466e0bfd7579",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 143,667,089\n",
      "Trainable params: 143,667,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBG1DJV4B7XG",
    "outputId": "6511ab56-e480-4dca-f6dc-180ae9486714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_coronal.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afbB58ZAETXD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "928/928 [==============================] - 8392s 9s/step - loss: nan - accuracy: 0.5174 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62457, saving model to vgg19_coronal.h5\n",
      "Epoch 2/50\n",
      "928/928 [==============================] - 8386s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62457\n",
      "Epoch 3/50\n",
      "928/928 [==============================] - 8388s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62457\n",
      "Epoch 4/50\n",
      "928/928 [==============================] - 8408s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62457\n",
      "Epoch 5/50\n",
      "928/928 [==============================] - 8387s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62457\n",
      "Epoch 6/50\n",
      "928/928 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5164"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_coronal_train, y_coronal_train, batch_size=10,epochs=50,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2nzYIb4B7XG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/173] Slices processed 112.\n",
      "-> [2/173] Slices processed 228.\n",
      "-> [3/173] Slices processed 338.\n",
      "-> [4/173] Slices processed 452.\n",
      "-> [5/173] Slices processed 565.\n",
      "-> [6/173] Slices processed 679.\n",
      "-> [7/173] Slices processed 789.\n",
      "-> [8/173] Slices processed 900.\n",
      "-> [9/173] Slices processed 1011.\n",
      "-> [10/173] Slices processed 1126.\n",
      "-> [11/173] Slices processed 1249.\n",
      "-> [12/173] Slices processed 1364.\n",
      "-> [13/173] Slices processed 1476.\n",
      "-> [14/173] Slices processed 1590.\n",
      "-> [15/173] Slices processed 1710.\n",
      "-> [16/173] Slices processed 1821.\n",
      "-> [17/173] Slices processed 1934.\n",
      "-> [18/173] Slices processed 2049.\n",
      "-> [19/173] Slices processed 2155.\n",
      "-> [20/173] Slices processed 2266.\n",
      "-> [21/173] Slices processed 2379.\n",
      "-> [22/173] Slices processed 2493.\n",
      "-> [23/173] Slices processed 2609.\n",
      "-> [24/173] Slices processed 2724.\n",
      "-> [25/173] Slices processed 2843.\n",
      "-> [26/173] Slices processed 2957.\n",
      "-> [27/173] Slices processed 3072.\n",
      "-> [28/173] Slices processed 3187.\n",
      "-> [29/173] Slices processed 3298.\n",
      "-> [30/173] Slices processed 3413.\n",
      "-> [31/173] Slices processed 3529.\n",
      "-> [32/173] Slices processed 3646.\n",
      "-> [33/173] Slices processed 3766.\n",
      "-> [34/173] Slices processed 3872.\n",
      "-> [35/173] Slices processed 3994.\n",
      "-> [36/173] Slices processed 4106.\n",
      "-> [37/173] Slices processed 4179.\n",
      "-> [38/173] Slices processed 4287.\n",
      "-> [39/173] Slices processed 4411.\n",
      "-> [40/173] Slices processed 4525.\n",
      "-> [41/173] Slices processed 4633.\n",
      "-> [42/173] Slices processed 4746.\n",
      "-> [43/173] Slices processed 4866.\n",
      "-> [44/173] Slices processed 4978.\n",
      "-> [45/173] Slices processed 5086.\n",
      "-> [46/173] Slices processed 5206.\n",
      "-> [47/173] Slices processed 5322.\n",
      "-> [48/173] Slices processed 5430.\n",
      "-> [49/173] Slices processed 5549.\n",
      "-> [50/173] Slices processed 5664.\n",
      "-> [51/173] Slices processed 5780.\n",
      "-> [52/173] Slices processed 5896.\n",
      "-> [53/173] Slices processed 6013.\n",
      "-> [54/173] Slices processed 6128.\n",
      "-> [55/173] Slices processed 6248.\n",
      "-> [56/173] Slices processed 6362.\n",
      "-> [57/173] Slices processed 6480.\n",
      "-> [58/173] Slices processed 6593.\n",
      "-> [59/173] Slices processed 6704.\n",
      "-> [60/173] Slices processed 6821.\n",
      "-> [61/173] Slices processed 6939.\n",
      "-> [62/173] Slices processed 7045.\n",
      "-> [63/173] Slices processed 7152.\n",
      "-> [64/173] Slices processed 7258.\n",
      "-> [65/173] Slices processed 7373.\n",
      "-> [66/173] Slices processed 7490.\n",
      "-> [67/173] Slices processed 7599.\n",
      "-> [68/173] Slices processed 7716.\n",
      "-> [69/173] Slices processed 7829.\n",
      "-> [70/173] Slices processed 7934.\n",
      "-> [71/173] Slices processed 8049.\n",
      "-> [72/173] Slices processed 8156.\n",
      "-> [73/173] Slices processed 8270.\n",
      "-> [74/173] Slices processed 8386.\n",
      "-> [75/173] Slices processed 8495.\n",
      "-> [76/173] Slices processed 8610.\n",
      "-> [77/173] Slices processed 8729.\n",
      "-> [78/173] Slices processed 8841.\n",
      "-> [79/173] Slices processed 8951.\n",
      "-> [80/173] Slices processed 9056.\n",
      "-> [81/173] Slices processed 9169.\n",
      "-> [82/173] Slices processed 9272.\n",
      "-> [83/173] Slices processed 9380.\n",
      "-> [84/173] Slices processed 9494.\n",
      "-> [85/173] Slices processed 9610.\n",
      "-> [86/173] Slices processed 9729.\n",
      "-> [87/173] Slices processed 9846.\n",
      "-> [88/173] Slices processed 9959.\n",
      "-> [89/173] Slices processed 10078.\n",
      "-> [90/173] Slices processed 10194.\n",
      "-> [91/173] Slices processed 10323.\n",
      "-> [92/173] Slices processed 10436.\n",
      "-> [93/173] Slices processed 10549.\n",
      "-> [94/173] Slices processed 10669.\n",
      "-> [95/173] Slices processed 10785.\n",
      "-> [96/173] Slices processed 10898.\n"
     ]
    }
   ],
   "source": [
    "X_sagital_train, y_sagital_train = get_slices_per_group_sagital(X_train, y_train)\n",
    "X_sagital_train = X_sagital_train.reshape(-1, X_sagital_train.shape[1], X_sagital_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_sagital_train.shape[0],X_sagital_train.shape[1],X_sagital_train.shape[2],X_sagital_train.shape[3], len(y_sagital_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_sagital_test.shape[0],X_sagital_test.shape[1],X_sagital_test.shape[2],X_sagital_test.shape[3], len(y_sagital_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl1Z4kUYHNuR"
   },
   "source": [
    "#EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "6oFQ-zSoGTni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 217, 181) 0.0\n",
      "(224, 224) 0.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = sitk.ReadImage(PD_file_paths[1], sitk.sitkFloat64)\n",
    "arr = sitk.GetArrayFromImage(img)\n",
    "print(arr.shape, arr.min())\n",
    "\n",
    "arr_reshaped = cv2.resize(arr[:, : , 100], (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "arr_reshaped[arr_reshaped < 0] = 0\n",
    "print(arr_reshaped.shape, arr_reshaped.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8Rf70BKGtaSF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224) 0.0\n"
     ]
    }
   ],
   "source": [
    "arr_reshaped[arr_reshaped < 0] = 0\n",
    "print(arr_reshaped.shape, arr_reshaped.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FuHg_UWaoSrD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "\n",
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(arr[60, : , :], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r5QBdyYNHOVD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(arr_reshaped, cmap=\"gray\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PvAOESUMZ3vC"
   ],
   "name": "Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

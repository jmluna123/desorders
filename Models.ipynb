{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5O_u_2VEVaxu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZDM9TeHSpdz"
   },
   "source": [
    "# DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvAOESUMZ3vC"
   },
   "source": [
    "## GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UEuSwGAuUIDE"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import  List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M_bEIIkaTMVc"
   },
   "outputs": [],
   "source": [
    "BUY_file_paths =  sorted(glob(\"./SEGMENTED/BUY/*.nii.gz\"))  #68 files\n",
    "EAT_file_paths =  sorted(glob(\"./SEGMENTED/EAT/*.nii.gz\"))  #85 files\n",
    "GAMBLE_file_paths =  sorted(glob(\"./SEGMENTED/GAMBLE/*.nii.gz\")) #7 files\n",
    "SEX_file_paths =  sorted(glob(\"./SEGMENTED/SEX/*.nii.gz\"))  #42 files\n",
    "\n",
    "PD_file_paths =  sorted(glob(\"./SEGMENTED/PD/*.nii.gz\"))  #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_file_paths =  sorted(glob(\"./PREPROCESSED/BUY/*.nii.gz\"))  #42 files\n",
    "EAT_file_paths =  sorted(glob(\"./PREPROCESSED/EAT/*.nii.gz\"))  #81 files\n",
    "GAMBLE_file_paths =  []#sorted(glob(\"./PREPROCESSED/GAMBLE/*.nii.gz\")) #7 files\n",
    "SEX_file_paths =  []#sorted(glob(\"./PREPROCESSED/SEX/*.nii.gz\"))  #22 files\n",
    "\n",
    "PD_file_paths =  sorted(glob(\"./PREPROCESSED/PD/*.nii.gz\"))  #116 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhjKHY1eUK8T",
    "outputId": "b3e7fe30-d891-486d-d291-af6046269e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 ['./PREPROCESSED/BUY\\\\3018.nii.gz', './PREPROCESSED/BUY\\\\3062.nii.gz', './PREPROCESSED/BUY\\\\3168.nii.gz']\n",
      "81 ['./PREPROCESSED/EAT\\\\3002.nii.gz', './PREPROCESSED/EAT\\\\3023.nii.gz', './PREPROCESSED/EAT\\\\3062.nii.gz']\n",
      "0 []\n",
      "0 []\n",
      "116 ['./PREPROCESSED/PD\\\\3006.nii.gz', './PREPROCESSED/PD\\\\3012.nii.gz', './PREPROCESSED/PD\\\\3014.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(len(BUY_file_paths), BUY_file_paths[:3])\n",
    "print(len(EAT_file_paths), EAT_file_paths[:3])\n",
    "print(len(GAMBLE_file_paths), GAMBLE_file_paths[:3])\n",
    "print(len(SEX_file_paths), SEX_file_paths[:3])\n",
    "\n",
    "print(len(PD_file_paths), PD_file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "print(len(BUY_file_paths) + len(EAT_file_paths) + len(GAMBLE_file_paths) + len(SEX_file_paths))\n",
    "print(len(PD_file_paths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIEPs4fyi_Do"
   },
   "source": [
    "## SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smYhVSm3REZT",
    "outputId": "4e5fb0de-9dbb-4e64-f4ac-07e3dd37abe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset = []\n",
    "y_dataset = []\n",
    "\n",
    "X_dataset.extend(PD_file_paths), y_dataset.extend([1] * len(PD_file_paths))\n",
    "X_dataset.extend(BUY_file_paths), y_dataset.extend([2] * len(BUY_file_paths))\n",
    "X_dataset.extend(EAT_file_paths), y_dataset.extend([3] * len(EAT_file_paths))\n",
    "#X_dataset.extend(GAMBLE_file_paths), y_dataset.extend([4] * len(GAMBLE_file_paths))\n",
    "#X_dataset.extend(SEX_file_paths), y_dataset.extend([5] * len(SEX_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uqc7y2bki-jm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size = 0.2, stratify=y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulHtkPzaYDdz",
    "outputId": "68995ed6-84a9-4e22-c0d2-0326b3d42b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 239 239\n",
      "Train: 191 191\n",
      "Test: 48 48\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset:\", len(X_dataset), len(y_dataset))\n",
    "print(\"Train:\", len(X_train), len(y_train))\n",
    "print(\"Test:\", len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5gQU1FEGLxm"
   },
   "source": [
    "## PREPROSSESING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tmO7ktYZjyzg"
   },
   "outputs": [],
   "source": [
    "def get_category(category, is_binary = True):\n",
    "  result = np.zeros(2 if is_binary else 5)\n",
    "  if is_binary:\n",
    "    return 1 if category == 1 else 0\n",
    "  elif category == 1:\n",
    "    result[0] = 1\n",
    "  else:\n",
    "    result[category-1] = 1\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dodkXvulaU6J"
   },
   "outputs": [],
   "source": [
    "def get_categories(y_data):\n",
    "  categories = None\n",
    "  is_first = True\n",
    "  for category in y_data:\n",
    "    if is_first:\n",
    "      categories = np.array([get_category(category)])\n",
    "      is_first = False\n",
    "    else:\n",
    "      categories = np.concatenate((categories,[get_category(category)]))\n",
    "  return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVlfjfF3NfXM",
    "outputId": "393185e6-679c-4a30-8782-66dea49fdeec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0. 0. 1.]\n",
      "1 [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(get_category(5, True), get_category(5, False))\n",
    "print(get_category(1, True), get_category(1, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D All Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from scipy import ndimage\n",
    "dimension = 100\n",
    "def get_slices_3d_all(path, category):\n",
    "    img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "    slice = arr[30:130, : , :]\n",
    "    \n",
    "    arr = np.zeros([slice.shape[0], dimension,dimension])\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(arr.shape[0]):\n",
    "        if arr[i:,:].max() != 0.0:\n",
    "            print(count)\n",
    "        arr[i, : , :] = cv2.resize(slice[i, : , :], (dimension, dimension), interpolation=cv2.INTER_CUBIC)\n",
    "        arr[arr<0] = 0\n",
    "        count += 1\n",
    "    \n",
    "    slices = np.array([arr])\n",
    "    slices = slices.reshape(1,arr.shape[0], arr.shape[1], arr.shape[2], 1)\n",
    "    slices_cat = np.array([get_category(category)])\n",
    "    \n",
    "    rotated = ndimage.rotate(arr, 45, reshape=False, axes=(1, 2))\n",
    "    rotated = rotated.reshape(1,arr.shape[0], arr.shape[1], arr.shape[2], 1)\n",
    "    slices = np.concatenate((slices, rotated))\n",
    "    slices_cat = np.concatenate((slices_cat, [get_category(category)]))\n",
    "    \n",
    "    return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_3d_all(paths, categories):\n",
    "    group = None\n",
    "    group_cat = None\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        try:\n",
    "            if i == 0:\n",
    "                group, group_cat = get_slices_3d_all(path, categories[i])\n",
    "            else:\n",
    "                new_group, new_group_cat = get_slices_3d_all(path, categories[i])\n",
    "                group = np.concatenate((group, new_group))\n",
    "                group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "            print(\"-> [%d/%d] Image processed.\" %(count,len(paths)))\n",
    "            count+=1\n",
    "        except:\n",
    "            print(\"Error in\", path)\n",
    "    return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 100, 100, 1)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_3d_all(X_dataset[11], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/3] Image processed.\n",
      "-> [2/3] Image processed.\n",
      "-> [3/3] Image processed.\n",
      "(6, 100, 100, 100, 1)\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "slices, slices_cat = get_slices_per_group_3d_all(X_dataset[:3], y_dataset[:3])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3854.9990418601315\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "\n",
    "i = 50\n",
    "print(slices[0,i,:,:,0].max())\n",
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(slices[5,i,:,:,0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "dimension = 120\n",
    "x = 32\n",
    "def get_slices_3d(path, category):\n",
    "    img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    #normalize the matrix, numbers between 0.0 - 1.0\n",
    "    #arr = arr / arr.max()\n",
    "    \n",
    "    slice = arr[68 - x :68,115:200,30:150]\n",
    "    \n",
    "    arr = np.zeros([x, dimension,dimension])\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i, : , :] = cv2.resize(slice[i, : , :], (dimension, dimension), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    slices = np.array([arr])\n",
    "    slices = slices.reshape(1,arr.shape[0], arr.shape[1], arr.shape[2], 1)\n",
    "    slices_cat = np.array([get_category(category)])\n",
    "    \n",
    "    return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_3d(paths, categories):\n",
    "    group = None\n",
    "    group_cat = None\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        if i == 0:\n",
    "            group, group_cat = get_slices_3d(path, categories[i])\n",
    "        else:\n",
    "            new_group, new_group_cat = get_slices_3d(path, categories[i])\n",
    "            group = np.concatenate((group, new_group))\n",
    "            group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "        print(\"-> [%d/%d] Image processed.\" %(count,len(paths)))\n",
    "        count+=1\n",
    "    return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 120, 120, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_3d(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/3] Image processed.\n",
      "-> [2/3] Image processed.\n",
      "-> [3/3] Image processed.\n",
      "(3, 32, 120, 120, 1)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "slices, slices_cat = get_slices_per_group_3d(X_dataset[:3], y_dataset[:3])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwSGlhsb0Iaw"
   },
   "source": [
    "## AXIAL (3 channels)\n",
    "arr[ xxx , : , : ] axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "SLICE_NUMBER = 50\n",
    "dim = 224\n",
    "def get_slices_axial_3c(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "  arr = arr[49:68,115:200,30:150]\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[arr.shape[0] - i -1, : , : ]\n",
    "    slice = cv2.resize(slice, (dim, dim), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "        slice = cv2.merge((slice,slice,slice))\n",
    "        if count == 0:\n",
    "            slices = np.array([slice])\n",
    "            slices_cat = np.array([get_category(category)])\n",
    "        if count < SLICE_NUMBER:\n",
    "            slices = np.concatenate((slices,[slice]))\n",
    "            slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "        count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_axial_3c(paths, categories):\n",
    "    \n",
    "    group = None\n",
    "    group_cat = None\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        if i == 0:\n",
    "            group, group_cat = get_slices_axial_3c(path, categories[i])\n",
    "        else:\n",
    "            try:\n",
    "                new_group, new_group_cat = get_slices_axial_3c(path, categories[i])\n",
    "                group = np.concatenate((group, new_group))\n",
    "                group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "            except:\n",
    "                print('error')\n",
    "\n",
    "        print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "        count+=1\n",
    "    return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/3] Slices processed 20.\n",
      "-> [2/3] Slices processed 40.\n",
      "-> [3/3] Slices processed 60.\n",
      "(60, 224, 224, 3)\n",
      "(60,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "i = 3\n",
    "slices, slices_cat = get_slices_per_group_axial_3c(X_dataset[0:i], y_dataset[0:i])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwSGlhsb0Iaw"
   },
   "source": [
    "## AXIAL\n",
    "arr[ xxx , : , : ] axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9cwlnfteXPLb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "SLICE_NUMBER = 20\n",
    "def get_slices_axial(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "    \n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "  arr = arr[49:68,115:200,30:150]\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[arr.shape[0] - i -1, : , : ]\n",
    "    slice = cv2.resize(slice, (120, 120), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      if count < SLICE_NUMBER:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lQz7bYsHENEt"
   },
   "outputs": [],
   "source": [
    "def get_slices_per_group_axial(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_axial(path, categories[i])\n",
    "    else:\n",
    "        try:\n",
    "          new_group, new_group_cat = get_slices_axial(path, categories[i])\n",
    "          group = np.concatenate((group, new_group))\n",
    "          group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "        except:\n",
    "            print(\"error\")\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhXSxy0Y1eEp",
    "outputId": "e71253d0-380d-44c8-80d8-d9ed159c0840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 120, 120)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_axial(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_DZGnMbC13P"
   },
   "source": [
    "## CORONAL\n",
    "arr[ : , xxx , : ] coronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JCnw2xZj_PT7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# type: the number of the group\n",
    "# group_n: the count of diferent groups\n",
    "# for example,we can have the groups \n",
    "#    1) [EAT, GAMBLE, SEX, BUY, PURE] and the image is from GAMBLE\n",
    "#     -> type = 2\n",
    "#     -> group_n = 5\n",
    "#    2) or [PURE, ICD] and the image is from PURE\n",
    "#     -> type = 1\n",
    "#     -> group_n = 2\n",
    "#output:\n",
    "#     -> normalized array of the slices \n",
    "#     -> the category of each image in one-hot encoded.\n",
    "# for example\n",
    "#   1) [0,1,0,0,0], and \n",
    "#   2) [1,0]\n",
    "def get_slices_coronal(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "  arr = arr = arr[49:68,115:200,30:150]\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[:, i , : ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9-LKeV1d_PT-"
   },
   "outputs": [],
   "source": [
    "def get_slices_per_group_coronal(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_coronal(path, categories[i])\n",
    "    else:\n",
    "        try:\n",
    "          new_group, new_group_cat = get_slices_coronal(path, categories[i])\n",
    "          group = np.concatenate((group, new_group))\n",
    "          group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "        except:\n",
    "            print(\"error\")\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eE7lOFb_PT_",
    "outputId": "6209c074-fd58-4e2e-d6e5-64602a10d748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 224, 224)\n",
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_coronal(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3ERsrLfC87J"
   },
   "source": [
    "## SAGITAL\n",
    "arr[ : , : , xxx ] sagital "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# type: the number of the group\n",
    "# group_n: the count of diferent groups\n",
    "# for example,we can have the groups \n",
    "#    1) [EAT, GAMBLE, SEX, BUY, PURE] and the image is from GAMBLE\n",
    "#     -> type = 2\n",
    "#     -> group_n = 5\n",
    "#    2) or [PURE, ICD] and the image is from PURE\n",
    "#     -> type = 1\n",
    "#     -> group_n = 2\n",
    "#output:\n",
    "#     -> normalized array of the slices \n",
    "#     -> the category of each image in one-hot encoded.\n",
    "# for example\n",
    "#   1) [0,1,0,0,0], and \n",
    "#   2) [1,0]\n",
    "def get_slices_sagital(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "  arr = arr = arr[49:68,115:200,30:150]\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[:, : , i ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_sagital(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_sagital(path, categories[i])\n",
    "    else:\n",
    "        try:\n",
    "          new_group, new_group_cat = get_slices_coronal(path, categories[i])\n",
    "          group = np.concatenate((group, new_group))\n",
    "          group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "        except:\n",
    "            print(\"error\")\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 224, 224)\n",
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_sagital(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNzzq4hUs2ww"
   },
   "source": [
    "# MODEL (BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axial (Enssemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, add, GlobalAveragePooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications import DenseNet201\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
    "from keras.layers import SeparableConv2D, AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/239] Slices processed 20.\n",
      "-> [2/239] Slices processed 40.\n",
      "-> [3/239] Slices processed 60.\n",
      "-> [4/239] Slices processed 80.\n",
      "-> [5/239] Slices processed 100.\n",
      "-> [6/239] Slices processed 120.\n",
      "-> [7/239] Slices processed 140.\n",
      "-> [8/239] Slices processed 160.\n",
      "-> [9/239] Slices processed 180.\n",
      "-> [10/239] Slices processed 200.\n",
      "-> [11/239] Slices processed 220.\n",
      "-> [12/239] Slices processed 240.\n",
      "-> [13/239] Slices processed 260.\n",
      "-> [14/239] Slices processed 280.\n",
      "-> [15/239] Slices processed 300.\n",
      "-> [16/239] Slices processed 320.\n",
      "-> [17/239] Slices processed 340.\n",
      "-> [18/239] Slices processed 360.\n",
      "-> [19/239] Slices processed 380.\n",
      "-> [20/239] Slices processed 400.\n",
      "-> [21/239] Slices processed 420.\n",
      "-> [22/239] Slices processed 440.\n",
      "-> [23/239] Slices processed 460.\n",
      "-> [24/239] Slices processed 480.\n",
      "-> [25/239] Slices processed 500.\n",
      "-> [26/239] Slices processed 520.\n",
      "-> [27/239] Slices processed 540.\n",
      "-> [28/239] Slices processed 560.\n",
      "-> [29/239] Slices processed 580.\n",
      "-> [30/239] Slices processed 600.\n",
      "-> [31/239] Slices processed 620.\n",
      "-> [32/239] Slices processed 640.\n",
      "-> [33/239] Slices processed 660.\n",
      "-> [34/239] Slices processed 680.\n",
      "-> [35/239] Slices processed 700.\n",
      "-> [36/239] Slices processed 720.\n",
      "-> [37/239] Slices processed 740.\n",
      "-> [38/239] Slices processed 760.\n",
      "-> [39/239] Slices processed 780.\n",
      "-> [40/239] Slices processed 800.\n",
      "-> [41/239] Slices processed 820.\n",
      "-> [42/239] Slices processed 840.\n",
      "-> [43/239] Slices processed 860.\n",
      "-> [44/239] Slices processed 880.\n",
      "-> [45/239] Slices processed 900.\n",
      "-> [46/239] Slices processed 920.\n",
      "-> [47/239] Slices processed 940.\n",
      "-> [48/239] Slices processed 960.\n",
      "-> [49/239] Slices processed 980.\n",
      "-> [50/239] Slices processed 1000.\n",
      "-> [51/239] Slices processed 1020.\n",
      "-> [52/239] Slices processed 1040.\n",
      "-> [53/239] Slices processed 1060.\n",
      "-> [54/239] Slices processed 1080.\n",
      "-> [55/239] Slices processed 1100.\n",
      "-> [56/239] Slices processed 1120.\n",
      "-> [57/239] Slices processed 1140.\n",
      "-> [58/239] Slices processed 1160.\n",
      "-> [59/239] Slices processed 1180.\n",
      "-> [60/239] Slices processed 1200.\n",
      "-> [61/239] Slices processed 1220.\n",
      "-> [62/239] Slices processed 1240.\n",
      "-> [63/239] Slices processed 1260.\n",
      "-> [64/239] Slices processed 1280.\n",
      "-> [65/239] Slices processed 1300.\n",
      "-> [66/239] Slices processed 1320.\n",
      "-> [67/239] Slices processed 1340.\n",
      "-> [68/239] Slices processed 1360.\n",
      "-> [69/239] Slices processed 1380.\n",
      "-> [70/239] Slices processed 1400.\n",
      "-> [71/239] Slices processed 1420.\n",
      "-> [72/239] Slices processed 1440.\n",
      "-> [73/239] Slices processed 1460.\n",
      "-> [74/239] Slices processed 1480.\n",
      "-> [75/239] Slices processed 1500.\n",
      "-> [76/239] Slices processed 1520.\n",
      "-> [77/239] Slices processed 1540.\n",
      "-> [78/239] Slices processed 1560.\n",
      "-> [79/239] Slices processed 1580.\n",
      "-> [80/239] Slices processed 1600.\n",
      "-> [81/239] Slices processed 1620.\n",
      "-> [82/239] Slices processed 1640.\n",
      "-> [83/239] Slices processed 1660.\n",
      "-> [84/239] Slices processed 1680.\n",
      "-> [85/239] Slices processed 1700.\n",
      "-> [86/239] Slices processed 1720.\n",
      "-> [87/239] Slices processed 1740.\n",
      "-> [88/239] Slices processed 1760.\n",
      "-> [89/239] Slices processed 1780.\n",
      "-> [90/239] Slices processed 1800.\n",
      "-> [91/239] Slices processed 1820.\n",
      "-> [92/239] Slices processed 1840.\n",
      "-> [93/239] Slices processed 1860.\n",
      "-> [94/239] Slices processed 1880.\n",
      "-> [95/239] Slices processed 1900.\n",
      "-> [96/239] Slices processed 1920.\n",
      "-> [97/239] Slices processed 1940.\n",
      "-> [98/239] Slices processed 1960.\n",
      "-> [99/239] Slices processed 1980.\n",
      "-> [100/239] Slices processed 2000.\n",
      "-> [101/239] Slices processed 2020.\n",
      "-> [102/239] Slices processed 2040.\n",
      "-> [103/239] Slices processed 2060.\n",
      "-> [104/239] Slices processed 2080.\n",
      "-> [105/239] Slices processed 2100.\n",
      "-> [106/239] Slices processed 2120.\n",
      "-> [107/239] Slices processed 2140.\n",
      "-> [108/239] Slices processed 2160.\n",
      "-> [109/239] Slices processed 2180.\n",
      "-> [110/239] Slices processed 2200.\n",
      "-> [111/239] Slices processed 2220.\n",
      "-> [112/239] Slices processed 2240.\n",
      "-> [113/239] Slices processed 2260.\n",
      "-> [114/239] Slices processed 2280.\n",
      "-> [115/239] Slices processed 2300.\n",
      "-> [116/239] Slices processed 2320.\n",
      "-> [117/239] Slices processed 2340.\n",
      "-> [118/239] Slices processed 2360.\n",
      "-> [119/239] Slices processed 2380.\n",
      "-> [120/239] Slices processed 2400.\n",
      "-> [121/239] Slices processed 2420.\n",
      "-> [122/239] Slices processed 2440.\n",
      "-> [123/239] Slices processed 2460.\n",
      "-> [124/239] Slices processed 2480.\n",
      "-> [125/239] Slices processed 2500.\n",
      "-> [126/239] Slices processed 2520.\n",
      "-> [127/239] Slices processed 2540.\n",
      "-> [128/239] Slices processed 2560.\n",
      "-> [129/239] Slices processed 2580.\n",
      "-> [130/239] Slices processed 2600.\n",
      "-> [131/239] Slices processed 2620.\n",
      "-> [132/239] Slices processed 2640.\n",
      "-> [133/239] Slices processed 2660.\n",
      "-> [134/239] Slices processed 2680.\n",
      "-> [135/239] Slices processed 2700.\n",
      "-> [136/239] Slices processed 2720.\n",
      "-> [137/239] Slices processed 2740.\n",
      "-> [138/239] Slices processed 2760.\n",
      "-> [139/239] Slices processed 2780.\n",
      "-> [140/239] Slices processed 2800.\n",
      "-> [141/239] Slices processed 2820.\n",
      "-> [142/239] Slices processed 2840.\n",
      "-> [143/239] Slices processed 2860.\n",
      "-> [144/239] Slices processed 2880.\n",
      "-> [145/239] Slices processed 2900.\n",
      "-> [146/239] Slices processed 2920.\n",
      "-> [147/239] Slices processed 2940.\n",
      "-> [148/239] Slices processed 2960.\n",
      "-> [149/239] Slices processed 2980.\n",
      "-> [150/239] Slices processed 3000.\n",
      "-> [151/239] Slices processed 3020.\n",
      "-> [152/239] Slices processed 3040.\n",
      "-> [153/239] Slices processed 3060.\n",
      "-> [154/239] Slices processed 3080.\n",
      "-> [155/239] Slices processed 3100.\n",
      "-> [156/239] Slices processed 3120.\n",
      "-> [157/239] Slices processed 3140.\n",
      "-> [158/239] Slices processed 3160.\n",
      "error\n",
      "-> [159/239] Slices processed 3160.\n",
      "error\n",
      "-> [160/239] Slices processed 3160.\n",
      "error\n",
      "-> [161/239] Slices processed 3160.\n",
      "error\n",
      "-> [162/239] Slices processed 3160.\n",
      "-> [163/239] Slices processed 3174.\n",
      "error\n",
      "-> [164/239] Slices processed 3174.\n",
      "error\n",
      "-> [165/239] Slices processed 3174.\n",
      "-> [166/239] Slices processed 3177.\n",
      "error\n",
      "-> [167/239] Slices processed 3177.\n",
      "error\n",
      "-> [168/239] Slices processed 3177.\n",
      "-> [169/239] Slices processed 3190.\n",
      "error\n",
      "-> [170/239] Slices processed 3190.\n",
      "-> [171/239] Slices processed 3210.\n",
      "error\n",
      "-> [172/239] Slices processed 3210.\n",
      "error\n",
      "-> [173/239] Slices processed 3210.\n",
      "error\n",
      "-> [174/239] Slices processed 3210.\n",
      "-> [175/239] Slices processed 3221.\n",
      "-> [176/239] Slices processed 3228.\n",
      "-> [177/239] Slices processed 3239.\n",
      "error\n",
      "-> [178/239] Slices processed 3239.\n",
      "error\n",
      "-> [179/239] Slices processed 3239.\n",
      "error\n",
      "-> [180/239] Slices processed 3239.\n",
      "-> [181/239] Slices processed 3259.\n",
      "error\n",
      "-> [182/239] Slices processed 3259.\n",
      "-> [183/239] Slices processed 3270.\n",
      "error\n",
      "-> [184/239] Slices processed 3270.\n",
      "error\n",
      "-> [185/239] Slices processed 3270.\n",
      "error\n",
      "-> [186/239] Slices processed 3270.\n",
      "-> [187/239] Slices processed 3272.\n",
      "error\n",
      "-> [188/239] Slices processed 3272.\n",
      "error\n",
      "-> [189/239] Slices processed 3272.\n",
      "error\n",
      "-> [190/239] Slices processed 3272.\n",
      "-> [191/239] Slices processed 3277.\n",
      "error\n",
      "-> [192/239] Slices processed 3277.\n",
      "-> [193/239] Slices processed 3291.\n",
      "error\n",
      "-> [194/239] Slices processed 3291.\n",
      "error\n",
      "-> [195/239] Slices processed 3291.\n",
      "error\n",
      "-> [196/239] Slices processed 3291.\n",
      "error\n",
      "-> [197/239] Slices processed 3291.\n",
      "error\n",
      "-> [198/239] Slices processed 3291.\n",
      "error\n",
      "-> [199/239] Slices processed 3291.\n",
      "error\n",
      "-> [200/239] Slices processed 3291.\n",
      "error\n",
      "-> [201/239] Slices processed 3291.\n",
      "error\n",
      "-> [202/239] Slices processed 3291.\n",
      "error\n",
      "-> [203/239] Slices processed 3291.\n",
      "error\n",
      "-> [204/239] Slices processed 3291.\n",
      "-> [205/239] Slices processed 3295.\n",
      "-> [206/239] Slices processed 3314.\n",
      "error\n",
      "-> [207/239] Slices processed 3314.\n",
      "error\n",
      "-> [208/239] Slices processed 3314.\n",
      "error\n",
      "-> [209/239] Slices processed 3314.\n",
      "error\n",
      "-> [210/239] Slices processed 3314.\n",
      "-> [211/239] Slices processed 3329.\n",
      "-> [212/239] Slices processed 3344.\n",
      "error\n",
      "-> [213/239] Slices processed 3344.\n",
      "error\n",
      "-> [214/239] Slices processed 3344.\n",
      "error\n",
      "-> [215/239] Slices processed 3344.\n",
      "error\n",
      "-> [216/239] Slices processed 3344.\n",
      "-> [217/239] Slices processed 3364.\n",
      "-> [218/239] Slices processed 3367.\n",
      "-> [219/239] Slices processed 3387.\n",
      "error\n",
      "-> [220/239] Slices processed 3387.\n",
      "error\n",
      "-> [221/239] Slices processed 3387.\n",
      "error\n",
      "-> [222/239] Slices processed 3387.\n",
      "error\n",
      "-> [223/239] Slices processed 3387.\n",
      "-> [224/239] Slices processed 3394.\n",
      "error\n",
      "-> [225/239] Slices processed 3394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [226/239] Slices processed 3414.\n",
      "-> [227/239] Slices processed 3432.\n",
      "error\n",
      "-> [228/239] Slices processed 3432.\n",
      "error\n",
      "-> [229/239] Slices processed 3432.\n",
      "error\n",
      "-> [230/239] Slices processed 3432.\n",
      "error\n",
      "-> [231/239] Slices processed 3432.\n",
      "-> [232/239] Slices processed 3440.\n",
      "-> [233/239] Slices processed 3450.\n",
      "-> [234/239] Slices processed 3463.\n",
      "-> [235/239] Slices processed 3469.\n",
      "-> [236/239] Slices processed 3477.\n",
      "-> [237/239] Slices processed 3490.\n",
      "error\n",
      "-> [238/239] Slices processed 3490.\n",
      "error\n",
      "-> [239/239] Slices processed 3490.\n"
     ]
    }
   ],
   "source": [
    "X_dataset_3c, y_dataset_3c = get_slices_per_group_axial_3c(X_dataset, y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset_3c, y_dataset_3c, test_size = 0.2, stratify=y_dataset_3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/100] Slices processed 20.\n",
      "-> [2/100] Slices processed 40.\n",
      "-> [3/100] Slices processed 60.\n",
      "-> [4/100] Slices processed 80.\n",
      "-> [5/100] Slices processed 100.\n",
      "-> [6/100] Slices processed 120.\n",
      "-> [7/100] Slices processed 140.\n",
      "-> [8/100] Slices processed 160.\n",
      "-> [9/100] Slices processed 180.\n",
      "-> [10/100] Slices processed 200.\n",
      "-> [11/100] Slices processed 220.\n",
      "-> [12/100] Slices processed 240.\n",
      "-> [13/100] Slices processed 260.\n",
      "-> [14/100] Slices processed 280.\n",
      "-> [15/100] Slices processed 300.\n",
      "-> [16/100] Slices processed 320.\n",
      "-> [17/100] Slices processed 340.\n",
      "-> [18/100] Slices processed 360.\n",
      "-> [19/100] Slices processed 380.\n",
      "-> [20/100] Slices processed 400.\n",
      "-> [21/100] Slices processed 420.\n",
      "-> [22/100] Slices processed 440.\n",
      "-> [23/100] Slices processed 460.\n",
      "-> [24/100] Slices processed 480.\n",
      "-> [25/100] Slices processed 500.\n",
      "-> [26/100] Slices processed 520.\n",
      "-> [27/100] Slices processed 540.\n",
      "-> [28/100] Slices processed 560.\n",
      "-> [29/100] Slices processed 580.\n",
      "-> [30/100] Slices processed 600.\n",
      "error\n",
      "-> [31/100] Slices processed 600.\n",
      "-> [32/100] Slices processed 620.\n",
      "-> [33/100] Slices processed 640.\n",
      "-> [34/100] Slices processed 660.\n",
      "-> [35/100] Slices processed 680.\n",
      "-> [36/100] Slices processed 700.\n",
      "-> [37/100] Slices processed 720.\n",
      "-> [38/100] Slices processed 740.\n",
      "-> [39/100] Slices processed 760.\n",
      "-> [40/100] Slices processed 780.\n",
      "-> [41/100] Slices processed 800.\n",
      "-> [42/100] Slices processed 820.\n",
      "-> [43/100] Slices processed 840.\n",
      "-> [44/100] Slices processed 860.\n",
      "-> [45/100] Slices processed 880.\n",
      "-> [46/100] Slices processed 900.\n",
      "-> [47/100] Slices processed 920.\n",
      "-> [48/100] Slices processed 940.\n",
      "-> [49/100] Slices processed 960.\n",
      "-> [50/100] Slices processed 980.\n",
      "-> [51/100] Slices processed 1000.\n",
      "-> [52/100] Slices processed 1020.\n",
      "-> [53/100] Slices processed 1040.\n",
      "-> [54/100] Slices processed 1060.\n",
      "-> [55/100] Slices processed 1080.\n",
      "-> [56/100] Slices processed 1100.\n",
      "-> [57/100] Slices processed 1120.\n",
      "-> [58/100] Slices processed 1140.\n",
      "-> [59/100] Slices processed 1160.\n",
      "-> [60/100] Slices processed 1180.\n",
      "-> [61/100] Slices processed 1200.\n",
      "-> [62/100] Slices processed 1220.\n",
      "-> [63/100] Slices processed 1240.\n",
      "-> [64/100] Slices processed 1260.\n",
      "-> [65/100] Slices processed 1280.\n",
      "-> [66/100] Slices processed 1300.\n",
      "-> [67/100] Slices processed 1320.\n",
      "-> [68/100] Slices processed 1340.\n",
      "-> [69/100] Slices processed 1360.\n",
      "-> [70/100] Slices processed 1380.\n",
      "-> [71/100] Slices processed 1400.\n",
      "-> [72/100] Slices processed 1420.\n",
      "-> [73/100] Slices processed 1440.\n",
      "-> [74/100] Slices processed 1460.\n",
      "-> [75/100] Slices processed 1480.\n",
      "-> [76/100] Slices processed 1500.\n",
      "-> [77/100] Slices processed 1520.\n",
      "-> [78/100] Slices processed 1540.\n",
      "-> [79/100] Slices processed 1560.\n",
      "-> [80/100] Slices processed 1580.\n",
      "-> [81/100] Slices processed 1600.\n",
      "-> [82/100] Slices processed 1620.\n",
      "-> [83/100] Slices processed 1640.\n",
      "-> [84/100] Slices processed 1660.\n",
      "-> [85/100] Slices processed 1680.\n",
      "-> [86/100] Slices processed 1700.\n",
      "-> [87/100] Slices processed 1720.\n",
      "-> [88/100] Slices processed 1740.\n",
      "-> [89/100] Slices processed 1760.\n",
      "-> [90/100] Slices processed 1780.\n",
      "-> [91/100] Slices processed 1800.\n",
      "-> [92/100] Slices processed 1820.\n",
      "-> [93/100] Slices processed 1840.\n",
      "-> [94/100] Slices processed 1860.\n",
      "-> [95/100] Slices processed 1880.\n",
      "-> [96/100] Slices processed 1900.\n",
      "-> [97/100] Slices processed 1920.\n",
      "-> [98/100] Slices processed 1940.\n",
      "-> [99/100] Slices processed 1960.\n",
      "-> [100/100] Slices processed 1980.\n"
     ]
    }
   ],
   "source": [
    "X_axial3c_train, y_axial3c_train = get_slices_per_group_axial_3c(X_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/47] Slices processed 20.\n",
      "-> [2/47] Slices processed 40.\n",
      "-> [3/47] Slices processed 60.\n",
      "error\n",
      "-> [4/47] Slices processed 60.\n",
      "-> [5/47] Slices processed 66.\n",
      "-> [6/47] Slices processed 86.\n",
      "-> [7/47] Slices processed 106.\n",
      "-> [8/47] Slices processed 126.\n",
      "-> [9/47] Slices processed 146.\n",
      "-> [10/47] Slices processed 166.\n",
      "-> [11/47] Slices processed 186.\n",
      "error\n",
      "-> [12/47] Slices processed 186.\n",
      "-> [13/47] Slices processed 199.\n",
      "-> [14/47] Slices processed 219.\n",
      "error\n",
      "-> [15/47] Slices processed 219.\n",
      "-> [16/47] Slices processed 239.\n",
      "-> [17/47] Slices processed 259.\n",
      "error\n",
      "-> [18/47] Slices processed 259.\n",
      "-> [19/47] Slices processed 279.\n",
      "-> [20/47] Slices processed 299.\n",
      "-> [21/47] Slices processed 317.\n",
      "-> [22/47] Slices processed 320.\n",
      "-> [23/47] Slices processed 340.\n",
      "-> [24/47] Slices processed 348.\n",
      "-> [25/47] Slices processed 368.\n",
      "-> [26/47] Slices processed 388.\n",
      "-> [27/47] Slices processed 408.\n",
      "-> [28/47] Slices processed 428.\n",
      "-> [29/47] Slices processed 448.\n",
      "-> [30/47] Slices processed 468.\n",
      "-> [31/47] Slices processed 488.\n",
      "-> [32/47] Slices processed 508.\n",
      "-> [33/47] Slices processed 528.\n",
      "-> [34/47] Slices processed 530.\n",
      "-> [35/47] Slices processed 534.\n",
      "error\n",
      "-> [36/47] Slices processed 534.\n",
      "-> [37/47] Slices processed 554.\n",
      "-> [38/47] Slices processed 574.\n",
      "-> [39/47] Slices processed 594.\n",
      "error\n",
      "-> [40/47] Slices processed 594.\n",
      "-> [41/47] Slices processed 614.\n",
      "-> [42/47] Slices processed 634.\n",
      "-> [43/47] Slices processed 654.\n",
      "-> [44/47] Slices processed 674.\n",
      "-> [45/47] Slices processed 694.\n",
      "error\n",
      "-> [46/47] Slices processed 694.\n",
      "-> [47/47] Slices processed 714.\n"
     ]
    }
   ],
   "source": [
    "X_axial3c_test, y_axial3c_test = get_slices_per_group_axial_3c(X_test[1:], y_test[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 224, 224, 3) (1980,)\n",
      "(964, 224, 224, 3) (964,)\n"
     ]
    }
   ],
   "source": [
    "print(X_axial3c_train.shape, y_axial3c_train.shape)\n",
    "print(X_axial3c_test.shape, y_axial3c_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "batch_size = 10\n",
    "epochs = 1000\n",
    "dropout_rate = 0.2\n",
    "num_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "input_tensor = Input(shape = input_shape)  \n",
    "\n",
    "base_model =VGG19(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_tensor,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.densenet import DenseNet169\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.nasnet import NASNetMobile\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "input_tensor = Input(shape = input_shape)  \n",
    "\n",
    "base_model1=NASNetMobile(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "base_model2=InceptionV3(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "base_model3=DenseNet201(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "base_model4=VGG19(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "x1 = base_model1.output\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "x3 = base_model3.output\n",
    "x3 = GlobalAveragePooling2D()(x3)\n",
    "\n",
    "x4 = base_model4.output\n",
    "x4 = GlobalAveragePooling2D()(x4)\n",
    "\n",
    "merge = concatenate([x1, x2, x3 , x4])\n",
    "predictions = Dense(1, activation='sigmoid')(merge)\n",
    "\n",
    "model = Model(inputs=input_tensor,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.0001, beta_1=0.7, beta_2=0.995, amsgrad=True),loss=keras.losses.binary_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1000\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_axial3c_18012022_1031.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[lr_reduce, es_callback, checkpoint],\n",
    "                    validation_split=0.20,\n",
    "                    verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_final_model = Model(inputs=model.input, outputs=merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "# training call backs \n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, epsilon=0.0001, patience=3, verbose=1)\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/1000\n",
      "159/159 - 47s - loss: 9.8581 - accuracy: 0.3535 - val_loss: 7.5476 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.50505, saving model to vgg19_axial3c_15022022_01231.h5\n",
      "Epoch 2/1000\n",
      "159/159 - 35s - loss: 9.8581 - accuracy: 0.3535 - val_loss: 7.5476 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.50505\n",
      "Epoch 3/1000\n",
      "159/159 - 35s - loss: 9.8581 - accuracy: 0.3535 - val_loss: 7.5476 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.50505\n",
      "Epoch 4/1000\n",
      "159/159 - 35s - loss: 9.8581 - accuracy: 0.3535 - val_loss: 7.5476 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.50505\n",
      "Epoch 5/1000\n",
      "159/159 - 35s - loss: 9.8581 - accuracy: 0.3535 - val_loss: 7.5476 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.50505\n",
      "Epoch 6/1000\n",
      "159/159 - 35s - loss: 9.8581 - accuracy: 0.3535 - val_loss: 7.5476 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.50505\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "epochs = 1000\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_axial3c_train.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(num_classes, activation=tf.nn.softmax))\n",
    "\n",
    "adam_opt2=Adam(lr = 0.0001, beta_1=0.7, beta_2=0.995, amsgrad=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.0001, beta_1=0.7, beta_2=0.995, amsgrad=True),loss=keras.losses.binary_crossentropy,metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"vgg19_axial3c_15022022_01231.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "history = model.fit(X_axial3c_train, y_axial3c_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[lr_reduce, es_callback, checkpoint],\n",
    "                    validation_split=0.20,\n",
    "                    verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 150528)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               38535424  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 38,535,681\n",
      "Trainable params: 38,535,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5985477178423236\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_axial3c_test)\n",
    "\n",
    "predictions = [(0 if i <0.5 else 1) for i in preds]\n",
    "cm = confusion_matrix(y_pred=predictions, y_true=y_axial3c_test)\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=y_axial3c_test, y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "labels = ['parkinson', \"parkinson + ICD\"]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('confusion_marix.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels, title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-ticks\")\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_acc.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_pogress.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "plt.figure()\n",
    "N = len(history.history['accuracy'])\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('loss.png', bbox_inches='tight', dpi = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D all brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/191] Image processed.\n",
      "-> [2/191] Image processed.\n",
      "-> [3/191] Image processed.\n",
      "-> [4/191] Image processed.\n",
      "-> [5/191] Image processed.\n",
      "-> [6/191] Image processed.\n",
      "-> [7/191] Image processed.\n",
      "-> [8/191] Image processed.\n",
      "-> [9/191] Image processed.\n",
      "-> [10/191] Image processed.\n",
      "-> [11/191] Image processed.\n",
      "-> [12/191] Image processed.\n",
      "-> [13/191] Image processed.\n",
      "-> [14/191] Image processed.\n",
      "-> [15/191] Image processed.\n",
      "-> [16/191] Image processed.\n",
      "-> [17/191] Image processed.\n",
      "-> [18/191] Image processed.\n",
      "-> [19/191] Image processed.\n",
      "-> [20/191] Image processed.\n",
      "-> [21/191] Image processed.\n",
      "-> [22/191] Image processed.\n",
      "-> [23/191] Image processed.\n",
      "-> [24/191] Image processed.\n",
      "-> [25/191] Image processed.\n",
      "-> [26/191] Image processed.\n",
      "-> [27/191] Image processed.\n",
      "-> [28/191] Image processed.\n",
      "-> [29/191] Image processed.\n",
      "-> [30/191] Image processed.\n",
      "-> [31/191] Image processed.\n",
      "-> [32/191] Image processed.\n",
      "-> [33/191] Image processed.\n",
      "-> [34/191] Image processed.\n",
      "-> [35/191] Image processed.\n",
      "-> [36/191] Image processed.\n",
      "-> [37/191] Image processed.\n",
      "-> [38/191] Image processed.\n",
      "-> [39/191] Image processed.\n",
      "-> [40/191] Image processed.\n",
      "-> [41/191] Image processed.\n",
      "-> [42/191] Image processed.\n",
      "-> [43/191] Image processed.\n",
      "-> [44/191] Image processed.\n",
      "-> [45/191] Image processed.\n",
      "-> [46/191] Image processed.\n",
      "-> [47/191] Image processed.\n",
      "-> [48/191] Image processed.\n",
      "-> [49/191] Image processed.\n",
      "-> [50/191] Image processed.\n",
      "-> [51/191] Image processed.\n",
      "-> [52/191] Image processed.\n",
      "-> [53/191] Image processed.\n",
      "-> [54/191] Image processed.\n",
      "-> [55/191] Image processed.\n",
      "-> [56/191] Image processed.\n",
      "-> [57/191] Image processed.\n",
      "-> [58/191] Image processed.\n",
      "-> [59/191] Image processed.\n",
      "-> [60/191] Image processed.\n",
      "-> [61/191] Image processed.\n",
      "-> [62/191] Image processed.\n",
      "-> [63/191] Image processed.\n",
      "-> [64/191] Image processed.\n",
      "-> [65/191] Image processed.\n",
      "-> [66/191] Image processed.\n",
      "-> [67/191] Image processed.\n",
      "-> [68/191] Image processed.\n",
      "-> [69/191] Image processed.\n",
      "-> [70/191] Image processed.\n",
      "-> [71/191] Image processed.\n",
      "-> [72/191] Image processed.\n",
      "-> [73/191] Image processed.\n",
      "-> [74/191] Image processed.\n",
      "-> [75/191] Image processed.\n",
      "-> [76/191] Image processed.\n",
      "-> [77/191] Image processed.\n",
      "-> [78/191] Image processed.\n",
      "Error in ./PREPROCESSED/EAT\\3222.nii.gz\n",
      "-> [79/191] Image processed.\n",
      "-> [80/191] Image processed.\n",
      "-> [81/191] Image processed.\n",
      "-> [82/191] Image processed.\n",
      "-> [83/191] Image processed.\n",
      "-> [84/191] Image processed.\n",
      "-> [85/191] Image processed.\n",
      "-> [86/191] Image processed.\n",
      "-> [87/191] Image processed.\n",
      "-> [88/191] Image processed.\n",
      "-> [89/191] Image processed.\n",
      "-> [90/191] Image processed.\n",
      "-> [91/191] Image processed.\n",
      "-> [92/191] Image processed.\n",
      "-> [93/191] Image processed.\n",
      "-> [94/191] Image processed.\n",
      "-> [95/191] Image processed.\n",
      "-> [96/191] Image processed.\n",
      "-> [97/191] Image processed.\n",
      "-> [98/191] Image processed.\n",
      "-> [99/191] Image processed.\n",
      "-> [100/191] Image processed.\n",
      "-> [101/191] Image processed.\n",
      "-> [102/191] Image processed.\n",
      "-> [103/191] Image processed.\n",
      "-> [104/191] Image processed.\n",
      "-> [105/191] Image processed.\n",
      "-> [106/191] Image processed.\n",
      "-> [107/191] Image processed.\n",
      "-> [108/191] Image processed.\n",
      "-> [109/191] Image processed.\n",
      "-> [110/191] Image processed.\n",
      "-> [111/191] Image processed.\n",
      "-> [112/191] Image processed.\n",
      "-> [113/191] Image processed.\n",
      "-> [114/191] Image processed.\n",
      "-> [115/191] Image processed.\n",
      "-> [116/191] Image processed.\n",
      "-> [117/191] Image processed.\n",
      "-> [118/191] Image processed.\n",
      "-> [119/191] Image processed.\n",
      "-> [120/191] Image processed.\n",
      "-> [121/191] Image processed.\n",
      "-> [122/191] Image processed.\n",
      "-> [123/191] Image processed.\n",
      "-> [124/191] Image processed.\n",
      "-> [125/191] Image processed.\n",
      "-> [126/191] Image processed.\n",
      "-> [127/191] Image processed.\n",
      "-> [128/191] Image processed.\n",
      "-> [129/191] Image processed.\n",
      "-> [130/191] Image processed.\n",
      "-> [131/191] Image processed.\n",
      "-> [132/191] Image processed.\n",
      "-> [133/191] Image processed.\n",
      "-> [134/191] Image processed.\n",
      "-> [135/191] Image processed.\n",
      "-> [136/191] Image processed.\n",
      "-> [137/191] Image processed.\n",
      "-> [138/191] Image processed.\n",
      "-> [139/191] Image processed.\n",
      "-> [140/191] Image processed.\n",
      "-> [141/191] Image processed.\n",
      "-> [142/191] Image processed.\n",
      "-> [143/191] Image processed.\n",
      "-> [144/191] Image processed.\n",
      "-> [145/191] Image processed.\n",
      "-> [146/191] Image processed.\n",
      "-> [147/191] Image processed.\n",
      "-> [148/191] Image processed.\n",
      "-> [149/191] Image processed.\n",
      "-> [150/191] Image processed.\n",
      "-> [151/191] Image processed.\n",
      "-> [152/191] Image processed.\n",
      "-> [153/191] Image processed.\n",
      "-> [154/191] Image processed.\n",
      "-> [155/191] Image processed.\n",
      "-> [156/191] Image processed.\n",
      "-> [157/191] Image processed.\n",
      "-> [158/191] Image processed.\n",
      "-> [159/191] Image processed.\n",
      "-> [160/191] Image processed.\n",
      "-> [161/191] Image processed.\n",
      "-> [162/191] Image processed.\n",
      "-> [163/191] Image processed.\n",
      "-> [164/191] Image processed.\n",
      "-> [165/191] Image processed.\n",
      "-> [166/191] Image processed.\n",
      "-> [167/191] Image processed.\n",
      "-> [168/191] Image processed.\n",
      "-> [169/191] Image processed.\n",
      "Error in ./PREPROCESSED/EAT\\55984.nii.gz\n",
      "-> [170/191] Image processed.\n",
      "-> [171/191] Image processed.\n",
      "-> [172/191] Image processed.\n",
      "-> [173/191] Image processed.\n",
      "-> [174/191] Image processed.\n",
      "-> [175/191] Image processed.\n",
      "-> [176/191] Image processed.\n",
      "-> [177/191] Image processed.\n",
      "-> [178/191] Image processed.\n",
      "-> [179/191] Image processed.\n",
      "-> [180/191] Image processed.\n",
      "-> [181/191] Image processed.\n",
      "-> [182/191] Image processed.\n",
      "-> [183/191] Image processed.\n",
      "-> [184/191] Image processed.\n",
      "-> [185/191] Image processed.\n",
      "-> [186/191] Image processed.\n",
      "-> [187/191] Image processed.\n",
      "-> [188/191] Image processed.\n",
      "-> [189/191] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_all_train, y_3d_all_train = get_slices_per_group_3d_all(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/48] Image processed.\n",
      "-> [2/48] Image processed.\n",
      "-> [3/48] Image processed.\n",
      "-> [4/48] Image processed.\n",
      "-> [5/48] Image processed.\n",
      "-> [6/48] Image processed.\n",
      "-> [7/48] Image processed.\n",
      "-> [8/48] Image processed.\n",
      "-> [9/48] Image processed.\n",
      "-> [10/48] Image processed.\n",
      "-> [11/48] Image processed.\n",
      "-> [12/48] Image processed.\n",
      "-> [13/48] Image processed.\n",
      "-> [14/48] Image processed.\n",
      "-> [15/48] Image processed.\n",
      "-> [16/48] Image processed.\n",
      "-> [17/48] Image processed.\n",
      "-> [18/48] Image processed.\n",
      "-> [19/48] Image processed.\n",
      "-> [20/48] Image processed.\n",
      "-> [21/48] Image processed.\n",
      "-> [22/48] Image processed.\n",
      "-> [23/48] Image processed.\n",
      "-> [24/48] Image processed.\n",
      "-> [25/48] Image processed.\n",
      "-> [26/48] Image processed.\n",
      "-> [27/48] Image processed.\n",
      "-> [28/48] Image processed.\n",
      "-> [29/48] Image processed.\n",
      "-> [30/48] Image processed.\n",
      "-> [31/48] Image processed.\n",
      "-> [32/48] Image processed.\n",
      "-> [33/48] Image processed.\n",
      "-> [34/48] Image processed.\n",
      "-> [35/48] Image processed.\n",
      "-> [36/48] Image processed.\n",
      "-> [37/48] Image processed.\n",
      "-> [38/48] Image processed.\n",
      "-> [39/48] Image processed.\n",
      "-> [40/48] Image processed.\n",
      "-> [41/48] Image processed.\n",
      "-> [42/48] Image processed.\n",
      "-> [43/48] Image processed.\n",
      "-> [44/48] Image processed.\n",
      "-> [45/48] Image processed.\n",
      "-> [46/48] Image processed.\n",
      "-> [47/48] Image processed.\n",
      "-> [48/48] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_all_test, y_3d_all_test = get_slices_per_group_3d_all(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (756, 100, 100, 100, 1) 756\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\",X_3d_all_train.shape, len(y_3d_all_train))\n",
    "#print(\"Test:\",X_3d_all_test.shape, len(y_3d_all_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 100, 100, 100, 20) 560       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 100, 100, 100, 64) 34624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100, 100, 100, 64) 0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 50, 50, 50, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 50, 50, 50, 128)   221312    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 50, 50, 50, 128)   442496    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 50, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 25, 25, 25, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 25, 25, 25, 256)   884992    \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 25, 25, 25, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 25, 25, 25, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 25, 25, 25, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25, 25, 25, 256)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 12, 12, 12, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 12, 12, 12, 512)   3539456   \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 12, 12, 12, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 12, 12, 12, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 12, 12, 12, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 12, 12, 12, 512)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 6, 6, 6, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 6, 6, 6, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 6, 6, 6, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 6, 6, 6, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 6, 6, 6, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 6, 512)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 3, 3, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 13825     \n",
      "=================================================================\n",
      "Total params: 59,995,249\n",
      "Trainable params: 59,995,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(input_shape=(100,100,100,1),filters=20,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(units=4096,activation=\"relu\"))\n",
    "#model.add(Dense(units=4096,activation=\"relu\"))\n",
    "#model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, epsilon=0.0001, patience=3, verbose=1)\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_3d_all_11012022_1210.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "567/567 - 10758s - loss: 1113931644928.0000 - accuracy: 0.5009 - val_loss: 0.6972 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.42857, saving model to vgg19_3d_all_11012022_1210.h5\n",
      "Epoch 2/1000\n",
      "567/567 - 9722s - loss: 0.6949 - accuracy: 0.5132 - val_loss: 0.6942 - val_accuracy: 0.4286\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.42857\n",
      "Epoch 3/1000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "epochs = 1000\n",
    "dropout_rate = 0.2\n",
    "\n",
    "history = model.fit(X_3d_all_train, y_3d_all_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[lr_reduce, es_callback, checkpoint],\n",
    "                    validation_split=0.25,\n",
    "                    verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 80, 100, 100, 1)\n",
      "[1 1 0 0]\n",
      "[[0.4959364]\n",
      " [0.4959364]\n",
      " [0.4959364]\n",
      " [0.4959364]]\n",
      "[0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "j = 14\n",
    "print(X_3d_all_test[i:j].shape)\n",
    "print(y_3d_all_test[i:j])\n",
    "preds = model.predict(X_3d_all_test[i:j])\n",
    "\n",
    "print(preds)\n",
    "predictions = [(0 if i <0.5 else 1) for i in preds]\n",
    "print(predictions)\n",
    "#cm = confusion_matrix(y_pred=predictions, y_true=y_3d_all_test[i:j])\n",
    "\n",
    "#print('Accuracy {}'.format(accuracy_score(y_true=y_3d_all_test[i:j], y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "labels = ['parkinson', \"parkinson + ICD\"]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('confusion_marix.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels, title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-ticks\")\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_acc.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_pogress.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "plt.figure()\n",
    "N = len(history.history['accuracy'])\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('loss.png', bbox_inches='tight', dpi = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/241] Image processed.\n",
      "-> [2/241] Image processed.\n",
      "-> [3/241] Image processed.\n",
      "-> [4/241] Image processed.\n",
      "-> [5/241] Image processed.\n",
      "-> [6/241] Image processed.\n",
      "-> [7/241] Image processed.\n",
      "-> [8/241] Image processed.\n",
      "-> [9/241] Image processed.\n",
      "-> [10/241] Image processed.\n",
      "-> [11/241] Image processed.\n",
      "-> [12/241] Image processed.\n",
      "-> [13/241] Image processed.\n",
      "-> [14/241] Image processed.\n",
      "-> [15/241] Image processed.\n",
      "-> [16/241] Image processed.\n",
      "-> [17/241] Image processed.\n",
      "-> [18/241] Image processed.\n",
      "-> [19/241] Image processed.\n",
      "-> [20/241] Image processed.\n",
      "-> [21/241] Image processed.\n",
      "-> [22/241] Image processed.\n",
      "-> [23/241] Image processed.\n",
      "-> [24/241] Image processed.\n",
      "-> [25/241] Image processed.\n",
      "-> [26/241] Image processed.\n",
      "-> [27/241] Image processed.\n",
      "-> [28/241] Image processed.\n",
      "-> [29/241] Image processed.\n",
      "-> [30/241] Image processed.\n",
      "-> [31/241] Image processed.\n",
      "-> [32/241] Image processed.\n",
      "-> [33/241] Image processed.\n",
      "-> [34/241] Image processed.\n",
      "-> [35/241] Image processed.\n",
      "-> [36/241] Image processed.\n",
      "-> [37/241] Image processed.\n",
      "-> [38/241] Image processed.\n",
      "-> [39/241] Image processed.\n",
      "-> [40/241] Image processed.\n",
      "-> [41/241] Image processed.\n",
      "-> [42/241] Image processed.\n",
      "-> [43/241] Image processed.\n",
      "-> [44/241] Image processed.\n",
      "-> [45/241] Image processed.\n",
      "-> [46/241] Image processed.\n",
      "-> [47/241] Image processed.\n",
      "-> [48/241] Image processed.\n",
      "-> [49/241] Image processed.\n",
      "-> [50/241] Image processed.\n",
      "-> [51/241] Image processed.\n",
      "-> [52/241] Image processed.\n",
      "-> [53/241] Image processed.\n",
      "-> [54/241] Image processed.\n",
      "-> [55/241] Image processed.\n",
      "-> [56/241] Image processed.\n",
      "-> [57/241] Image processed.\n",
      "-> [58/241] Image processed.\n",
      "-> [59/241] Image processed.\n",
      "-> [60/241] Image processed.\n",
      "-> [61/241] Image processed.\n",
      "-> [62/241] Image processed.\n",
      "-> [63/241] Image processed.\n",
      "-> [64/241] Image processed.\n",
      "-> [65/241] Image processed.\n",
      "-> [66/241] Image processed.\n",
      "-> [67/241] Image processed.\n",
      "-> [68/241] Image processed.\n",
      "-> [69/241] Image processed.\n",
      "-> [70/241] Image processed.\n",
      "-> [71/241] Image processed.\n",
      "-> [72/241] Image processed.\n",
      "-> [73/241] Image processed.\n",
      "-> [74/241] Image processed.\n",
      "-> [75/241] Image processed.\n",
      "-> [76/241] Image processed.\n",
      "-> [77/241] Image processed.\n",
      "-> [78/241] Image processed.\n",
      "-> [79/241] Image processed.\n",
      "-> [80/241] Image processed.\n",
      "-> [81/241] Image processed.\n",
      "-> [82/241] Image processed.\n",
      "-> [83/241] Image processed.\n",
      "-> [84/241] Image processed.\n",
      "-> [85/241] Image processed.\n",
      "-> [86/241] Image processed.\n",
      "-> [87/241] Image processed.\n",
      "-> [88/241] Image processed.\n",
      "-> [89/241] Image processed.\n",
      "-> [90/241] Image processed.\n",
      "-> [91/241] Image processed.\n",
      "-> [92/241] Image processed.\n",
      "-> [93/241] Image processed.\n",
      "-> [94/241] Image processed.\n",
      "-> [95/241] Image processed.\n",
      "-> [96/241] Image processed.\n",
      "-> [97/241] Image processed.\n",
      "-> [98/241] Image processed.\n",
      "-> [99/241] Image processed.\n",
      "-> [100/241] Image processed.\n",
      "-> [101/241] Image processed.\n",
      "-> [102/241] Image processed.\n",
      "-> [103/241] Image processed.\n",
      "-> [104/241] Image processed.\n",
      "-> [105/241] Image processed.\n",
      "-> [106/241] Image processed.\n",
      "-> [107/241] Image processed.\n",
      "-> [108/241] Image processed.\n",
      "-> [109/241] Image processed.\n",
      "-> [110/241] Image processed.\n",
      "-> [111/241] Image processed.\n",
      "-> [112/241] Image processed.\n",
      "-> [113/241] Image processed.\n",
      "-> [114/241] Image processed.\n",
      "-> [115/241] Image processed.\n",
      "-> [116/241] Image processed.\n",
      "-> [117/241] Image processed.\n",
      "-> [118/241] Image processed.\n",
      "-> [119/241] Image processed.\n",
      "-> [120/241] Image processed.\n",
      "-> [121/241] Image processed.\n",
      "-> [122/241] Image processed.\n",
      "-> [123/241] Image processed.\n",
      "-> [124/241] Image processed.\n",
      "-> [125/241] Image processed.\n",
      "-> [126/241] Image processed.\n",
      "-> [127/241] Image processed.\n",
      "-> [128/241] Image processed.\n",
      "-> [129/241] Image processed.\n",
      "-> [130/241] Image processed.\n",
      "-> [131/241] Image processed.\n",
      "-> [132/241] Image processed.\n",
      "-> [133/241] Image processed.\n",
      "-> [134/241] Image processed.\n",
      "-> [135/241] Image processed.\n",
      "-> [136/241] Image processed.\n",
      "-> [137/241] Image processed.\n",
      "-> [138/241] Image processed.\n",
      "-> [139/241] Image processed.\n",
      "-> [140/241] Image processed.\n",
      "-> [141/241] Image processed.\n",
      "-> [142/241] Image processed.\n",
      "-> [143/241] Image processed.\n",
      "-> [144/241] Image processed.\n",
      "-> [145/241] Image processed.\n",
      "-> [146/241] Image processed.\n",
      "-> [147/241] Image processed.\n",
      "-> [148/241] Image processed.\n",
      "-> [149/241] Image processed.\n",
      "-> [150/241] Image processed.\n",
      "-> [151/241] Image processed.\n",
      "-> [152/241] Image processed.\n",
      "-> [153/241] Image processed.\n",
      "-> [154/241] Image processed.\n",
      "-> [155/241] Image processed.\n",
      "-> [156/241] Image processed.\n",
      "-> [157/241] Image processed.\n",
      "-> [158/241] Image processed.\n",
      "-> [159/241] Image processed.\n",
      "-> [160/241] Image processed.\n",
      "-> [161/241] Image processed.\n",
      "-> [162/241] Image processed.\n",
      "-> [163/241] Image processed.\n",
      "-> [164/241] Image processed.\n",
      "-> [165/241] Image processed.\n",
      "-> [166/241] Image processed.\n",
      "-> [167/241] Image processed.\n",
      "-> [168/241] Image processed.\n",
      "-> [169/241] Image processed.\n",
      "-> [170/241] Image processed.\n",
      "-> [171/241] Image processed.\n",
      "-> [172/241] Image processed.\n",
      "-> [173/241] Image processed.\n",
      "-> [174/241] Image processed.\n",
      "-> [175/241] Image processed.\n",
      "-> [176/241] Image processed.\n",
      "-> [177/241] Image processed.\n",
      "-> [178/241] Image processed.\n",
      "-> [179/241] Image processed.\n",
      "-> [180/241] Image processed.\n",
      "-> [181/241] Image processed.\n",
      "-> [182/241] Image processed.\n",
      "-> [183/241] Image processed.\n",
      "-> [184/241] Image processed.\n",
      "-> [185/241] Image processed.\n",
      "-> [186/241] Image processed.\n",
      "-> [187/241] Image processed.\n",
      "-> [188/241] Image processed.\n",
      "-> [189/241] Image processed.\n",
      "-> [190/241] Image processed.\n",
      "-> [191/241] Image processed.\n",
      "-> [192/241] Image processed.\n",
      "-> [193/241] Image processed.\n",
      "-> [194/241] Image processed.\n",
      "-> [195/241] Image processed.\n",
      "-> [196/241] Image processed.\n",
      "-> [197/241] Image processed.\n",
      "-> [198/241] Image processed.\n",
      "-> [199/241] Image processed.\n",
      "-> [200/241] Image processed.\n",
      "-> [201/241] Image processed.\n",
      "-> [202/241] Image processed.\n",
      "-> [203/241] Image processed.\n",
      "-> [204/241] Image processed.\n",
      "-> [205/241] Image processed.\n",
      "-> [206/241] Image processed.\n",
      "-> [207/241] Image processed.\n",
      "-> [208/241] Image processed.\n",
      "-> [209/241] Image processed.\n",
      "-> [210/241] Image processed.\n",
      "-> [211/241] Image processed.\n",
      "-> [212/241] Image processed.\n",
      "-> [213/241] Image processed.\n",
      "-> [214/241] Image processed.\n",
      "-> [215/241] Image processed.\n",
      "-> [216/241] Image processed.\n",
      "-> [217/241] Image processed.\n",
      "-> [218/241] Image processed.\n",
      "-> [219/241] Image processed.\n",
      "-> [220/241] Image processed.\n",
      "-> [221/241] Image processed.\n",
      "-> [222/241] Image processed.\n",
      "-> [223/241] Image processed.\n",
      "-> [224/241] Image processed.\n",
      "-> [225/241] Image processed.\n",
      "-> [226/241] Image processed.\n",
      "-> [227/241] Image processed.\n",
      "-> [228/241] Image processed.\n",
      "-> [229/241] Image processed.\n",
      "-> [230/241] Image processed.\n",
      "-> [231/241] Image processed.\n",
      "-> [232/241] Image processed.\n",
      "-> [233/241] Image processed.\n",
      "-> [234/241] Image processed.\n",
      "-> [235/241] Image processed.\n",
      "-> [236/241] Image processed.\n",
      "-> [237/241] Image processed.\n",
      "-> [238/241] Image processed.\n",
      "-> [239/241] Image processed.\n",
      "-> [240/241] Image processed.\n",
      "-> [241/241] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_train, y_3d_train = get_slices_per_group_3d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/61] Image processed.\n",
      "-> [2/61] Image processed.\n",
      "-> [3/61] Image processed.\n",
      "-> [4/61] Image processed.\n",
      "-> [5/61] Image processed.\n",
      "-> [6/61] Image processed.\n",
      "-> [7/61] Image processed.\n",
      "-> [8/61] Image processed.\n",
      "-> [9/61] Image processed.\n",
      "-> [10/61] Image processed.\n",
      "-> [11/61] Image processed.\n",
      "-> [12/61] Image processed.\n",
      "-> [13/61] Image processed.\n",
      "-> [14/61] Image processed.\n",
      "-> [15/61] Image processed.\n",
      "-> [16/61] Image processed.\n",
      "-> [17/61] Image processed.\n",
      "-> [18/61] Image processed.\n",
      "-> [19/61] Image processed.\n",
      "-> [20/61] Image processed.\n",
      "-> [21/61] Image processed.\n",
      "-> [22/61] Image processed.\n",
      "-> [23/61] Image processed.\n",
      "-> [24/61] Image processed.\n",
      "-> [25/61] Image processed.\n",
      "-> [26/61] Image processed.\n",
      "-> [27/61] Image processed.\n",
      "-> [28/61] Image processed.\n",
      "-> [29/61] Image processed.\n",
      "-> [30/61] Image processed.\n",
      "-> [31/61] Image processed.\n",
      "-> [32/61] Image processed.\n",
      "-> [33/61] Image processed.\n",
      "-> [34/61] Image processed.\n",
      "-> [35/61] Image processed.\n",
      "-> [36/61] Image processed.\n",
      "-> [37/61] Image processed.\n",
      "-> [38/61] Image processed.\n",
      "-> [39/61] Image processed.\n",
      "-> [40/61] Image processed.\n",
      "-> [41/61] Image processed.\n",
      "-> [42/61] Image processed.\n",
      "-> [43/61] Image processed.\n",
      "-> [44/61] Image processed.\n",
      "-> [45/61] Image processed.\n",
      "-> [46/61] Image processed.\n",
      "-> [47/61] Image processed.\n",
      "-> [48/61] Image processed.\n",
      "-> [49/61] Image processed.\n",
      "-> [50/61] Image processed.\n",
      "-> [51/61] Image processed.\n",
      "-> [52/61] Image processed.\n",
      "-> [53/61] Image processed.\n",
      "-> [54/61] Image processed.\n",
      "-> [55/61] Image processed.\n",
      "-> [56/61] Image processed.\n",
      "-> [57/61] Image processed.\n",
      "-> [58/61] Image processed.\n",
      "-> [59/61] Image processed.\n",
      "-> [60/61] Image processed.\n",
      "-> [61/61] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_test, y_3d_test = get_slices_per_group_3d(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (241, 32, 120, 120, 1) 241\n",
      "Test: (61, 32, 120, 120, 1) 61\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\",X_3d_train.shape, len(y_3d_train))\n",
    "print(\"Test:\",X_3d_test.shape, len(y_3d_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 32, 120, 120, 20)  560       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, 120, 120, 64)  34624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 120, 120, 64)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 16, 60, 60, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 60, 60, 128)   221312    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 16, 60, 60, 128)   442496    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 60, 60, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 8, 30, 30, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 8, 30, 30, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 8, 30, 30, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 8, 30, 30, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 8, 30, 30, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 30, 30, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 15, 15, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 4, 15, 15, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 4, 15, 15, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 4, 15, 15, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 4, 15, 15, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 15, 15, 512)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 3, 3, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              18878464  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 99,739,201\n",
      "Trainable params: 99,739,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(input_shape=(32,120,120,1),filters=20,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_3d_3112-1856.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 3128s 156s/step - loss: 7.6737 - accuracy: 0.5833 - val_loss: 0.6914 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67347, saving model to vgg19_3d_3112-1856.h5\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 3084s 154s/step - loss: 0.6954 - accuracy: 0.6562 - val_loss: 0.6852 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67347\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 3148s 157s/step - loss: 0.6814 - accuracy: 0.6667 - val_loss: 0.6763 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67347\n",
      "Epoch 4/10\n",
      " 4/20 [=====>........................] - ETA: 43:17 - loss: 0.6400 - accuracy: 0.8000"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_3d_train, y_3d_train, batch_size=10,epochs=10,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.savefig('3d_graph_13122021.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_3d_test)\n",
    "\n",
    "predictions = [(0 if i <0.5 else 1) for i in preds]\n",
    "cm = confusion_matrix(y_pred=predictions, y_true=y_axial3c_test)\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=y_3d_test, y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-ticks\")\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_acc.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('model_pogress.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "plt.figure()\n",
    "N = len(history.history['accuracy'])\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.savefig('loss.png', bbox_inches='tight', dpi = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTMlHtqbcTsm"
   },
   "source": [
    "## AXIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6KuVpJFev4t",
    "outputId": "c6f3ceb6-6a1b-437d-c93e-14c47265bf01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/191] Slices processed 20.\n",
      "-> [2/191] Slices processed 40.\n",
      "-> [3/191] Slices processed 60.\n",
      "-> [4/191] Slices processed 80.\n",
      "error\n",
      "-> [5/191] Slices processed 80.\n",
      "error\n",
      "-> [6/191] Slices processed 80.\n",
      "-> [7/191] Slices processed 82.\n",
      "-> [8/191] Slices processed 92.\n",
      "-> [9/191] Slices processed 112.\n",
      "-> [10/191] Slices processed 132.\n",
      "-> [11/191] Slices processed 152.\n",
      "-> [12/191] Slices processed 172.\n",
      "-> [13/191] Slices processed 192.\n",
      "error\n",
      "-> [14/191] Slices processed 192.\n",
      "-> [15/191] Slices processed 212.\n",
      "-> [16/191] Slices processed 232.\n",
      "-> [17/191] Slices processed 252.\n",
      "error\n",
      "-> [18/191] Slices processed 252.\n",
      "-> [19/191] Slices processed 272.\n",
      "-> [20/191] Slices processed 292.\n",
      "-> [21/191] Slices processed 312.\n",
      "-> [22/191] Slices processed 332.\n",
      "-> [23/191] Slices processed 338.\n",
      "-> [24/191] Slices processed 358.\n",
      "-> [25/191] Slices processed 378.\n",
      "-> [26/191] Slices processed 398.\n",
      "-> [27/191] Slices processed 418.\n",
      "-> [28/191] Slices processed 431.\n",
      "-> [29/191] Slices processed 451.\n",
      "-> [30/191] Slices processed 471.\n",
      "-> [31/191] Slices processed 491.\n",
      "error\n",
      "-> [32/191] Slices processed 491.\n",
      "-> [33/191] Slices processed 511.\n",
      "error\n",
      "-> [34/191] Slices processed 511.\n",
      "-> [35/191] Slices processed 531.\n",
      "-> [36/191] Slices processed 551.\n",
      "-> [37/191] Slices processed 571.\n",
      "-> [38/191] Slices processed 591.\n",
      "-> [39/191] Slices processed 611.\n",
      "-> [40/191] Slices processed 631.\n",
      "-> [41/191] Slices processed 651.\n",
      "-> [42/191] Slices processed 671.\n",
      "-> [43/191] Slices processed 691.\n",
      "-> [44/191] Slices processed 711.\n",
      "-> [45/191] Slices processed 731.\n",
      "-> [46/191] Slices processed 751.\n",
      "-> [47/191] Slices processed 771.\n",
      "-> [48/191] Slices processed 791.\n",
      "-> [49/191] Slices processed 811.\n",
      "-> [50/191] Slices processed 826.\n",
      "-> [51/191] Slices processed 846.\n",
      "-> [52/191] Slices processed 866.\n",
      "-> [53/191] Slices processed 886.\n",
      "-> [54/191] Slices processed 900.\n",
      "-> [55/191] Slices processed 920.\n",
      "-> [56/191] Slices processed 940.\n",
      "-> [57/191] Slices processed 960.\n",
      "error\n",
      "-> [58/191] Slices processed 960.\n",
      "error\n",
      "-> [59/191] Slices processed 960.\n",
      "error\n",
      "-> [60/191] Slices processed 960.\n",
      "-> [61/191] Slices processed 980.\n",
      "-> [62/191] Slices processed 1000.\n",
      "-> [63/191] Slices processed 1020.\n",
      "-> [64/191] Slices processed 1040.\n",
      "-> [65/191] Slices processed 1060.\n",
      "-> [66/191] Slices processed 1080.\n",
      "error\n",
      "-> [67/191] Slices processed 1080.\n",
      "-> [68/191] Slices processed 1095.\n",
      "-> [69/191] Slices processed 1115.\n",
      "-> [70/191] Slices processed 1135.\n",
      "error\n",
      "-> [71/191] Slices processed 1135.\n",
      "-> [72/191] Slices processed 1155.\n",
      "error\n",
      "-> [73/191] Slices processed 1155.\n",
      "error\n",
      "-> [74/191] Slices processed 1155.\n",
      "-> [75/191] Slices processed 1175.\n",
      "error\n",
      "-> [76/191] Slices processed 1175.\n",
      "-> [77/191] Slices processed 1195.\n",
      "-> [78/191] Slices processed 1215.\n",
      "-> [79/191] Slices processed 1235.\n",
      "-> [80/191] Slices processed 1255.\n",
      "error\n",
      "-> [81/191] Slices processed 1255.\n",
      "-> [82/191] Slices processed 1275.\n",
      "-> [83/191] Slices processed 1295.\n",
      "-> [84/191] Slices processed 1315.\n",
      "-> [85/191] Slices processed 1335.\n",
      "-> [86/191] Slices processed 1355.\n",
      "error\n",
      "-> [87/191] Slices processed 1355.\n",
      "-> [88/191] Slices processed 1375.\n",
      "-> [89/191] Slices processed 1382.\n",
      "-> [90/191] Slices processed 1402.\n",
      "-> [91/191] Slices processed 1422.\n",
      "-> [92/191] Slices processed 1442.\n",
      "error\n",
      "-> [93/191] Slices processed 1442.\n",
      "-> [94/191] Slices processed 1462.\n",
      "-> [95/191] Slices processed 1482.\n",
      "-> [96/191] Slices processed 1502.\n",
      "-> [97/191] Slices processed 1522.\n",
      "-> [98/191] Slices processed 1542.\n",
      "-> [99/191] Slices processed 1555.\n",
      "-> [100/191] Slices processed 1575.\n",
      "-> [101/191] Slices processed 1595.\n",
      "error\n",
      "-> [102/191] Slices processed 1595.\n",
      "-> [103/191] Slices processed 1615.\n",
      "error\n",
      "-> [104/191] Slices processed 1615.\n",
      "-> [105/191] Slices processed 1635.\n",
      "-> [106/191] Slices processed 1655.\n",
      "-> [107/191] Slices processed 1675.\n",
      "-> [108/191] Slices processed 1695.\n",
      "-> [109/191] Slices processed 1715.\n",
      "-> [110/191] Slices processed 1735.\n",
      "-> [111/191] Slices processed 1755.\n",
      "error\n",
      "-> [112/191] Slices processed 1755.\n",
      "-> [113/191] Slices processed 1775.\n",
      "-> [114/191] Slices processed 1795.\n",
      "-> [115/191] Slices processed 1815.\n",
      "-> [116/191] Slices processed 1835.\n",
      "-> [117/191] Slices processed 1855.\n",
      "error\n",
      "-> [118/191] Slices processed 1855.\n",
      "error\n",
      "-> [119/191] Slices processed 1855.\n",
      "-> [120/191] Slices processed 1875.\n",
      "-> [121/191] Slices processed 1895.\n",
      "-> [122/191] Slices processed 1900.\n",
      "error\n",
      "-> [123/191] Slices processed 1900.\n",
      "error\n",
      "-> [124/191] Slices processed 1900.\n",
      "error\n",
      "-> [125/191] Slices processed 1900.\n",
      "-> [126/191] Slices processed 1920.\n",
      "error\n",
      "-> [127/191] Slices processed 1920.\n",
      "-> [128/191] Slices processed 1940.\n",
      "-> [129/191] Slices processed 1960.\n",
      "-> [130/191] Slices processed 1980.\n",
      "-> [131/191] Slices processed 2000.\n",
      "-> [132/191] Slices processed 2020.\n",
      "-> [133/191] Slices processed 2040.\n",
      "-> [134/191] Slices processed 2058.\n",
      "-> [135/191] Slices processed 2078.\n",
      "error\n",
      "-> [136/191] Slices processed 2078.\n",
      "-> [137/191] Slices processed 2098.\n",
      "-> [138/191] Slices processed 2118.\n",
      "-> [139/191] Slices processed 2138.\n",
      "-> [140/191] Slices processed 2158.\n",
      "error\n",
      "-> [141/191] Slices processed 2158.\n",
      "error\n",
      "-> [142/191] Slices processed 2158.\n",
      "-> [143/191] Slices processed 2178.\n",
      "-> [144/191] Slices processed 2198.\n",
      "-> [145/191] Slices processed 2218.\n",
      "-> [146/191] Slices processed 2238.\n",
      "-> [147/191] Slices processed 2241.\n",
      "error\n",
      "-> [148/191] Slices processed 2241.\n",
      "-> [149/191] Slices processed 2252.\n",
      "error\n",
      "-> [150/191] Slices processed 2252.\n",
      "-> [151/191] Slices processed 2272.\n",
      "-> [152/191] Slices processed 2292.\n",
      "error\n",
      "-> [153/191] Slices processed 2292.\n",
      "-> [154/191] Slices processed 2312.\n",
      "error\n",
      "-> [155/191] Slices processed 2312.\n",
      "-> [156/191] Slices processed 2332.\n",
      "-> [157/191] Slices processed 2352.\n",
      "-> [158/191] Slices processed 2355.\n",
      "error\n",
      "-> [159/191] Slices processed 2355.\n",
      "-> [160/191] Slices processed 2375.\n",
      "-> [161/191] Slices processed 2388.\n",
      "-> [162/191] Slices processed 2408.\n",
      "-> [163/191] Slices processed 2428.\n",
      "error\n",
      "-> [164/191] Slices processed 2428.\n",
      "-> [165/191] Slices processed 2448.\n",
      "error\n",
      "-> [166/191] Slices processed 2448.\n",
      "-> [167/191] Slices processed 2459.\n",
      "-> [168/191] Slices processed 2479.\n",
      "-> [169/191] Slices processed 2499.\n",
      "-> [170/191] Slices processed 2519.\n",
      "-> [171/191] Slices processed 2539.\n",
      "-> [172/191] Slices processed 2559.\n",
      "-> [173/191] Slices processed 2579.\n",
      "-> [174/191] Slices processed 2599.\n",
      "error\n",
      "-> [175/191] Slices processed 2599.\n",
      "-> [176/191] Slices processed 2619.\n",
      "error\n",
      "-> [177/191] Slices processed 2619.\n",
      "-> [178/191] Slices processed 2639.\n",
      "-> [179/191] Slices processed 2647.\n",
      "-> [180/191] Slices processed 2667.\n",
      "-> [181/191] Slices processed 2687.\n",
      "-> [182/191] Slices processed 2707.\n",
      "-> [183/191] Slices processed 2726.\n",
      "error\n",
      "-> [184/191] Slices processed 2726.\n",
      "-> [185/191] Slices processed 2746.\n",
      "-> [186/191] Slices processed 2766.\n",
      "error\n",
      "-> [187/191] Slices processed 2766.\n",
      "-> [188/191] Slices processed 2773.\n",
      "error\n",
      "-> [189/191] Slices processed 2773.\n",
      "-> [190/191] Slices processed 2793.\n",
      "-> [191/191] Slices processed 2813.\n",
      "-> [1/48] Slices processed 20.\n",
      "-> [2/48] Slices processed 24.\n",
      "error\n",
      "-> [3/48] Slices processed 24.\n",
      "-> [4/48] Slices processed 44.\n",
      "-> [5/48] Slices processed 64.\n",
      "-> [6/48] Slices processed 84.\n",
      "-> [7/48] Slices processed 104.\n",
      "-> [8/48] Slices processed 124.\n",
      "-> [9/48] Slices processed 144.\n",
      "-> [10/48] Slices processed 164.\n",
      "-> [11/48] Slices processed 184.\n",
      "error\n",
      "-> [12/48] Slices processed 184.\n",
      "-> [13/48] Slices processed 204.\n",
      "error\n",
      "-> [14/48] Slices processed 204.\n",
      "-> [15/48] Slices processed 224.\n",
      "-> [16/48] Slices processed 244.\n",
      "-> [17/48] Slices processed 264.\n",
      "error\n",
      "-> [18/48] Slices processed 264.\n",
      "-> [19/48] Slices processed 284.\n",
      "error\n",
      "-> [20/48] Slices processed 284.\n",
      "-> [21/48] Slices processed 304.\n",
      "-> [22/48] Slices processed 324.\n",
      "-> [23/48] Slices processed 344.\n",
      "-> [24/48] Slices processed 352.\n",
      "-> [25/48] Slices processed 372.\n",
      "-> [26/48] Slices processed 383.\n",
      "-> [27/48] Slices processed 403.\n",
      "error\n",
      "-> [28/48] Slices processed 403.\n",
      "error\n",
      "-> [29/48] Slices processed 403.\n",
      "-> [30/48] Slices processed 423.\n",
      "-> [31/48] Slices processed 443.\n",
      "error\n",
      "-> [32/48] Slices processed 443.\n",
      "-> [33/48] Slices processed 463.\n",
      "error\n",
      "-> [34/48] Slices processed 463.\n",
      "-> [35/48] Slices processed 483.\n",
      "error\n",
      "-> [36/48] Slices processed 483.\n",
      "-> [37/48] Slices processed 497.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "-> [38/48] Slices processed 497.\n",
      "error\n",
      "-> [39/48] Slices processed 497.\n",
      "-> [40/48] Slices processed 517.\n",
      "-> [41/48] Slices processed 537.\n",
      "-> [42/48] Slices processed 557.\n",
      "-> [43/48] Slices processed 577.\n",
      "-> [44/48] Slices processed 597.\n",
      "-> [45/48] Slices processed 617.\n",
      "-> [46/48] Slices processed 637.\n",
      "-> [47/48] Slices processed 657.\n",
      "-> [48/48] Slices processed 677.\n"
     ]
    }
   ],
   "source": [
    "X_axial_train, y_axial_train = get_slices_per_group_axial(X_train, y_train)\n",
    "X_axial_train = X_axial_train.reshape(-1, X_axial_train.shape[1], X_axial_train.shape[2], 1)\n",
    "\n",
    "X_axial_test, y_axial_test = get_slices_per_group_axial(X_test, y_test)\n",
    "X_axial_test = X_axial_test.reshape(-1, X_axial_train.shape[1], X_axial_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-36EzPmfjyA",
    "outputId": "e17efeb8-62c4-49ef-8446-1ec8863ff0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X:(2813, 120, 120, 1), y: 2813\n",
      "Test: X:(677, 120, 120, 1), y: 677\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_axial_train.shape[0],X_axial_train.shape[1],X_axial_train.shape[2],X_axial_train.shape[3], len(y_axial_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_axial_test.shape[0],X_axial_test.shape[1],X_axial_test.shape[2],X_axial_test.shape[3], len(y_axial_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7bK3grjmDsh"
   },
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GmsZwEJRpg-t"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y7XVr5bl5MU",
    "outputId": "18ce578d-5d08-4ce3-f8cc-aad0bd5b537b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 120, 120, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 120, 120, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              18878464  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 59,781,009\n",
      "Trainable params: 59,781,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(120,120,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-ixtI5Tpsv0",
    "outputId": "07ba67f2-d3ea-4cd9-8074-212236f6b3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_axial_14012022_0053.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training call backs \n",
    "lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, epsilon=0.0001, patience=3, verbose=1)\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "225/225 [==============================] - 656s 3s/step - loss: 0.7835 - accuracy: 0.6222 - val_loss: 0.5871 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78153, saving model to vgg19_axial_14012022_0053.h5\n",
      "Epoch 2/30\n",
      "225/225 [==============================] - 654s 3s/step - loss: 0.6636 - accuracy: 0.6311 - val_loss: 0.5509 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78153\n",
      "Epoch 3/30\n",
      "225/225 [==============================] - 655s 3s/step - loss: 0.6624 - accuracy: 0.6311 - val_loss: 0.5564 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78153\n",
      "Epoch 4/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6612 - accuracy: 0.6311 - val_loss: 0.5829 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78153\n",
      "Epoch 5/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6603 - accuracy: 0.6311 - val_loss: 0.5873 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.78153\n",
      "Epoch 6/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6603 - accuracy: 0.6311 - val_loss: 0.5805 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78153\n",
      "Epoch 7/30\n",
      "225/225 [==============================] - 658s 3s/step - loss: 0.6584 - accuracy: 0.6311 - val_loss: 0.5611 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78153\n",
      "Epoch 8/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6592 - accuracy: 0.6311 - val_loss: 0.5760 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78153\n",
      "Epoch 9/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6592 - accuracy: 0.6311 - val_loss: 0.5896 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.78153\n",
      "Epoch 10/30\n",
      "225/225 [==============================] - 656s 3s/step - loss: 0.6591 - accuracy: 0.6311 - val_loss: 0.5954 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.78153\n",
      "Epoch 11/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6593 - accuracy: 0.6311 - val_loss: 0.5775 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.78153\n",
      "Epoch 12/30\n",
      "225/225 [==============================] - 657s 3s/step - loss: 0.6605 - accuracy: 0.6311 - val_loss: 0.5864 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.78153\n",
      "Epoch 13/30\n",
      "225/225 [==============================] - 658s 3s/step - loss: 0.6582 - accuracy: 0.6311 - val_loss: 0.5920 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.78153\n",
      "Epoch 14/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6590 - accuracy: 0.6311 - val_loss: 0.5818 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78153\n",
      "Epoch 15/30\n",
      "225/225 [==============================] - 658s 3s/step - loss: 0.6596 - accuracy: 0.6311 - val_loss: 0.5803 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78153\n",
      "Epoch 16/30\n",
      "225/225 [==============================] - 725s 3s/step - loss: 0.6591 - accuracy: 0.6311 - val_loss: 0.5787 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78153\n",
      "Epoch 17/30\n",
      "225/225 [==============================] - 680s 3s/step - loss: 0.6596 - accuracy: 0.6311 - val_loss: 0.5613 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78153\n",
      "Epoch 18/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6603 - accuracy: 0.6311 - val_loss: 0.5842 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.78153\n",
      "Epoch 19/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6595 - accuracy: 0.6311 - val_loss: 0.5774 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.78153\n",
      "Epoch 20/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6601 - accuracy: 0.6311 - val_loss: 0.5741 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.78153\n",
      "Epoch 21/30\n",
      "225/225 [==============================] - 656s 3s/step - loss: 0.6587 - accuracy: 0.6311 - val_loss: 0.5846 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.78153\n",
      "Epoch 22/30\n",
      "225/225 [==============================] - 666s 3s/step - loss: 0.6594 - accuracy: 0.6311 - val_loss: 0.5754 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.78153\n",
      "Epoch 23/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6592 - accuracy: 0.6311 - val_loss: 0.5766 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.78153\n",
      "Epoch 24/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6600 - accuracy: 0.6311 - val_loss: 0.5813 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.78153\n",
      "Epoch 25/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6595 - accuracy: 0.6311 - val_loss: 0.5837 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.78153\n",
      "Epoch 26/30\n",
      "225/225 [==============================] - 657s 3s/step - loss: 0.6597 - accuracy: 0.6311 - val_loss: 0.5957 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.78153\n",
      "Epoch 27/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6593 - accuracy: 0.6311 - val_loss: 0.5774 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.78153\n",
      "Epoch 28/30\n",
      "225/225 [==============================] - 658s 3s/step - loss: 0.6589 - accuracy: 0.6311 - val_loss: 0.5779 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.78153\n",
      "Epoch 29/30\n",
      "225/225 [==============================] - 660s 3s/step - loss: 0.6591 - accuracy: 0.6311 - val_loss: 0.5817 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.78153\n",
      "Epoch 30/30\n",
      "225/225 [==============================] - 659s 3s/step - loss: 0.6590 - accuracy: 0.6311 - val_loss: 0.5713 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.78153\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_axial_train, y_axial_train, batch_size=10,epochs=30,validation_split=0.2, callbacks=[checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "seDApqQk5FtY",
    "outputId": "fc45785c-eb2f-465f-eef0-94b3ffe8452c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "#plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 0.5606 - accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5605908632278442, 0.800000011920929]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = model.evaluate(X_axial_test[:300], y_axial_test[:300])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_axial_test[:300])\n",
    "\n",
    "predictions = [(0 if i <0.5 else 1) for i in preds]\n",
    "cm = confusion_matrix(y_pred=predictions, y_true=y_axial_test[:300])\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=y_axial_test[:300], y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  60],\n",
       "       [  0, 240]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxGks6FB7W8"
   },
   "source": [
    "# CORONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9C4njiq6B7XG",
    "outputId": "4a93da83-0133-4de3-c371-91d13555ce4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/202] Slices processed 19.\n",
      "-> [2/202] Slices processed 38.\n",
      "-> [3/202] Slices processed 57.\n",
      "-> [4/202] Slices processed 76.\n",
      "-> [5/202] Slices processed 95.\n",
      "-> [6/202] Slices processed 114.\n",
      "-> [7/202] Slices processed 133.\n",
      "-> [8/202] Slices processed 152.\n",
      "-> [9/202] Slices processed 171.\n",
      "-> [10/202] Slices processed 190.\n",
      "-> [11/202] Slices processed 206.\n",
      "-> [12/202] Slices processed 225.\n",
      "-> [13/202] Slices processed 244.\n",
      "-> [14/202] Slices processed 263.\n",
      "-> [15/202] Slices processed 279.\n",
      "-> [16/202] Slices processed 298.\n",
      "-> [17/202] Slices processed 317.\n",
      "-> [18/202] Slices processed 336.\n",
      "-> [19/202] Slices processed 355.\n",
      "-> [20/202] Slices processed 374.\n",
      "-> [21/202] Slices processed 393.\n",
      "-> [22/202] Slices processed 412.\n",
      "-> [23/202] Slices processed 431.\n",
      "-> [24/202] Slices processed 450.\n",
      "-> [25/202] Slices processed 469.\n",
      "-> [26/202] Slices processed 488.\n",
      "-> [27/202] Slices processed 507.\n",
      "-> [28/202] Slices processed 526.\n",
      "-> [29/202] Slices processed 545.\n",
      "-> [30/202] Slices processed 564.\n",
      "-> [31/202] Slices processed 583.\n",
      "-> [32/202] Slices processed 602.\n",
      "-> [33/202] Slices processed 621.\n",
      "-> [34/202] Slices processed 640.\n",
      "-> [35/202] Slices processed 659.\n",
      "-> [36/202] Slices processed 678.\n",
      "-> [37/202] Slices processed 697.\n",
      "-> [38/202] Slices processed 716.\n",
      "-> [39/202] Slices processed 735.\n",
      "error\n",
      "-> [40/202] Slices processed 735.\n",
      "-> [41/202] Slices processed 754.\n",
      "-> [42/202] Slices processed 773.\n",
      "-> [43/202] Slices processed 792.\n",
      "-> [44/202] Slices processed 811.\n",
      "-> [45/202] Slices processed 830.\n",
      "-> [46/202] Slices processed 849.\n",
      "-> [47/202] Slices processed 868.\n",
      "-> [48/202] Slices processed 887.\n",
      "-> [49/202] Slices processed 906.\n",
      "-> [50/202] Slices processed 925.\n",
      "-> [51/202] Slices processed 944.\n",
      "-> [52/202] Slices processed 963.\n",
      "-> [53/202] Slices processed 982.\n",
      "-> [54/202] Slices processed 1001.\n",
      "-> [55/202] Slices processed 1020.\n",
      "-> [56/202] Slices processed 1039.\n",
      "-> [57/202] Slices processed 1058.\n",
      "-> [58/202] Slices processed 1077.\n",
      "-> [59/202] Slices processed 1096.\n",
      "-> [60/202] Slices processed 1115.\n",
      "-> [61/202] Slices processed 1134.\n",
      "-> [62/202] Slices processed 1153.\n",
      "-> [63/202] Slices processed 1172.\n",
      "-> [64/202] Slices processed 1191.\n",
      "-> [65/202] Slices processed 1210.\n",
      "-> [66/202] Slices processed 1226.\n",
      "-> [67/202] Slices processed 1245.\n",
      "-> [68/202] Slices processed 1264.\n",
      "-> [69/202] Slices processed 1283.\n",
      "-> [70/202] Slices processed 1302.\n",
      "-> [71/202] Slices processed 1321.\n",
      "-> [72/202] Slices processed 1340.\n",
      "-> [73/202] Slices processed 1359.\n",
      "-> [74/202] Slices processed 1378.\n",
      "-> [75/202] Slices processed 1397.\n",
      "-> [76/202] Slices processed 1416.\n",
      "-> [77/202] Slices processed 1435.\n",
      "-> [78/202] Slices processed 1454.\n",
      "-> [79/202] Slices processed 1473.\n",
      "-> [80/202] Slices processed 1492.\n",
      "-> [81/202] Slices processed 1511.\n",
      "-> [82/202] Slices processed 1530.\n",
      "-> [83/202] Slices processed 1549.\n",
      "-> [84/202] Slices processed 1568.\n",
      "-> [85/202] Slices processed 1587.\n",
      "-> [86/202] Slices processed 1606.\n",
      "-> [87/202] Slices processed 1625.\n",
      "-> [88/202] Slices processed 1644.\n",
      "-> [89/202] Slices processed 1663.\n",
      "-> [90/202] Slices processed 1682.\n",
      "-> [91/202] Slices processed 1701.\n",
      "-> [92/202] Slices processed 1720.\n",
      "-> [93/202] Slices processed 1739.\n",
      "-> [94/202] Slices processed 1758.\n",
      "-> [95/202] Slices processed 1777.\n",
      "-> [96/202] Slices processed 1796.\n",
      "-> [97/202] Slices processed 1815.\n",
      "-> [98/202] Slices processed 1834.\n",
      "-> [99/202] Slices processed 1853.\n",
      "-> [100/202] Slices processed 1872.\n",
      "-> [101/202] Slices processed 1891.\n",
      "-> [102/202] Slices processed 1910.\n",
      "-> [103/202] Slices processed 1929.\n",
      "-> [104/202] Slices processed 1948.\n",
      "-> [105/202] Slices processed 1967.\n",
      "-> [106/202] Slices processed 1986.\n",
      "-> [107/202] Slices processed 2005.\n",
      "-> [108/202] Slices processed 2024.\n",
      "-> [109/202] Slices processed 2043.\n",
      "-> [110/202] Slices processed 2062.\n",
      "-> [111/202] Slices processed 2081.\n",
      "-> [112/202] Slices processed 2100.\n",
      "-> [113/202] Slices processed 2119.\n",
      "-> [114/202] Slices processed 2138.\n",
      "-> [115/202] Slices processed 2157.\n",
      "-> [116/202] Slices processed 2176.\n",
      "-> [117/202] Slices processed 2195.\n",
      "-> [118/202] Slices processed 2214.\n",
      "-> [119/202] Slices processed 2233.\n",
      "-> [120/202] Slices processed 2252.\n",
      "-> [121/202] Slices processed 2271.\n",
      "-> [122/202] Slices processed 2290.\n",
      "-> [123/202] Slices processed 2309.\n",
      "-> [124/202] Slices processed 2328.\n",
      "-> [125/202] Slices processed 2347.\n",
      "-> [126/202] Slices processed 2366.\n",
      "-> [127/202] Slices processed 2385.\n",
      "-> [128/202] Slices processed 2404.\n",
      "-> [129/202] Slices processed 2423.\n",
      "-> [130/202] Slices processed 2442.\n",
      "-> [131/202] Slices processed 2461.\n",
      "-> [132/202] Slices processed 2480.\n",
      "-> [133/202] Slices processed 2499.\n",
      "-> [134/202] Slices processed 2518.\n",
      "-> [135/202] Slices processed 2537.\n",
      "-> [136/202] Slices processed 2556.\n",
      "-> [137/202] Slices processed 2575.\n",
      "-> [138/202] Slices processed 2594.\n",
      "-> [139/202] Slices processed 2613.\n",
      "-> [140/202] Slices processed 2632.\n",
      "-> [141/202] Slices processed 2651.\n",
      "-> [142/202] Slices processed 2670.\n",
      "-> [143/202] Slices processed 2689.\n",
      "-> [144/202] Slices processed 2705.\n",
      "-> [145/202] Slices processed 2724.\n",
      "-> [146/202] Slices processed 2743.\n",
      "-> [147/202] Slices processed 2762.\n",
      "-> [148/202] Slices processed 2781.\n",
      "-> [149/202] Slices processed 2800.\n",
      "-> [150/202] Slices processed 2819.\n",
      "-> [151/202] Slices processed 2838.\n",
      "-> [152/202] Slices processed 2857.\n",
      "-> [153/202] Slices processed 2865.\n",
      "-> [154/202] Slices processed 2884.\n",
      "-> [155/202] Slices processed 2903.\n",
      "-> [156/202] Slices processed 2922.\n",
      "-> [157/202] Slices processed 2941.\n",
      "-> [158/202] Slices processed 2960.\n",
      "-> [159/202] Slices processed 2979.\n",
      "-> [160/202] Slices processed 2998.\n",
      "-> [161/202] Slices processed 3017.\n",
      "-> [162/202] Slices processed 3036.\n",
      "-> [163/202] Slices processed 3055.\n",
      "-> [164/202] Slices processed 3074.\n",
      "-> [165/202] Slices processed 3093.\n",
      "-> [166/202] Slices processed 3112.\n",
      "-> [167/202] Slices processed 3131.\n",
      "-> [168/202] Slices processed 3150.\n",
      "-> [169/202] Slices processed 3169.\n",
      "-> [170/202] Slices processed 3188.\n",
      "-> [171/202] Slices processed 3207.\n",
      "-> [172/202] Slices processed 3226.\n",
      "-> [173/202] Slices processed 3245.\n",
      "-> [174/202] Slices processed 3264.\n",
      "-> [175/202] Slices processed 3283.\n",
      "-> [176/202] Slices processed 3302.\n",
      "-> [177/202] Slices processed 3321.\n",
      "-> [178/202] Slices processed 3340.\n",
      "-> [179/202] Slices processed 3359.\n",
      "-> [180/202] Slices processed 3378.\n",
      "-> [181/202] Slices processed 3397.\n",
      "-> [182/202] Slices processed 3416.\n",
      "-> [183/202] Slices processed 3435.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_2416/3491320886.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [184/202] Slices processed 3454.\n",
      "-> [185/202] Slices processed 3473.\n",
      "-> [186/202] Slices processed 3492.\n",
      "-> [187/202] Slices processed 3511.\n",
      "-> [188/202] Slices processed 3530.\n",
      "-> [189/202] Slices processed 3549.\n",
      "-> [190/202] Slices processed 3568.\n",
      "-> [191/202] Slices processed 3587.\n",
      "-> [192/202] Slices processed 3606.\n",
      "-> [193/202] Slices processed 3625.\n",
      "-> [194/202] Slices processed 3644.\n",
      "-> [195/202] Slices processed 3663.\n",
      "-> [196/202] Slices processed 3682.\n",
      "-> [197/202] Slices processed 3701.\n",
      "-> [198/202] Slices processed 3720.\n",
      "-> [199/202] Slices processed 3739.\n",
      "-> [200/202] Slices processed 3758.\n",
      "-> [201/202] Slices processed 3777.\n",
      "-> [202/202] Slices processed 3796.\n"
     ]
    }
   ],
   "source": [
    "X_coronal_train, y_coronal_train = get_slices_per_group_coronal(X_train, y_train)\n",
    "X_coronal_train = X_coronal_train.reshape(-1, X_coronal_train.shape[1], X_coronal_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMncXN8hITS-",
    "outputId": "12c8b938-1747-4d6d-e030-acb66e2990f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/51] Slices processed 19.\n",
      "-> [2/51] Slices processed 38.\n",
      "-> [3/51] Slices processed 57.\n",
      "-> [4/51] Slices processed 76.\n",
      "-> [5/51] Slices processed 95.\n",
      "-> [6/51] Slices processed 114.\n",
      "-> [7/51] Slices processed 133.\n",
      "-> [8/51] Slices processed 152.\n",
      "-> [9/51] Slices processed 171.\n",
      "-> [10/51] Slices processed 190.\n",
      "-> [11/51] Slices processed 209.\n",
      "-> [12/51] Slices processed 228.\n",
      "-> [13/51] Slices processed 247.\n",
      "-> [14/51] Slices processed 266.\n",
      "-> [15/51] Slices processed 285.\n",
      "-> [16/51] Slices processed 304.\n",
      "-> [17/51] Slices processed 323.\n",
      "-> [18/51] Slices processed 342.\n",
      "-> [19/51] Slices processed 361.\n",
      "-> [20/51] Slices processed 380.\n",
      "-> [21/51] Slices processed 399.\n",
      "-> [22/51] Slices processed 418.\n",
      "-> [23/51] Slices processed 437.\n",
      "-> [24/51] Slices processed 456.\n",
      "-> [25/51] Slices processed 475.\n",
      "-> [26/51] Slices processed 494.\n",
      "-> [27/51] Slices processed 513.\n",
      "-> [28/51] Slices processed 532.\n",
      "-> [29/51] Slices processed 551.\n",
      "-> [30/51] Slices processed 570.\n",
      "-> [31/51] Slices processed 589.\n",
      "-> [32/51] Slices processed 608.\n",
      "-> [33/51] Slices processed 627.\n",
      "-> [34/51] Slices processed 646.\n",
      "-> [35/51] Slices processed 665.\n",
      "-> [36/51] Slices processed 684.\n",
      "-> [37/51] Slices processed 703.\n",
      "-> [38/51] Slices processed 722.\n",
      "-> [39/51] Slices processed 741.\n",
      "-> [40/51] Slices processed 760.\n",
      "-> [41/51] Slices processed 779.\n",
      "-> [42/51] Slices processed 798.\n",
      "-> [43/51] Slices processed 817.\n",
      "-> [44/51] Slices processed 836.\n",
      "-> [45/51] Slices processed 855.\n",
      "-> [46/51] Slices processed 874.\n",
      "-> [47/51] Slices processed 893.\n",
      "-> [48/51] Slices processed 912.\n",
      "-> [49/51] Slices processed 931.\n",
      "-> [50/51] Slices processed 950.\n",
      "-> [51/51] Slices processed 969.\n"
     ]
    }
   ],
   "source": [
    "X_coronal_test, y_coronal_test = get_slices_per_group_coronal(X_test, y_test)\n",
    "X_coronal_test = X_coronal_test.reshape(-1, X_coronal_train.shape[1], X_coronal_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viljIspWB7XG",
    "outputId": "fd32e79d-f158-463e-8507-4ffd28f3a3bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X:(3796, 224, 224, 1), y: 3796\n",
      "Test: X:(969, 224, 224, 1), y: 969\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_coronal_train.shape[0],X_coronal_train.shape[1],X_coronal_train.shape[2],X_coronal_train.shape[3], len(y_coronal_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_coronal_test.shape[0],X_coronal_test.shape[1],X_coronal_test.shape[2],X_coronal_test.shape[3], len(y_coronal_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PURhal9KB7XG"
   },
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "GmsZwEJRpg-t"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PknsV4akB7XG",
    "outputId": "a3b91a1b-36a8-4351-b9e3-466e0bfd7579",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 143,667,089\n",
      "Trainable params: 143,667,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBG1DJV4B7XG",
    "outputId": "6511ab56-e480-4dca-f6dc-180ae9486714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_coronal_15012022_2322.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "afbB58ZAETXD",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 4993s 2s/step - loss: 2897.2546 - accuracy: 0.6067 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57500, saving model to vgg19_coronal_15012022_2322.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 5065s 2s/step - loss: 0.6720 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 4960s 2s/step - loss: 0.6719 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 5106s 2s/step - loss: 0.6721 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 5093s 2s/step - loss: 0.6716 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 5089s 2s/step - loss: 0.6717 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 5101s 2s/step - loss: 0.6720 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 5125s 2s/step - loss: 0.6720 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 5122s 2s/step - loss: 0.6719 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 5143s 2s/step - loss: 0.6718 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 5165s 2s/step - loss: 0.6718 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 5222s 2s/step - loss: 0.6718 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 13/50\n",
      " 883/3036 [=======>......................] - ETA: 59:10 - loss: 0.6807 - accuracy: 0.5832"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2416/241698994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_coronal_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_coronal_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_coronal_train, y_coronal_train, batch_size=1,epochs=50,validation_split=0.2, callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2nzYIb4B7XG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./vgg19_coronal.h5\")\n",
    "test_results = model.evaluate(X_coronal_test, y_coronal_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/202] Slices processed 15.\n",
      "-> [2/202] Slices processed 34.\n",
      "-> [3/202] Slices processed 53.\n",
      "-> [4/202] Slices processed 72.\n",
      "-> [5/202] Slices processed 91.\n",
      "-> [6/202] Slices processed 110.\n",
      "-> [7/202] Slices processed 129.\n",
      "-> [8/202] Slices processed 148.\n",
      "-> [9/202] Slices processed 167.\n",
      "-> [10/202] Slices processed 186.\n",
      "-> [11/202] Slices processed 202.\n",
      "-> [12/202] Slices processed 221.\n",
      "-> [13/202] Slices processed 240.\n",
      "-> [14/202] Slices processed 259.\n",
      "-> [15/202] Slices processed 275.\n",
      "-> [16/202] Slices processed 294.\n",
      "-> [17/202] Slices processed 313.\n",
      "-> [18/202] Slices processed 332.\n",
      "-> [19/202] Slices processed 351.\n",
      "-> [20/202] Slices processed 370.\n",
      "-> [21/202] Slices processed 389.\n",
      "-> [22/202] Slices processed 408.\n",
      "-> [23/202] Slices processed 427.\n",
      "-> [24/202] Slices processed 446.\n",
      "-> [25/202] Slices processed 465.\n",
      "-> [26/202] Slices processed 484.\n",
      "-> [27/202] Slices processed 503.\n",
      "-> [28/202] Slices processed 522.\n",
      "-> [29/202] Slices processed 541.\n",
      "-> [30/202] Slices processed 560.\n",
      "-> [31/202] Slices processed 579.\n",
      "-> [32/202] Slices processed 598.\n",
      "-> [33/202] Slices processed 617.\n",
      "-> [34/202] Slices processed 636.\n",
      "-> [35/202] Slices processed 655.\n",
      "-> [36/202] Slices processed 674.\n",
      "-> [37/202] Slices processed 693.\n",
      "-> [38/202] Slices processed 712.\n",
      "-> [39/202] Slices processed 731.\n",
      "error\n",
      "-> [40/202] Slices processed 731.\n",
      "-> [41/202] Slices processed 750.\n",
      "-> [42/202] Slices processed 769.\n",
      "-> [43/202] Slices processed 788.\n",
      "-> [44/202] Slices processed 807.\n",
      "-> [45/202] Slices processed 826.\n",
      "-> [46/202] Slices processed 845.\n",
      "-> [47/202] Slices processed 864.\n",
      "-> [48/202] Slices processed 883.\n",
      "-> [49/202] Slices processed 902.\n",
      "-> [50/202] Slices processed 921.\n",
      "-> [51/202] Slices processed 940.\n",
      "-> [52/202] Slices processed 959.\n",
      "-> [53/202] Slices processed 978.\n",
      "-> [54/202] Slices processed 997.\n",
      "-> [55/202] Slices processed 1016.\n",
      "-> [56/202] Slices processed 1035.\n",
      "-> [57/202] Slices processed 1054.\n",
      "-> [58/202] Slices processed 1073.\n",
      "-> [59/202] Slices processed 1092.\n",
      "-> [60/202] Slices processed 1111.\n",
      "-> [61/202] Slices processed 1130.\n",
      "-> [62/202] Slices processed 1149.\n",
      "-> [63/202] Slices processed 1168.\n",
      "-> [64/202] Slices processed 1187.\n",
      "-> [65/202] Slices processed 1206.\n",
      "-> [66/202] Slices processed 1222.\n",
      "-> [67/202] Slices processed 1241.\n",
      "-> [68/202] Slices processed 1260.\n",
      "-> [69/202] Slices processed 1279.\n",
      "-> [70/202] Slices processed 1298.\n",
      "-> [71/202] Slices processed 1317.\n",
      "-> [72/202] Slices processed 1336.\n",
      "-> [73/202] Slices processed 1355.\n",
      "-> [74/202] Slices processed 1374.\n",
      "-> [75/202] Slices processed 1393.\n",
      "-> [76/202] Slices processed 1412.\n",
      "-> [77/202] Slices processed 1431.\n",
      "-> [78/202] Slices processed 1450.\n",
      "-> [79/202] Slices processed 1469.\n",
      "-> [80/202] Slices processed 1488.\n",
      "-> [81/202] Slices processed 1507.\n",
      "-> [82/202] Slices processed 1526.\n",
      "-> [83/202] Slices processed 1545.\n",
      "-> [84/202] Slices processed 1564.\n",
      "-> [85/202] Slices processed 1583.\n",
      "-> [86/202] Slices processed 1602.\n",
      "-> [87/202] Slices processed 1621.\n",
      "-> [88/202] Slices processed 1640.\n",
      "-> [89/202] Slices processed 1659.\n",
      "-> [90/202] Slices processed 1678.\n",
      "-> [91/202] Slices processed 1697.\n",
      "-> [92/202] Slices processed 1716.\n",
      "-> [93/202] Slices processed 1735.\n",
      "-> [94/202] Slices processed 1754.\n",
      "-> [95/202] Slices processed 1773.\n",
      "-> [96/202] Slices processed 1792.\n",
      "-> [97/202] Slices processed 1811.\n",
      "-> [98/202] Slices processed 1830.\n",
      "-> [99/202] Slices processed 1849.\n",
      "-> [100/202] Slices processed 1868.\n",
      "-> [101/202] Slices processed 1887.\n",
      "-> [102/202] Slices processed 1906.\n",
      "-> [103/202] Slices processed 1925.\n",
      "-> [104/202] Slices processed 1944.\n",
      "-> [105/202] Slices processed 1963.\n",
      "-> [106/202] Slices processed 1982.\n",
      "-> [107/202] Slices processed 2001.\n",
      "-> [108/202] Slices processed 2020.\n",
      "-> [109/202] Slices processed 2039.\n",
      "-> [110/202] Slices processed 2058.\n",
      "-> [111/202] Slices processed 2077.\n",
      "-> [112/202] Slices processed 2096.\n",
      "-> [113/202] Slices processed 2115.\n",
      "-> [114/202] Slices processed 2134.\n",
      "-> [115/202] Slices processed 2153.\n",
      "-> [116/202] Slices processed 2172.\n",
      "-> [117/202] Slices processed 2191.\n",
      "-> [118/202] Slices processed 2210.\n",
      "-> [119/202] Slices processed 2229.\n",
      "-> [120/202] Slices processed 2248.\n",
      "-> [121/202] Slices processed 2267.\n",
      "-> [122/202] Slices processed 2286.\n",
      "-> [123/202] Slices processed 2305.\n",
      "-> [124/202] Slices processed 2324.\n",
      "-> [125/202] Slices processed 2343.\n",
      "-> [126/202] Slices processed 2362.\n",
      "-> [127/202] Slices processed 2381.\n",
      "-> [128/202] Slices processed 2400.\n",
      "-> [129/202] Slices processed 2419.\n",
      "-> [130/202] Slices processed 2438.\n",
      "-> [131/202] Slices processed 2457.\n",
      "-> [132/202] Slices processed 2476.\n",
      "-> [133/202] Slices processed 2495.\n",
      "-> [134/202] Slices processed 2514.\n",
      "-> [135/202] Slices processed 2533.\n",
      "-> [136/202] Slices processed 2552.\n",
      "-> [137/202] Slices processed 2571.\n",
      "-> [138/202] Slices processed 2590.\n",
      "-> [139/202] Slices processed 2609.\n",
      "-> [140/202] Slices processed 2628.\n",
      "-> [141/202] Slices processed 2647.\n",
      "-> [142/202] Slices processed 2666.\n",
      "-> [143/202] Slices processed 2685.\n",
      "-> [144/202] Slices processed 2701.\n",
      "-> [145/202] Slices processed 2720.\n",
      "-> [146/202] Slices processed 2739.\n",
      "-> [147/202] Slices processed 2758.\n",
      "-> [148/202] Slices processed 2777.\n",
      "-> [149/202] Slices processed 2796.\n",
      "-> [150/202] Slices processed 2815.\n",
      "-> [151/202] Slices processed 2834.\n",
      "-> [152/202] Slices processed 2853.\n",
      "-> [153/202] Slices processed 2861.\n",
      "-> [154/202] Slices processed 2880.\n",
      "-> [155/202] Slices processed 2899.\n",
      "-> [156/202] Slices processed 2918.\n",
      "-> [157/202] Slices processed 2937.\n",
      "-> [158/202] Slices processed 2956.\n",
      "-> [159/202] Slices processed 2975.\n",
      "-> [160/202] Slices processed 2994.\n",
      "-> [161/202] Slices processed 3013.\n",
      "-> [162/202] Slices processed 3032.\n",
      "-> [163/202] Slices processed 3051.\n",
      "-> [164/202] Slices processed 3070.\n",
      "-> [165/202] Slices processed 3089.\n",
      "-> [166/202] Slices processed 3108.\n",
      "-> [167/202] Slices processed 3127.\n",
      "-> [168/202] Slices processed 3146.\n",
      "-> [169/202] Slices processed 3165.\n",
      "-> [170/202] Slices processed 3184.\n",
      "-> [171/202] Slices processed 3203.\n",
      "-> [172/202] Slices processed 3222.\n",
      "-> [173/202] Slices processed 3241.\n",
      "-> [174/202] Slices processed 3260.\n",
      "-> [175/202] Slices processed 3279.\n",
      "-> [176/202] Slices processed 3298.\n",
      "-> [177/202] Slices processed 3317.\n",
      "-> [178/202] Slices processed 3336.\n",
      "-> [179/202] Slices processed 3355.\n",
      "-> [180/202] Slices processed 3374.\n",
      "-> [181/202] Slices processed 3393.\n",
      "-> [182/202] Slices processed 3412.\n",
      "-> [183/202] Slices processed 3431.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_2416/3491320886.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [184/202] Slices processed 3450.\n",
      "-> [185/202] Slices processed 3469.\n",
      "-> [186/202] Slices processed 3488.\n",
      "-> [187/202] Slices processed 3507.\n",
      "-> [188/202] Slices processed 3526.\n",
      "-> [189/202] Slices processed 3545.\n",
      "-> [190/202] Slices processed 3564.\n",
      "-> [191/202] Slices processed 3583.\n",
      "-> [192/202] Slices processed 3602.\n",
      "-> [193/202] Slices processed 3621.\n",
      "-> [194/202] Slices processed 3640.\n",
      "-> [195/202] Slices processed 3659.\n",
      "-> [196/202] Slices processed 3678.\n",
      "-> [197/202] Slices processed 3697.\n",
      "-> [198/202] Slices processed 3716.\n",
      "-> [199/202] Slices processed 3735.\n",
      "-> [200/202] Slices processed 3754.\n",
      "-> [201/202] Slices processed 3773.\n",
      "-> [202/202] Slices processed 3792.\n"
     ]
    }
   ],
   "source": [
    "X_sagital_train, y_sagital_train = get_slices_per_group_sagital(X_train, y_train)\n",
    "X_sagital_train = X_sagital_train.reshape(-1, X_sagital_train.shape[1], X_sagital_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sagital_test, y_sagital_test = get_slices_per_group_sagital(X_test, y_test)\n",
    "X_sagital_test = X_sagital_test.reshape(-1, X_sagital_train.shape[1], X_sagital_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_sagital_train.shape[0],X_sagital_train.shape[1],X_sagital_train.shape[2],X_sagital_train.shape[3], len(y_sagital_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_sagital_test.shape[0],X_sagital_test.shape[1],X_sagital_test.shape[2],X_sagital_test.shape[3], len(y_sagital_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PURhal9KB7XG"
   },
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "GmsZwEJRpg-t"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PknsV4akB7XG",
    "outputId": "a3b91a1b-36a8-4351-b9e3-466e0bfd7579",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_96 (Conv2D)           (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_98 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 143,667,089\n",
      "Trainable params: 143,667,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBG1DJV4B7XG",
    "outputId": "6511ab56-e480-4dca-f6dc-180ae9486714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_sagital_16012022_1749.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afbB58ZAETXD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3036/3036 [==============================] - 4981s 2s/step - loss: 12.2045 - accuracy: 0.6041 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.57500, saving model to vgg19_sagital_16012022_1749.h5\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 2/50\n",
      "3036/3036 [==============================] - 4972s 2s/step - loss: 0.6718 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 3/50\n",
      "3036/3036 [==============================] - 4754s 2s/step - loss: 0.6720 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 4/50\n",
      "3036/3036 [==============================] - 4567s 2s/step - loss: 0.6720 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 5/50\n",
      "3036/3036 [==============================] - 4571s 2s/step - loss: 0.6719 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 6/50\n",
      "3036/3036 [==============================] - 4559s 2s/step - loss: 0.6720 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 7/50\n",
      "3036/3036 [==============================] - 4555s 2s/step - loss: 0.6711 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 8/50\n",
      "3036/3036 [==============================] - 4570s 2s/step - loss: 0.6706 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 9/50\n",
      "3036/3036 [==============================] - 4555s 2s/step - loss: 0.6715 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 10/50\n",
      "3036/3036 [==============================] - 4548s 1s/step - loss: 0.6714 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 11/50\n",
      "3036/3036 [==============================] - 4552s 1s/step - loss: 0.6711 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 12/50\n",
      "3036/3036 [==============================] - 4829s 2s/step - loss: 0.6710 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 13/50\n",
      "3036/3036 [==============================] - 4996s 2s/step - loss: 0.6717 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 14/50\n",
      "3036/3036 [==============================] - 4964s 2s/step - loss: 0.6714 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 15/50\n",
      "3036/3036 [==============================] - 5200s 2s/step - loss: 0.6713 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 16/50\n",
      "3036/3036 [==============================] - 5106s 2s/step - loss: 0.6715 - accuracy: 0.6057 - val_loss: nan - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.57500\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 17/50\n",
      "2418/3036 [======================>.......] - ETA: 17:14 - loss: 0.6719 - accuracy: 0.6042"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_coronal_train, y_coronal_train, batch_size=1,epochs=50,validation_split=0.2, callbacks=[checkpoint,early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl1Z4kUYHNuR"
   },
   "source": [
    "#EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oFQ-zSoGTni"
   },
   "outputs": [],
   "source": [
    "arr_reshaped = cv2.resize(arr[:, : , 100], (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "arr_reshaped[arr_reshaped < 0] = 0\n",
    "print(arr_reshaped.shape, arr_reshaped.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8Rf70BKGtaSF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr_reshaped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9404/911365263.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marr_reshaped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marr_reshaped\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_reshaped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_reshaped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arr_reshaped' is not defined"
     ]
    }
   ],
   "source": [
    "arr_reshaped[arr_reshaped < 0] = 0\n",
    "print(arr_reshaped.shape, arr_reshaped.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r5QBdyYNHOVD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(arr_reshaped, cmap=\"gray\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25788/1415570555.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBUY_file_paths\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/ESPOL/integradora/images_preprocessed/BUY/*/ex_*.nii.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#68 files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mEAT_file_paths\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/ESPOL/integradora/images_preprocessed/EAT/*/ex_*.nii.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#81files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mGAMBLE_file_paths\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/ESPOL/integradora/images_preprocessed/GAMBLE/*/ex_*.nii.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#7 files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mSEX_file_paths\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"E:/ESPOL/integradora/images_preprocessed/SEX/*/ex_*.nii.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#42 files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "BUY_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/BUY/*/ex_*.nii.gz\"))  #68 files\n",
    "EAT_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/EAT/*/ex_*.nii.gz\")) #81files\n",
    "GAMBLE_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/GAMBLE/*/ex_*.nii.gz\"))  #7 files\n",
    "SEX_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/SEX/*/ex_*.nii.gz\"))  #42 files\n",
    "\n",
    "PD_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/PD/*/ex_*.nii.gz\"))  #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BUY_file_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25788/512374688.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUY_file_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBUY_file_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEAT_file_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEAT_file_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGAMBLE_file_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGAMBLE_file_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSEX_file_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSEX_file_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BUY_file_paths' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(BUY_file_paths), BUY_file_paths[:3])\n",
    "print(len(EAT_file_paths), EAT_file_paths[:3])\n",
    "print(len(GAMBLE_file_paths), GAMBLE_file_paths[:3])\n",
    "print(len(SEX_file_paths), SEX_file_paths[:3])\n",
    "\n",
    "print(len(PD_file_paths), PD_file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BUY_file_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25788/2524329886.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdestiny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"E:/ESPOL/integradora/desorders/PREPROCESSED/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"BUY/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mBUY_file_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestiny\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mid\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".nii.gz\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BUY_file_paths' is not defined"
     ]
    }
   ],
   "source": [
    "destiny = \"E:/ESPOL/integradora/desorders/PREPROCESSED/\" + \"BUY/\"\n",
    "\n",
    "for file in BUY_file_paths:\n",
    "    id = file.split(\"\\\\\")[1]\n",
    "    shutil.copyfile(file, destiny + id + \".nii.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python39\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading The Model\n"
     ]
    }
   ],
   "source": [
    "#Axial assamble\n",
    "\n",
    "batch_size = 10\n",
    "epochs = 1000\n",
    "dropout_rate = 0.2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=X_axial3c_test.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(num_classes, activation=tf.nn.softmax))\n",
    "\n",
    "adam_opt2=Adam(lr = 0.0001, beta_1=0.7, beta_2=0.995, amsgrad=True)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.0001, beta_1=0.7, beta_2=0.995, amsgrad=True),loss=keras.losses.binary_crossentropy,metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"vgg19_axial3c_15022022_01231.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', period=1)\n",
    "model.load_weights('vgg19_axial3c_15022022_01231.h5') #Load Weights\n",
    "print('Loading The Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./vgg19_axial3c_17012022_1741.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(X_test, y_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./PREPROCESSED/EAT\\\\4108.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3819.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3124.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\40693.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3952.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3753.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3633.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3666.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3365.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3530.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3026.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3624.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\4064.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3419.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\3290.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3415.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\42860.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3830.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\3522.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3012.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3002.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\41521.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\51518.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3778.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\73673.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3129.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\41664.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3325.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\3565.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3080.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\55984.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3387.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\56184.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3538.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3589.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3374.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3507.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3322.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3442.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3254.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\50451.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\3068.nii.gz',\n",
       " './PREPROCESSED/EAT\\\\50222.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\70087.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3352.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3122.nii.gz',\n",
       " './PREPROCESSED/PD\\\\3383.nii.gz',\n",
       " './PREPROCESSED/BUY\\\\5011.nii.gz']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9742120343839542\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "\n",
    "predictions = [(0 if i <0.5 else 1) for i in preds]\n",
    "cm = confusion_matrix(y_pred=predictions, y_true=y_test)\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=y_test, y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.99564040e-01],\n",
       "       [8.12378764e-01],\n",
       "       [9.99853730e-01],\n",
       "       [5.04152179e-01],\n",
       "       [7.63765693e-01],\n",
       "       [9.99991357e-01],\n",
       "       [9.99999523e-01],\n",
       "       [9.70557451e-01],\n",
       "       [9.98879433e-01],\n",
       "       [9.93870020e-01],\n",
       "       [9.99813795e-01],\n",
       "       [9.85491812e-01],\n",
       "       [9.33430195e-01],\n",
       "       [9.99078572e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999881e-01],\n",
       "       [1.15221083e-04],\n",
       "       [9.01652098e-01],\n",
       "       [7.20411539e-04],\n",
       "       [2.79992819e-04],\n",
       "       [9.99996781e-01],\n",
       "       [9.97048020e-01],\n",
       "       [5.34687042e-01],\n",
       "       [9.99997258e-01],\n",
       "       [9.98619199e-03],\n",
       "       [9.99942303e-01],\n",
       "       [4.33390737e-01],\n",
       "       [9.99983728e-01],\n",
       "       [7.83111744e-08],\n",
       "       [9.95022655e-01],\n",
       "       [9.98543024e-01],\n",
       "       [9.99680877e-01],\n",
       "       [2.22097933e-02],\n",
       "       [9.25597548e-03],\n",
       "       [9.94977832e-01],\n",
       "       [3.26287882e-05],\n",
       "       [1.26740336e-02],\n",
       "       [9.99996543e-01],\n",
       "       [9.63730097e-01],\n",
       "       [2.29313791e-05],\n",
       "       [2.58830190e-03],\n",
       "       [9.99782383e-01],\n",
       "       [5.90115786e-04],\n",
       "       [8.96175861e-01],\n",
       "       [9.99987483e-01],\n",
       "       [3.35896875e-05],\n",
       "       [9.98246849e-01],\n",
       "       [8.35031271e-04],\n",
       "       [9.93719459e-01],\n",
       "       [9.99941647e-01],\n",
       "       [1.66191902e-37],\n",
       "       [9.99612093e-01],\n",
       "       [9.40210342e-01],\n",
       "       [9.99774456e-01],\n",
       "       [1.67950094e-02],\n",
       "       [9.99930203e-01],\n",
       "       [9.68970120e-01],\n",
       "       [1.12808965e-22],\n",
       "       [9.99341428e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99090374e-01],\n",
       "       [9.99956369e-01],\n",
       "       [9.99989390e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.99999285e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.75562096e-01],\n",
       "       [1.48567557e-02],\n",
       "       [9.99865413e-01],\n",
       "       [9.94004786e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.93841887e-01],\n",
       "       [9.66965914e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99934673e-01],\n",
       "       [9.99999642e-01],\n",
       "       [9.81567919e-01],\n",
       "       [3.06817889e-03],\n",
       "       [9.99224782e-01],\n",
       "       [5.82740977e-05],\n",
       "       [9.95601773e-01],\n",
       "       [9.19370294e-01],\n",
       "       [9.99985218e-01],\n",
       "       [9.99998689e-01],\n",
       "       [9.99953985e-01],\n",
       "       [9.99980509e-01],\n",
       "       [9.99174237e-01],\n",
       "       [9.97736812e-01],\n",
       "       [9.99718606e-01],\n",
       "       [9.99891400e-01],\n",
       "       [7.39952087e-01],\n",
       "       [9.94692922e-01],\n",
       "       [9.99978662e-01],\n",
       "       [9.96457934e-01],\n",
       "       [9.98075485e-01],\n",
       "       [6.29146397e-02],\n",
       "       [9.99995887e-01],\n",
       "       [8.78246427e-01],\n",
       "       [9.16997790e-01],\n",
       "       [9.99948502e-01],\n",
       "       [7.03290284e-01],\n",
       "       [9.99999404e-01],\n",
       "       [9.99989212e-01],\n",
       "       [9.99989331e-01],\n",
       "       [9.83935475e-01],\n",
       "       [9.99996364e-01],\n",
       "       [7.14357793e-02],\n",
       "       [9.99985456e-01],\n",
       "       [2.15492073e-05],\n",
       "       [5.56285795e-06],\n",
       "       [9.99838889e-01],\n",
       "       [9.78666961e-01],\n",
       "       [9.99666929e-01],\n",
       "       [9.99806941e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.99303937e-01],\n",
       "       [9.99996424e-01],\n",
       "       [1.60948675e-05],\n",
       "       [7.18243659e-01],\n",
       "       [9.99992788e-01],\n",
       "       [1.57326940e-05],\n",
       "       [2.49172747e-01],\n",
       "       [9.99784470e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.89439934e-01],\n",
       "       [9.88461733e-01],\n",
       "       [6.24437816e-05],\n",
       "       [9.99972045e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.89684582e-01],\n",
       "       [9.99919116e-01],\n",
       "       [9.95923519e-01],\n",
       "       [9.99726295e-01],\n",
       "       [2.23948973e-05],\n",
       "       [1.74340606e-03],\n",
       "       [9.99941587e-01],\n",
       "       [9.99965072e-01],\n",
       "       [3.77836823e-03],\n",
       "       [6.54995441e-04],\n",
       "       [9.99899209e-01],\n",
       "       [9.98884082e-01],\n",
       "       [9.80005026e-01],\n",
       "       [2.66963452e-05],\n",
       "       [3.52725387e-03],\n",
       "       [8.62248659e-01],\n",
       "       [9.99999642e-01],\n",
       "       [4.51557845e-01],\n",
       "       [3.56344581e-02],\n",
       "       [9.87873793e-01],\n",
       "       [3.08286548e-01],\n",
       "       [9.98510182e-01],\n",
       "       [9.98634696e-01],\n",
       "       [9.99996781e-01],\n",
       "       [9.97443080e-01],\n",
       "       [9.97405171e-01],\n",
       "       [9.97518837e-01],\n",
       "       [9.98678803e-01],\n",
       "       [9.99910116e-01],\n",
       "       [9.99999583e-01],\n",
       "       [7.31527805e-04],\n",
       "       [9.99998093e-01],\n",
       "       [9.99993324e-01],\n",
       "       [9.99957204e-01],\n",
       "       [1.78059936e-03],\n",
       "       [7.81276882e-01],\n",
       "       [1.79871917e-03],\n",
       "       [2.21995622e-01],\n",
       "       [9.98066604e-01],\n",
       "       [9.98202205e-01],\n",
       "       [9.98723984e-01],\n",
       "       [2.79533267e-02],\n",
       "       [9.99982715e-01],\n",
       "       [9.99980092e-01],\n",
       "       [0.00000000e+00],\n",
       "       [1.72781944e-03],\n",
       "       [5.71376040e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99818087e-01],\n",
       "       [8.48137861e-05],\n",
       "       [1.00000000e+00],\n",
       "       [2.46779948e-01],\n",
       "       [9.97646332e-01],\n",
       "       [9.99272406e-01],\n",
       "       [4.59023893e-01],\n",
       "       [5.66181540e-03],\n",
       "       [2.24439645e-09],\n",
       "       [9.98448908e-01],\n",
       "       [2.22444534e-04],\n",
       "       [1.00000000e+00],\n",
       "       [8.30908537e-01],\n",
       "       [5.21716429e-05],\n",
       "       [0.00000000e+00],\n",
       "       [2.18974947e-05],\n",
       "       [4.04788700e-08],\n",
       "       [9.99940991e-01],\n",
       "       [1.72430396e-01],\n",
       "       [2.62340873e-01],\n",
       "       [9.98125315e-01],\n",
       "       [9.99980986e-01],\n",
       "       [9.95426536e-01],\n",
       "       [9.99801636e-01],\n",
       "       [1.93417072e-04],\n",
       "       [9.99994397e-01],\n",
       "       [9.99695063e-01],\n",
       "       [9.99921203e-01],\n",
       "       [9.99934256e-01],\n",
       "       [5.64732909e-01],\n",
       "       [9.54405606e-01],\n",
       "       [9.98740554e-01],\n",
       "       [9.99945045e-01],\n",
       "       [9.97509360e-01],\n",
       "       [1.33335590e-04],\n",
       "       [9.99982595e-01],\n",
       "       [1.31757060e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.98169899e-01],\n",
       "       [9.98194158e-01],\n",
       "       [3.26451591e-05],\n",
       "       [9.99999881e-01],\n",
       "       [9.99348640e-01],\n",
       "       [9.99984741e-01],\n",
       "       [9.99992132e-01],\n",
       "       [9.99883652e-01],\n",
       "       [9.95961070e-01],\n",
       "       [9.99897122e-01],\n",
       "       [1.24809931e-05],\n",
       "       [9.99454260e-01],\n",
       "       [9.34584260e-01],\n",
       "       [9.99998450e-01],\n",
       "       [2.68727541e-04],\n",
       "       [3.17174060e-32],\n",
       "       [9.84082282e-01],\n",
       "       [4.72605228e-04],\n",
       "       [9.99230742e-01],\n",
       "       [9.99729395e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.70617712e-01],\n",
       "       [4.44074601e-01],\n",
       "       [6.34437356e-06],\n",
       "       [9.99999762e-01],\n",
       "       [9.99999642e-01],\n",
       "       [2.41100788e-04],\n",
       "       [3.76220742e-05],\n",
       "       [9.99918222e-01],\n",
       "       [0.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.99899983e-01],\n",
       "       [9.98932183e-01],\n",
       "       [1.61319971e-04],\n",
       "       [9.99974310e-01],\n",
       "       [9.99994040e-01],\n",
       "       [9.99918938e-01],\n",
       "       [4.72477078e-03],\n",
       "       [9.99879956e-01],\n",
       "       [7.11327011e-05],\n",
       "       [9.99999404e-01],\n",
       "       [9.09067392e-01],\n",
       "       [9.98072207e-01],\n",
       "       [4.09055054e-01],\n",
       "       [9.95039999e-01],\n",
       "       [9.89564061e-01],\n",
       "       [3.08286548e-01],\n",
       "       [1.42864719e-05],\n",
       "       [1.93764736e-05],\n",
       "       [9.99993503e-01],\n",
       "       [9.99205351e-01],\n",
       "       [3.20979655e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.87343252e-01],\n",
       "       [1.00398064e-03],\n",
       "       [9.67839122e-01],\n",
       "       [1.06494337e-01],\n",
       "       [1.20025561e-05],\n",
       "       [1.74212456e-03],\n",
       "       [2.04378366e-02],\n",
       "       [2.44051218e-04],\n",
       "       [9.99997258e-01],\n",
       "       [1.00000000e+00],\n",
       "       [4.36043739e-03],\n",
       "       [9.99895930e-01],\n",
       "       [6.42414716e-33],\n",
       "       [9.93712902e-01],\n",
       "       [9.99737144e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99805272e-01],\n",
       "       [9.99978602e-01],\n",
       "       [9.99974430e-01],\n",
       "       [1.44648552e-03],\n",
       "       [9.99996305e-01],\n",
       "       [9.99999762e-01],\n",
       "       [6.36517107e-01],\n",
       "       [1.23858452e-04],\n",
       "       [9.99676824e-01],\n",
       "       [1.16321116e-05],\n",
       "       [1.00000000e+00],\n",
       "       [9.81975079e-01],\n",
       "       [2.96705961e-03],\n",
       "       [2.02243086e-07],\n",
       "       [1.00000000e+00],\n",
       "       [3.29166651e-04],\n",
       "       [9.99406159e-01],\n",
       "       [2.56388456e-01],\n",
       "       [1.01057589e-02],\n",
       "       [9.99883294e-01],\n",
       "       [4.25417966e-07],\n",
       "       [9.99763787e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99992728e-01],\n",
       "       [7.85981536e-01],\n",
       "       [7.79478192e-01],\n",
       "       [9.99973059e-01],\n",
       "       [9.99997139e-01],\n",
       "       [3.19820255e-01],\n",
       "       [9.70080256e-01],\n",
       "       [9.80497539e-01],\n",
       "       [9.99277830e-01],\n",
       "       [4.68845814e-01],\n",
       "       [9.99949098e-01],\n",
       "       [9.98181224e-01],\n",
       "       [7.97742963e-01],\n",
       "       [9.96777177e-01],\n",
       "       [9.99719381e-01],\n",
       "       [9.99945641e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99987721e-01],\n",
       "       [1.46760317e-06],\n",
       "       [9.94747043e-01],\n",
       "       [9.99791443e-01],\n",
       "       [9.99982715e-01],\n",
       "       [9.99954343e-01],\n",
       "       [9.98762965e-01],\n",
       "       [2.42424905e-02],\n",
       "       [0.00000000e+00],\n",
       "       [8.25076699e-02],\n",
       "       [8.28410089e-02],\n",
       "       [1.48211002e-01],\n",
       "       [0.00000000e+00],\n",
       "       [3.81809771e-02],\n",
       "       [9.96623516e-01],\n",
       "       [7.61194533e-05],\n",
       "       [9.99959707e-01],\n",
       "       [9.99993801e-01],\n",
       "       [9.99990940e-01],\n",
       "       [9.99579430e-01],\n",
       "       [9.99895096e-01],\n",
       "       [9.98932183e-01],\n",
       "       [9.99921501e-01],\n",
       "       [2.41074562e-02],\n",
       "       [4.51437414e-01],\n",
       "       [9.99429584e-01],\n",
       "       [9.15928960e-01],\n",
       "       [5.67284226e-03],\n",
       "       [3.98159027e-04],\n",
       "       [9.68921542e-01],\n",
       "       [1.00976288e-01],\n",
       "       [9.93841767e-01],\n",
       "       [6.51800632e-03],\n",
       "       [9.99999046e-01],\n",
       "       [9.99759793e-01],\n",
       "       [1.56371236e-01],\n",
       "       [9.99518514e-01],\n",
       "       [9.91874933e-03],\n",
       "       [9.98447955e-01],\n",
       "       [9.99013543e-01],\n",
       "       [9.91362691e-01],\n",
       "       [1.00000000e+00],\n",
       "       [2.32813254e-05],\n",
       "       [7.29664922e-01],\n",
       "       [1.00000000e+00],\n",
       "       [6.46753397e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.58995390e-04],\n",
       "       [1.21475023e-05],\n",
       "       [9.99999881e-01],\n",
       "       [3.68635535e-01],\n",
       "       [9.99987543e-01],\n",
       "       [9.99997735e-01],\n",
       "       [7.71486998e-01],\n",
       "       [5.59294522e-02],\n",
       "       [9.87258792e-01],\n",
       "       [9.79396462e-01],\n",
       "       [9.99989271e-01],\n",
       "       [9.99940515e-01],\n",
       "       [9.99600530e-01],\n",
       "       [9.99989212e-01],\n",
       "       [1.17396841e-04],\n",
       "       [2.18115620e-05],\n",
       "       [9.70381856e-01],\n",
       "       [5.45106232e-01],\n",
       "       [9.79123950e-01],\n",
       "       [9.94058669e-01],\n",
       "       [9.99963760e-01],\n",
       "       [2.12339759e-02],\n",
       "       [9.99992967e-01],\n",
       "       [9.99992251e-01],\n",
       "       [5.97989559e-01],\n",
       "       [9.99911666e-01],\n",
       "       [9.97964263e-01],\n",
       "       [2.14323103e-02],\n",
       "       [9.99637365e-01],\n",
       "       [1.13740265e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.98507619e-01],\n",
       "       [1.24335289e-04],\n",
       "       [9.99961138e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99929428e-01],\n",
       "       [9.99738336e-01],\n",
       "       [9.97843862e-01],\n",
       "       [9.99510884e-01],\n",
       "       [9.95282590e-01],\n",
       "       [9.96699572e-01],\n",
       "       [1.26740336e-02],\n",
       "       [9.99998569e-01],\n",
       "       [9.99231160e-01],\n",
       "       [1.61329317e-05],\n",
       "       [6.55552367e-06],\n",
       "       [4.12615836e-02],\n",
       "       [1.15674122e-23],\n",
       "       [1.00000000e+00],\n",
       "       [9.22328591e-01],\n",
       "       [9.99976635e-01],\n",
       "       [9.85658765e-01],\n",
       "       [9.62429643e-01],\n",
       "       [9.99996483e-01],\n",
       "       [9.98994589e-01],\n",
       "       [9.99997020e-01],\n",
       "       [9.87408519e-01],\n",
       "       [9.94390845e-01],\n",
       "       [2.71364643e-05],\n",
       "       [9.99988675e-01],\n",
       "       [1.01730227e-03],\n",
       "       [3.24831009e-02],\n",
       "       [9.82930183e-01],\n",
       "       [1.29630004e-22],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999285e-01],\n",
       "       [4.04757150e-15],\n",
       "       [9.99956250e-01],\n",
       "       [1.22487269e-04],\n",
       "       [8.48061827e-05],\n",
       "       [9.94717360e-01],\n",
       "       [3.36536765e-03],\n",
       "       [1.00000000e+00],\n",
       "       [8.08200240e-02],\n",
       "       [9.99448359e-01],\n",
       "       [9.99998748e-01],\n",
       "       [9.96824741e-01],\n",
       "       [9.97714639e-01],\n",
       "       [8.03919673e-01],\n",
       "       [9.18526769e-01],\n",
       "       [5.15021190e-23],\n",
       "       [9.97128487e-01],\n",
       "       [5.98464787e-01],\n",
       "       [3.18557024e-04],\n",
       "       [9.91679788e-01],\n",
       "       [6.19721711e-02],\n",
       "       [9.99910712e-01],\n",
       "       [9.11553741e-01],\n",
       "       [9.98875499e-01],\n",
       "       [6.86287880e-04],\n",
       "       [8.93765926e-01],\n",
       "       [1.00000000e+00],\n",
       "       [3.82207036e-02],\n",
       "       [9.70543146e-01],\n",
       "       [9.99390841e-01],\n",
       "       [9.99630928e-01],\n",
       "       [9.56281722e-01],\n",
       "       [9.73877430e-01],\n",
       "       [5.88160753e-03],\n",
       "       [9.99999702e-01],\n",
       "       [9.98447061e-01],\n",
       "       [9.88148093e-01],\n",
       "       [9.72493291e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.65582013e-01],\n",
       "       [9.99877572e-01],\n",
       "       [9.99746621e-01],\n",
       "       [3.21897460e-07],\n",
       "       [9.99945164e-01],\n",
       "       [4.11121033e-11],\n",
       "       [9.99986172e-01],\n",
       "       [0.00000000e+00],\n",
       "       [9.22646880e-01],\n",
       "       [4.14073467e-04],\n",
       "       [9.99991596e-01],\n",
       "       [9.69697595e-01],\n",
       "       [9.99994636e-01],\n",
       "       [9.88389492e-01],\n",
       "       [9.98925149e-01],\n",
       "       [9.33075353e-05],\n",
       "       [9.74045098e-01],\n",
       "       [9.99981880e-01],\n",
       "       [3.42190266e-02],\n",
       "       [9.99918520e-01],\n",
       "       [8.93619835e-01],\n",
       "       [9.99978304e-01],\n",
       "       [9.99318480e-01],\n",
       "       [9.99999583e-01],\n",
       "       [9.96745229e-02],\n",
       "       [1.00000000e+00],\n",
       "       [2.65309215e-03],\n",
       "       [1.00000000e+00],\n",
       "       [1.00000000e+00],\n",
       "       [9.30948973e-01],\n",
       "       [9.50922072e-01],\n",
       "       [9.89874482e-01],\n",
       "       [1.15093408e-05],\n",
       "       [1.39706399e-05],\n",
       "       [9.99991417e-01],\n",
       "       [4.52829540e-01],\n",
       "       [9.98207927e-01],\n",
       "       [9.99999523e-01],\n",
       "       [1.46151287e-05],\n",
       "       [9.32242274e-01],\n",
       "       [9.99984860e-01],\n",
       "       [9.99999166e-01],\n",
       "       [1.26212835e-04],\n",
       "       [9.93591845e-01],\n",
       "       [3.21835279e-04],\n",
       "       [9.99369025e-01],\n",
       "       [9.99984860e-01],\n",
       "       [6.20938811e-09],\n",
       "       [9.99943495e-01],\n",
       "       [9.99974251e-01],\n",
       "       [8.70500803e-01],\n",
       "       [9.95614648e-01],\n",
       "       [9.99986649e-01],\n",
       "       [9.98996377e-01],\n",
       "       [9.96520996e-01],\n",
       "       [9.99999762e-01],\n",
       "       [9.99999344e-01],\n",
       "       [9.99996662e-01],\n",
       "       [9.99994516e-01],\n",
       "       [1.67489052e-04],\n",
       "       [9.91535664e-01],\n",
       "       [9.99956012e-01],\n",
       "       [9.99432802e-01],\n",
       "       [2.30887651e-01],\n",
       "       [6.29067421e-04],\n",
       "       [9.95632470e-01],\n",
       "       [9.99997020e-01],\n",
       "       [9.99963045e-01],\n",
       "       [9.99999642e-01],\n",
       "       [1.23295188e-03],\n",
       "       [2.18480825e-04],\n",
       "       [9.99978185e-01],\n",
       "       [9.99999225e-01],\n",
       "       [9.99784768e-01],\n",
       "       [9.99868274e-01],\n",
       "       [7.92405009e-03],\n",
       "       [3.35800648e-03],\n",
       "       [1.00000000e+00],\n",
       "       [5.99771738e-04],\n",
       "       [1.24021724e-07],\n",
       "       [9.95019674e-01],\n",
       "       [6.32626598e-06],\n",
       "       [3.51401196e-25],\n",
       "       [7.21877813e-01],\n",
       "       [1.56427043e-20],\n",
       "       [9.99992490e-01],\n",
       "       [1.22024394e-04],\n",
       "       [9.00056303e-01],\n",
       "       [1.54211884e-05],\n",
       "       [9.99987245e-01],\n",
       "       [9.98761058e-01],\n",
       "       [9.89673495e-01],\n",
       "       [4.66368375e-24],\n",
       "       [9.94485378e-01],\n",
       "       [9.99481678e-01],\n",
       "       [9.94315997e-05],\n",
       "       [0.00000000e+00],\n",
       "       [8.48105252e-01],\n",
       "       [9.99763727e-01],\n",
       "       [9.99838710e-01],\n",
       "       [9.99998689e-01],\n",
       "       [9.99573469e-01],\n",
       "       [9.97751176e-01],\n",
       "       [9.99962449e-01],\n",
       "       [9.99997258e-01],\n",
       "       [6.21533181e-05],\n",
       "       [9.99770582e-01],\n",
       "       [4.11003828e-04],\n",
       "       [9.99993324e-01],\n",
       "       [1.76984072e-03],\n",
       "       [9.99998212e-01],\n",
       "       [9.98373091e-01],\n",
       "       [9.91960883e-01],\n",
       "       [1.12784932e-04],\n",
       "       [9.96282935e-01],\n",
       "       [8.20296705e-02],\n",
       "       [9.99906540e-01],\n",
       "       [9.99857128e-01],\n",
       "       [3.39572648e-06],\n",
       "       [1.08726181e-05],\n",
       "       [8.59341681e-01],\n",
       "       [1.80021871e-05],\n",
       "       [2.30818987e-04],\n",
       "       [9.99968410e-01],\n",
       "       [9.99927163e-01],\n",
       "       [9.99901533e-01],\n",
       "       [2.90751457e-04],\n",
       "       [8.18735480e-01],\n",
       "       [9.99991894e-01],\n",
       "       [1.11662149e-02],\n",
       "       [2.16066837e-04],\n",
       "       [0.00000000e+00],\n",
       "       [9.96390820e-01],\n",
       "       [2.26220489e-03],\n",
       "       [8.92670095e-01],\n",
       "       [9.99997258e-01],\n",
       "       [2.00169683e-02],\n",
       "       [9.92543936e-01],\n",
       "       [9.09323633e-01],\n",
       "       [9.99936879e-01],\n",
       "       [5.15100360e-03],\n",
       "       [9.99973655e-01],\n",
       "       [9.99998629e-01],\n",
       "       [7.15759397e-03],\n",
       "       [9.99936521e-01],\n",
       "       [5.68598509e-04],\n",
       "       [9.99909997e-01],\n",
       "       [3.09633911e-01],\n",
       "       [9.99998808e-01],\n",
       "       [9.99228954e-01],\n",
       "       [9.99981046e-01],\n",
       "       [9.99964535e-01],\n",
       "       [9.97060270e-05],\n",
       "       [8.06555836e-05],\n",
       "       [2.50101089e-04],\n",
       "       [2.29179859e-04],\n",
       "       [1.13337745e-04],\n",
       "       [9.99996066e-01],\n",
       "       [9.99986649e-01],\n",
       "       [9.05901194e-04],\n",
       "       [1.00000000e+00],\n",
       "       [1.35891260e-05],\n",
       "       [9.67538017e-06],\n",
       "       [2.18974947e-05],\n",
       "       [9.99492526e-01],\n",
       "       [9.97337580e-01],\n",
       "       [9.83358920e-01],\n",
       "       [9.99839306e-01],\n",
       "       [5.04386425e-03],\n",
       "       [3.76430750e-02],\n",
       "       [5.35219908e-04],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999642e-01],\n",
       "       [9.89683449e-01],\n",
       "       [9.99406278e-01],\n",
       "       [5.16316295e-03],\n",
       "       [9.55241561e-01],\n",
       "       [9.99998987e-01],\n",
       "       [1.45244933e-18],\n",
       "       [4.54297036e-01],\n",
       "       [9.99838293e-01],\n",
       "       [9.99968946e-01],\n",
       "       [9.99998927e-01],\n",
       "       [9.97947931e-01],\n",
       "       [2.73698568e-03],\n",
       "       [9.99971032e-01],\n",
       "       [9.80005026e-01],\n",
       "       [9.96728778e-01],\n",
       "       [1.18155628e-01],\n",
       "       [2.30580568e-04],\n",
       "       [9.98381138e-01],\n",
       "       [9.96233761e-01],\n",
       "       [9.99982476e-01],\n",
       "       [9.99784827e-01],\n",
       "       [3.32564116e-04],\n",
       "       [2.02289224e-03],\n",
       "       [9.99957681e-01],\n",
       "       [7.73316383e-01],\n",
       "       [9.99885201e-01],\n",
       "       [9.99998093e-01],\n",
       "       [9.99918103e-01],\n",
       "       [0.00000000e+00],\n",
       "       [3.95909137e-06],\n",
       "       [9.08630536e-05],\n",
       "       [9.99807239e-01],\n",
       "       [9.99992192e-01],\n",
       "       [9.93133783e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.09888124e-01],\n",
       "       [9.99986172e-01],\n",
       "       [9.99610424e-01],\n",
       "       [7.85981536e-01],\n",
       "       [3.30013037e-03],\n",
       "       [9.99986053e-01],\n",
       "       [0.00000000e+00],\n",
       "       [2.26575136e-03],\n",
       "       [3.50953937e-02],\n",
       "       [9.98559713e-01],\n",
       "       [9.99751925e-01],\n",
       "       [9.99346912e-01],\n",
       "       [2.27367636e-07]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[224  10]\n",
      " [  8 456]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "labels = [\"parkinson + ICD\", 'parkinson']\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.savefig('confusion_marix.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels, title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PvAOESUMZ3vC"
   ],
   "name": "Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5O_u_2VEVaxu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZDM9TeHSpdz"
   },
   "source": [
    "# DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvAOESUMZ3vC"
   },
   "source": [
    "## GET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UEuSwGAuUIDE"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from typing import  List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "M_bEIIkaTMVc"
   },
   "outputs": [],
   "source": [
    "BUY_file_paths =  sorted(glob(\"./SEGMENTED/BUY/*.nii.gz\"))  #68 files\n",
    "EAT_file_paths =  sorted(glob(\"./SEGMENTED/EAT/*.nii.gz\"))  #files\n",
    "GAMBLE_file_paths =  sorted(glob(\"./SEGMENTED/GAMBLE/*.nii.gz\"))  #7 files\n",
    "SEX_file_paths =  sorted(glob(\"./SEGMENTED/SEX/*.nii.gz\"))  #42 files\n",
    "\n",
    "PD_file_paths =  sorted(glob(\"./SEGMENTED/PD/*.nii.gz\"))  #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_file_paths =  sorted(glob(\"./PREPROCESSED/BUY/*.nii.gz\"))  #68 files\n",
    "EAT_file_paths =  sorted(glob(\"./PREPROCESSED/EAT/*.nii.gz\"))  #files\n",
    "GAMBLE_file_paths =  sorted(glob(\"./PREPROCESSED/GAMBLE/*.nii.gz\"))  #7 files\n",
    "SEX_file_paths =  sorted(glob(\"./PREPROCESSED/SEX/*.nii.gz\"))  #42 files\n",
    "\n",
    "PD_file_paths =  sorted(glob(\"./PREPROCESSED/PD/*.nii.gz\"))  #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhjKHY1eUK8T",
    "outputId": "b3e7fe30-d891-486d-d291-af6046269e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "81 ['./PREPROCESSED/EAT\\\\3002.nii.gz', './PREPROCESSED/EAT\\\\3023.nii.gz', './PREPROCESSED/EAT\\\\3062.nii.gz']\n",
      "7 ['./PREPROCESSED/GAMBLE\\\\3536.nii.gz', './PREPROCESSED/GAMBLE\\\\3565.nii.gz', './PREPROCESSED/GAMBLE\\\\3863.nii.gz']\n",
      "22 ['./PREPROCESSED/SEX\\\\3062.nii.gz', './PREPROCESSED/SEX\\\\3068.nii.gz', './PREPROCESSED/SEX\\\\3073.nii.gz']\n",
      "116 ['./PREPROCESSED/PD\\\\3006.nii.gz', './PREPROCESSED/PD\\\\3012.nii.gz', './PREPROCESSED/PD\\\\3014.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(len(BUY_file_paths), BUY_file_paths[:3])\n",
    "print(len(EAT_file_paths), EAT_file_paths[:3])\n",
    "print(len(GAMBLE_file_paths), GAMBLE_file_paths[:3])\n",
    "print(len(SEX_file_paths), SEX_file_paths[:3])\n",
    "\n",
    "print(len(PD_file_paths), PD_file_paths[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIEPs4fyi_Do"
   },
   "source": [
    "## SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "smYhVSm3REZT",
    "outputId": "4e5fb0de-9dbb-4e64-f4ac-07e3dd37abe6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dataset = []\n",
    "y_dataset = []\n",
    "\n",
    "X_dataset.extend(PD_file_paths), y_dataset.extend([1] * len(PD_file_paths))\n",
    "X_dataset.extend(BUY_file_paths), y_dataset.extend([2] * len(BUY_file_paths))\n",
    "X_dataset.extend(EAT_file_paths), y_dataset.extend([3] * len(EAT_file_paths))\n",
    "X_dataset.extend(GAMBLE_file_paths), y_dataset.extend([4] * len(GAMBLE_file_paths))\n",
    "X_dataset.extend(SEX_file_paths), y_dataset.extend([5] * len(SEX_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Uqc7y2bki-jm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, test_size = 0.2, stratify=y_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulHtkPzaYDdz",
    "outputId": "68995ed6-84a9-4e22-c0d2-0326b3d42b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 226 226\n",
      "Train: 180 180\n",
      "Test: 46 46\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset:\", len(X_dataset), len(y_dataset))\n",
    "print(\"Train:\", len(X_train), len(y_train))\n",
    "print(\"Test:\", len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5gQU1FEGLxm"
   },
   "source": [
    "## PREPROSSESING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tmO7ktYZjyzg"
   },
   "outputs": [],
   "source": [
    "def get_category(category, is_binary = True):\n",
    "  result = np.zeros(2 if is_binary else 5)\n",
    "  if is_binary:\n",
    "    return 1 if category == 1 else 0\n",
    "  elif category == 1:\n",
    "    result[0] = 1\n",
    "  else:\n",
    "    result[category-1] = 1\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "dodkXvulaU6J"
   },
   "outputs": [],
   "source": [
    "def get_categories(y_data):\n",
    "  categories = None\n",
    "  is_first = True\n",
    "  for category in y_data:\n",
    "    if is_first:\n",
    "      categories = np.array([get_category(category)])\n",
    "      is_first = False\n",
    "    else:\n",
    "      categories = np.concatenate((categories,[get_category(category)]))\n",
    "  return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVlfjfF3NfXM",
    "outputId": "393185e6-679c-4a30-8782-66dea49fdeec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0. 0. 1.]\n",
      "1 [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(get_category(5, True), get_category(5, False))\n",
    "print(get_category(1, True), get_category(1, False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D All Brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv2\n",
    "\n",
    "dimension = 180\n",
    "def get_slices_3d_all(path, category):\n",
    "    img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    #normalize the matrix, numbers between 0.0 - 1.0\n",
    "    arr = arr / arr.max()\n",
    "    \n",
    "    slice = arr[10:160, : , :]\n",
    "    \n",
    "    arr = np.zeros([150, dimension,dimension])\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i, : , :] = cv2.resize(slice[i, : , :], (dimension, dimension), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    slices = np.array([arr])\n",
    "    slices = slices.reshape(1,arr.shape[0], arr.shape[1], arr.shape[2], 1)\n",
    "    slices_cat = np.array([get_category(category)])\n",
    "    \n",
    "    return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_3d_all(paths, categories):\n",
    "    group = None\n",
    "    group_cat = None\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        try:\n",
    "            if i == 0:\n",
    "                group, group_cat = get_slices_3d_all(path, categories[i])\n",
    "            else:\n",
    "                new_group, new_group_cat = get_slices_3d_all(path, categories[i])\n",
    "                group = np.concatenate((group, new_group))\n",
    "                group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "            print(\"-> [%d/%d] Image processed.\" %(count,len(paths)))\n",
    "            count+=1\n",
    "        except:\n",
    "            print(\"Error in\", path)\n",
    "    return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 150, 180, 180, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_3d_all(X_dataset[11], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/3] Image processed.\n",
      "-> [2/3] Image processed.\n",
      "-> [3/3] Image processed.\n",
      "(3, 150, 180, 180, 1)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "slices, slices_cat = get_slices_per_group_3d_all(X_dataset[:3], y_dataset[:3])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "dimension = 180\n",
    "def get_slices_3d(path, category):\n",
    "    img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "    arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    #normalize the matrix, numbers between 0.0 - 1.0\n",
    "    arr = arr / arr.max()\n",
    "    \n",
    "    slice = arr[27:68, : , :]\n",
    "    \n",
    "    arr = np.zeros([32, dimension,dimension])\n",
    "    \n",
    "    for i in range(arr.shape[0]):\n",
    "        arr[i, : , :] = cv2.resize(slice[i, : , :], (dimension, dimension), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    slices = np.array([arr])\n",
    "    slices = slices.reshape(1,arr.shape[0], arr.shape[1], arr.shape[2], 1)\n",
    "    slices_cat = np.array([get_category(category)])\n",
    "    \n",
    "    return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_3d(paths, categories):\n",
    "    group = None\n",
    "    group_cat = None\n",
    "\n",
    "    count = 1\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        if i == 0:\n",
    "            group, group_cat = get_slices_3d(path, categories[i])\n",
    "        else:\n",
    "            new_group, new_group_cat = get_slices_3d(path, categories[i])\n",
    "            group = np.concatenate((group, new_group))\n",
    "            group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "        print(\"-> [%d/%d] Image processed.\" %(count,len(paths)))\n",
    "        count+=1\n",
    "    return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 180, 180, 1)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_3d(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/3] Image processed.\n",
      "-> [2/3] Image processed.\n",
      "-> [3/3] Image processed.\n",
      "(3, 32, 180, 180, 1)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "slices, slices_cat = get_slices_per_group_3d(X_dataset[:3], y_dataset[:3])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwSGlhsb0Iaw"
   },
   "source": [
    "## AXIAL\n",
    "arr[ xxx , : , : ] axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9cwlnfteXPLb"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "SLICE_NUMBER = 50\n",
    "def get_slices_axial(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[arr.shape[0] - i -1, : , : ]\n",
    "    slice = cv2.resize(slice, (120, 120), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      if count < SLICE_NUMBER:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lQz7bYsHENEt"
   },
   "outputs": [],
   "source": [
    "def get_slices_per_group_axial(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_axial(path, categories[i])\n",
    "    else:\n",
    "      new_group, new_group_cat = get_slices_axial(path, categories[i])\n",
    "      group = np.concatenate((group, new_group))\n",
    "      group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhXSxy0Y1eEp",
    "outputId": "e71253d0-380d-44c8-80d8-d9ed159c0840"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 217, 181)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_axial(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_DZGnMbC13P"
   },
   "source": [
    "## CORONAL\n",
    "arr[ : , xxx , : ] coronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JCnw2xZj_PT7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "# type: the number of the group\n",
    "# group_n: the count of diferent groups\n",
    "# for example,we can have the groups \n",
    "#    1) [EAT, GAMBLE, SEX, BUY, PURE] and the image is from GAMBLE\n",
    "#     -> type = 2\n",
    "#     -> group_n = 5\n",
    "#    2) or [PURE, ICD] and the image is from PURE\n",
    "#     -> type = 1\n",
    "#     -> group_n = 2\n",
    "#output:\n",
    "#     -> normalized array of the slices \n",
    "#     -> the category of each image in one-hot encoded.\n",
    "# for example\n",
    "#   1) [0,1,0,0,0], and \n",
    "#   2) [1,0]\n",
    "def get_slices_coronal(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[:, i , : ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9-LKeV1d_PT-"
   },
   "outputs": [],
   "source": [
    "def get_slices_per_group_coronal(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_coronal(path, categories[i])\n",
    "    else:\n",
    "      new_group, new_group_cat = get_slices_coronal(path, categories[i])\n",
    "      group = np.concatenate((group, new_group))\n",
    "      group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eE7lOFb_PT_",
    "outputId": "6209c074-fd58-4e2e-d6e5-64602a10d748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 224, 224)\n",
      "(67,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_coronal(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3ERsrLfC87J"
   },
   "source": [
    "## SAGITAL\n",
    "arr[ : , : , xxx ] sagital "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# type: the number of the group\n",
    "# group_n: the count of diferent groups\n",
    "# for example,we can have the groups \n",
    "#    1) [EAT, GAMBLE, SEX, BUY, PURE] and the image is from GAMBLE\n",
    "#     -> type = 2\n",
    "#     -> group_n = 5\n",
    "#    2) or [PURE, ICD] and the image is from PURE\n",
    "#     -> type = 1\n",
    "#     -> group_n = 2\n",
    "#output:\n",
    "#     -> normalized array of the slices \n",
    "#     -> the category of each image in one-hot encoded.\n",
    "# for example\n",
    "#   1) [0,1,0,0,0], and \n",
    "#   2) [1,0]\n",
    "def get_slices_sagital(path, category):\n",
    "  img = sitk.ReadImage(path, sitk.sitkFloat64)\n",
    "  arr = sitk.GetArrayFromImage(img)\n",
    "\n",
    "  #normalize the matrix, numbers between 0.0 - 1.0\n",
    "  arr = arr / arr.max()\n",
    "\n",
    "  slices = None\n",
    "  slices_cat = None\n",
    "  count = 0\n",
    "\n",
    "  for i in range(arr.shape[0]):\n",
    "    slice = arr[:, : , i ]\n",
    "    slice = cv2.resize(slice, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    slice[slice < 0] = 0\n",
    "    if slice.max() != 0:\n",
    "      if count == 0:\n",
    "        slices = np.array([slice])\n",
    "        slices_cat = np.array([get_category(category)])\n",
    "      else:\n",
    "        slices = np.concatenate((slices,[slice]))\n",
    "        slices_cat = np.concatenate((slices_cat,[get_category(category)]))\n",
    "      count+=1\n",
    "  #print(\"->\", count , \"slices of\", arr.shape[0], \"where used for image\", path)\n",
    "  return slices, slices_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slices_per_group_sagital(paths, categories):\n",
    "  group = None\n",
    "  group_cat = None\n",
    "\n",
    "  count = 1\n",
    "  for i in range(len(paths)):\n",
    "    path = paths[i]\n",
    "    if i == 0:\n",
    "      group, group_cat = get_slices_sagital(path, categories[i])\n",
    "    else:\n",
    "      new_group, new_group_cat = get_slices_sagital(path, categories[i])\n",
    "      group = np.concatenate((group, new_group))\n",
    "      group_cat = np.concatenate((group_cat, new_group_cat))\n",
    "\n",
    "    print(\"-> [%d/%d] Slices processed %d.\" %(count,len(paths), group.shape[0] ))\n",
    "    count+=1\n",
    "  return group, group_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 224, 224)\n",
      "(120,)\n"
     ]
    }
   ],
   "source": [
    "#test with one image\n",
    "slices, slices_cat = get_slices_sagital(X_dataset[0], y_dataset[0])\n",
    "print(slices.shape)\n",
    "print(slices_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNzzq4hUs2ww"
   },
   "source": [
    "# MODEL (BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D all brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/180] Image processed.\n",
      "-> [2/180] Image processed.\n",
      "-> [3/180] Image processed.\n",
      "-> [4/180] Image processed.\n",
      "-> [5/180] Image processed.\n",
      "-> [6/180] Image processed.\n",
      "-> [7/180] Image processed.\n",
      "-> [8/180] Image processed.\n",
      "-> [9/180] Image processed.\n",
      "-> [10/180] Image processed.\n",
      "-> [11/180] Image processed.\n",
      "-> [12/180] Image processed.\n",
      "-> [13/180] Image processed.\n",
      "-> [14/180] Image processed.\n",
      "-> [15/180] Image processed.\n",
      "-> [16/180] Image processed.\n",
      "-> [17/180] Image processed.\n",
      "-> [18/180] Image processed.\n",
      "-> [19/180] Image processed.\n",
      "-> [20/180] Image processed.\n",
      "-> [21/180] Image processed.\n",
      "-> [22/180] Image processed.\n",
      "-> [23/180] Image processed.\n",
      "-> [24/180] Image processed.\n",
      "-> [25/180] Image processed.\n",
      "-> [26/180] Image processed.\n",
      "-> [27/180] Image processed.\n",
      "-> [28/180] Image processed.\n",
      "-> [29/180] Image processed.\n",
      "-> [30/180] Image processed.\n",
      "Error in ./PREPROCESSED/EAT\\3222.nii.gz\n",
      "-> [31/180] Image processed.\n",
      "-> [32/180] Image processed.\n",
      "-> [33/180] Image processed.\n",
      "-> [34/180] Image processed.\n",
      "-> [35/180] Image processed.\n",
      "-> [36/180] Image processed.\n",
      "-> [37/180] Image processed.\n",
      "-> [38/180] Image processed.\n",
      "-> [39/180] Image processed.\n",
      "-> [40/180] Image processed.\n",
      "-> [41/180] Image processed.\n",
      "-> [42/180] Image processed.\n",
      "-> [43/180] Image processed.\n",
      "-> [44/180] Image processed.\n",
      "-> [45/180] Image processed.\n",
      "-> [46/180] Image processed.\n",
      "-> [47/180] Image processed.\n",
      "-> [48/180] Image processed.\n",
      "-> [49/180] Image processed.\n",
      "-> [50/180] Image processed.\n",
      "-> [51/180] Image processed.\n",
      "-> [52/180] Image processed.\n",
      "-> [53/180] Image processed.\n",
      "-> [54/180] Image processed.\n",
      "-> [55/180] Image processed.\n",
      "-> [56/180] Image processed.\n",
      "-> [57/180] Image processed.\n",
      "-> [58/180] Image processed.\n",
      "-> [59/180] Image processed.\n",
      "-> [60/180] Image processed.\n",
      "-> [61/180] Image processed.\n",
      "-> [62/180] Image processed.\n",
      "-> [63/180] Image processed.\n",
      "-> [64/180] Image processed.\n",
      "-> [65/180] Image processed.\n",
      "-> [66/180] Image processed.\n",
      "-> [67/180] Image processed.\n",
      "-> [68/180] Image processed.\n",
      "-> [69/180] Image processed.\n",
      "-> [70/180] Image processed.\n",
      "-> [71/180] Image processed.\n",
      "-> [72/180] Image processed.\n",
      "-> [73/180] Image processed.\n",
      "-> [74/180] Image processed.\n",
      "-> [75/180] Image processed.\n",
      "-> [76/180] Image processed.\n",
      "-> [77/180] Image processed.\n",
      "-> [78/180] Image processed.\n",
      "-> [79/180] Image processed.\n",
      "-> [80/180] Image processed.\n",
      "-> [81/180] Image processed.\n",
      "-> [82/180] Image processed.\n",
      "-> [83/180] Image processed.\n",
      "-> [84/180] Image processed.\n",
      "-> [85/180] Image processed.\n",
      "-> [86/180] Image processed.\n",
      "-> [87/180] Image processed.\n",
      "Error in ./PREPROCESSED/EAT\\59503.nii.gz\n",
      "-> [88/180] Image processed.\n",
      "Error in ./PREPROCESSED/SEX\\71880.nii.gz\n",
      "-> [89/180] Image processed.\n",
      "Error in ./PREPROCESSED/PD\\3021.nii.gz\n",
      "Error in ./PREPROCESSED/EAT\\50451.nii.gz\n",
      "-> [90/180] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_all_train, y_3d_all_train = get_slices_per_group_3d_all(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d_all_test, y_3d_all_test = get_slices_per_group_3d(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\",X_3d_train.shape, len(y_3d_train))\n",
    "print(\"Test:\",X_3d_test.shape, len(y_3d_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 150, 180, 180, 20) 560       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 150, 180, 180, 64) 34624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 180, 180, 64) 0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 75, 90, 90, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 75, 90, 90, 128)   221312    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 75, 90, 90, 128)   442496    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 90, 90, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 37, 45, 45, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 37, 45, 45, 256)   884992    \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 37, 45, 45, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 37, 45, 45, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 37, 45, 45, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 45, 45, 256)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 18, 22, 22, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 18, 22, 22, 512)   3539456   \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 18, 22, 22, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 18, 22, 22, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 18, 22, 22, 512)   7078400   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 18, 22, 22, 512)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 9, 11, 11, 512)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 9, 11, 11, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 9, 11, 11, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 9, 11, 11, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 9, 11, 11, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 9, 11, 11, 512)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 4, 5, 5, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              209719296 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 290,580,033\n",
      "Trainable params: 290,580,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(input_shape=(150,180,180,1),filters=20,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/241] Image processed.\n",
      "-> [2/241] Image processed.\n",
      "-> [3/241] Image processed.\n",
      "-> [4/241] Image processed.\n",
      "-> [5/241] Image processed.\n",
      "-> [6/241] Image processed.\n",
      "-> [7/241] Image processed.\n",
      "-> [8/241] Image processed.\n",
      "-> [9/241] Image processed.\n",
      "-> [10/241] Image processed.\n",
      "-> [11/241] Image processed.\n",
      "-> [12/241] Image processed.\n",
      "-> [13/241] Image processed.\n",
      "-> [14/241] Image processed.\n",
      "-> [15/241] Image processed.\n",
      "-> [16/241] Image processed.\n",
      "-> [17/241] Image processed.\n",
      "-> [18/241] Image processed.\n",
      "-> [19/241] Image processed.\n",
      "-> [20/241] Image processed.\n",
      "-> [21/241] Image processed.\n",
      "-> [22/241] Image processed.\n",
      "-> [23/241] Image processed.\n",
      "-> [24/241] Image processed.\n",
      "-> [25/241] Image processed.\n",
      "-> [26/241] Image processed.\n",
      "-> [27/241] Image processed.\n",
      "-> [28/241] Image processed.\n",
      "-> [29/241] Image processed.\n",
      "-> [30/241] Image processed.\n",
      "-> [31/241] Image processed.\n",
      "-> [32/241] Image processed.\n",
      "-> [33/241] Image processed.\n",
      "-> [34/241] Image processed.\n",
      "-> [35/241] Image processed.\n",
      "-> [36/241] Image processed.\n",
      "-> [37/241] Image processed.\n",
      "-> [38/241] Image processed.\n",
      "-> [39/241] Image processed.\n",
      "-> [40/241] Image processed.\n",
      "-> [41/241] Image processed.\n",
      "-> [42/241] Image processed.\n",
      "-> [43/241] Image processed.\n",
      "-> [44/241] Image processed.\n",
      "-> [45/241] Image processed.\n",
      "-> [46/241] Image processed.\n",
      "-> [47/241] Image processed.\n",
      "-> [48/241] Image processed.\n",
      "-> [49/241] Image processed.\n",
      "-> [50/241] Image processed.\n",
      "-> [51/241] Image processed.\n",
      "-> [52/241] Image processed.\n",
      "-> [53/241] Image processed.\n",
      "-> [54/241] Image processed.\n",
      "-> [55/241] Image processed.\n",
      "-> [56/241] Image processed.\n",
      "-> [57/241] Image processed.\n",
      "-> [58/241] Image processed.\n",
      "-> [59/241] Image processed.\n",
      "-> [60/241] Image processed.\n",
      "-> [61/241] Image processed.\n",
      "-> [62/241] Image processed.\n",
      "-> [63/241] Image processed.\n",
      "-> [64/241] Image processed.\n",
      "-> [65/241] Image processed.\n",
      "-> [66/241] Image processed.\n",
      "-> [67/241] Image processed.\n",
      "-> [68/241] Image processed.\n",
      "-> [69/241] Image processed.\n",
      "-> [70/241] Image processed.\n",
      "-> [71/241] Image processed.\n",
      "-> [72/241] Image processed.\n",
      "-> [73/241] Image processed.\n",
      "-> [74/241] Image processed.\n",
      "-> [75/241] Image processed.\n",
      "-> [76/241] Image processed.\n",
      "-> [77/241] Image processed.\n",
      "-> [78/241] Image processed.\n",
      "-> [79/241] Image processed.\n",
      "-> [80/241] Image processed.\n",
      "-> [81/241] Image processed.\n",
      "-> [82/241] Image processed.\n",
      "-> [83/241] Image processed.\n",
      "-> [84/241] Image processed.\n",
      "-> [85/241] Image processed.\n",
      "-> [86/241] Image processed.\n",
      "-> [87/241] Image processed.\n",
      "-> [88/241] Image processed.\n",
      "-> [89/241] Image processed.\n",
      "-> [90/241] Image processed.\n",
      "-> [91/241] Image processed.\n",
      "-> [92/241] Image processed.\n",
      "-> [93/241] Image processed.\n",
      "-> [94/241] Image processed.\n",
      "-> [95/241] Image processed.\n",
      "-> [96/241] Image processed.\n",
      "-> [97/241] Image processed.\n",
      "-> [98/241] Image processed.\n",
      "-> [99/241] Image processed.\n",
      "-> [100/241] Image processed.\n",
      "-> [101/241] Image processed.\n",
      "-> [102/241] Image processed.\n",
      "-> [103/241] Image processed.\n",
      "-> [104/241] Image processed.\n",
      "-> [105/241] Image processed.\n",
      "-> [106/241] Image processed.\n",
      "-> [107/241] Image processed.\n",
      "-> [108/241] Image processed.\n",
      "-> [109/241] Image processed.\n",
      "-> [110/241] Image processed.\n",
      "-> [111/241] Image processed.\n",
      "-> [112/241] Image processed.\n",
      "-> [113/241] Image processed.\n",
      "-> [114/241] Image processed.\n",
      "-> [115/241] Image processed.\n",
      "-> [116/241] Image processed.\n",
      "-> [117/241] Image processed.\n",
      "-> [118/241] Image processed.\n",
      "-> [119/241] Image processed.\n",
      "-> [120/241] Image processed.\n",
      "-> [121/241] Image processed.\n",
      "-> [122/241] Image processed.\n",
      "-> [123/241] Image processed.\n",
      "-> [124/241] Image processed.\n",
      "-> [125/241] Image processed.\n",
      "-> [126/241] Image processed.\n",
      "-> [127/241] Image processed.\n",
      "-> [128/241] Image processed.\n",
      "-> [129/241] Image processed.\n",
      "-> [130/241] Image processed.\n",
      "-> [131/241] Image processed.\n",
      "-> [132/241] Image processed.\n",
      "-> [133/241] Image processed.\n",
      "-> [134/241] Image processed.\n",
      "-> [135/241] Image processed.\n",
      "-> [136/241] Image processed.\n",
      "-> [137/241] Image processed.\n",
      "-> [138/241] Image processed.\n",
      "-> [139/241] Image processed.\n",
      "-> [140/241] Image processed.\n",
      "-> [141/241] Image processed.\n",
      "-> [142/241] Image processed.\n",
      "-> [143/241] Image processed.\n",
      "-> [144/241] Image processed.\n",
      "-> [145/241] Image processed.\n",
      "-> [146/241] Image processed.\n",
      "-> [147/241] Image processed.\n",
      "-> [148/241] Image processed.\n",
      "-> [149/241] Image processed.\n",
      "-> [150/241] Image processed.\n",
      "-> [151/241] Image processed.\n",
      "-> [152/241] Image processed.\n",
      "-> [153/241] Image processed.\n",
      "-> [154/241] Image processed.\n",
      "-> [155/241] Image processed.\n",
      "-> [156/241] Image processed.\n",
      "-> [157/241] Image processed.\n",
      "-> [158/241] Image processed.\n",
      "-> [159/241] Image processed.\n",
      "-> [160/241] Image processed.\n",
      "-> [161/241] Image processed.\n",
      "-> [162/241] Image processed.\n",
      "-> [163/241] Image processed.\n",
      "-> [164/241] Image processed.\n",
      "-> [165/241] Image processed.\n",
      "-> [166/241] Image processed.\n",
      "-> [167/241] Image processed.\n",
      "-> [168/241] Image processed.\n",
      "-> [169/241] Image processed.\n",
      "-> [170/241] Image processed.\n",
      "-> [171/241] Image processed.\n",
      "-> [172/241] Image processed.\n",
      "-> [173/241] Image processed.\n",
      "-> [174/241] Image processed.\n",
      "-> [175/241] Image processed.\n",
      "-> [176/241] Image processed.\n",
      "-> [177/241] Image processed.\n",
      "-> [178/241] Image processed.\n",
      "-> [179/241] Image processed.\n",
      "-> [180/241] Image processed.\n",
      "-> [181/241] Image processed.\n",
      "-> [182/241] Image processed.\n",
      "-> [183/241] Image processed.\n",
      "-> [184/241] Image processed.\n",
      "-> [185/241] Image processed.\n",
      "-> [186/241] Image processed.\n",
      "-> [187/241] Image processed.\n",
      "-> [188/241] Image processed.\n",
      "-> [189/241] Image processed.\n",
      "-> [190/241] Image processed.\n",
      "-> [191/241] Image processed.\n",
      "-> [192/241] Image processed.\n",
      "-> [193/241] Image processed.\n",
      "-> [194/241] Image processed.\n",
      "-> [195/241] Image processed.\n",
      "-> [196/241] Image processed.\n",
      "-> [197/241] Image processed.\n",
      "-> [198/241] Image processed.\n",
      "-> [199/241] Image processed.\n",
      "-> [200/241] Image processed.\n",
      "-> [201/241] Image processed.\n",
      "-> [202/241] Image processed.\n",
      "-> [203/241] Image processed.\n",
      "-> [204/241] Image processed.\n",
      "-> [205/241] Image processed.\n",
      "-> [206/241] Image processed.\n",
      "-> [207/241] Image processed.\n",
      "-> [208/241] Image processed.\n",
      "-> [209/241] Image processed.\n",
      "-> [210/241] Image processed.\n",
      "-> [211/241] Image processed.\n",
      "-> [212/241] Image processed.\n",
      "-> [213/241] Image processed.\n",
      "-> [214/241] Image processed.\n",
      "-> [215/241] Image processed.\n",
      "-> [216/241] Image processed.\n",
      "-> [217/241] Image processed.\n",
      "-> [218/241] Image processed.\n",
      "-> [219/241] Image processed.\n",
      "-> [220/241] Image processed.\n",
      "-> [221/241] Image processed.\n",
      "-> [222/241] Image processed.\n",
      "-> [223/241] Image processed.\n",
      "-> [224/241] Image processed.\n",
      "-> [225/241] Image processed.\n",
      "-> [226/241] Image processed.\n",
      "-> [227/241] Image processed.\n",
      "-> [228/241] Image processed.\n",
      "-> [229/241] Image processed.\n",
      "-> [230/241] Image processed.\n",
      "-> [231/241] Image processed.\n",
      "-> [232/241] Image processed.\n",
      "-> [233/241] Image processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_12260/2852190984.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [234/241] Image processed.\n",
      "-> [235/241] Image processed.\n",
      "-> [236/241] Image processed.\n",
      "-> [237/241] Image processed.\n",
      "-> [238/241] Image processed.\n",
      "-> [239/241] Image processed.\n",
      "-> [240/241] Image processed.\n",
      "-> [241/241] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_train, y_3d_train = get_slices_per_group_3d(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/61] Image processed.\n",
      "-> [2/61] Image processed.\n",
      "-> [3/61] Image processed.\n",
      "-> [4/61] Image processed.\n",
      "-> [5/61] Image processed.\n",
      "-> [6/61] Image processed.\n",
      "-> [7/61] Image processed.\n",
      "-> [8/61] Image processed.\n",
      "-> [9/61] Image processed.\n",
      "-> [10/61] Image processed.\n",
      "-> [11/61] Image processed.\n",
      "-> [12/61] Image processed.\n",
      "-> [13/61] Image processed.\n",
      "-> [14/61] Image processed.\n",
      "-> [15/61] Image processed.\n",
      "-> [16/61] Image processed.\n",
      "-> [17/61] Image processed.\n",
      "-> [18/61] Image processed.\n",
      "-> [19/61] Image processed.\n",
      "-> [20/61] Image processed.\n",
      "-> [21/61] Image processed.\n",
      "-> [22/61] Image processed.\n",
      "-> [23/61] Image processed.\n",
      "-> [24/61] Image processed.\n",
      "-> [25/61] Image processed.\n",
      "-> [26/61] Image processed.\n",
      "-> [27/61] Image processed.\n",
      "-> [28/61] Image processed.\n",
      "-> [29/61] Image processed.\n",
      "-> [30/61] Image processed.\n",
      "-> [31/61] Image processed.\n",
      "-> [32/61] Image processed.\n",
      "-> [33/61] Image processed.\n",
      "-> [34/61] Image processed.\n",
      "-> [35/61] Image processed.\n",
      "-> [36/61] Image processed.\n",
      "-> [37/61] Image processed.\n",
      "-> [38/61] Image processed.\n",
      "-> [39/61] Image processed.\n",
      "-> [40/61] Image processed.\n",
      "-> [41/61] Image processed.\n",
      "-> [42/61] Image processed.\n",
      "-> [43/61] Image processed.\n",
      "-> [44/61] Image processed.\n",
      "-> [45/61] Image processed.\n",
      "-> [46/61] Image processed.\n",
      "-> [47/61] Image processed.\n",
      "-> [48/61] Image processed.\n",
      "-> [49/61] Image processed.\n",
      "-> [50/61] Image processed.\n",
      "-> [51/61] Image processed.\n",
      "-> [52/61] Image processed.\n",
      "-> [53/61] Image processed.\n",
      "-> [54/61] Image processed.\n",
      "-> [55/61] Image processed.\n",
      "-> [56/61] Image processed.\n",
      "-> [57/61] Image processed.\n",
      "-> [58/61] Image processed.\n",
      "-> [59/61] Image processed.\n",
      "-> [60/61] Image processed.\n",
      "-> [61/61] Image processed.\n"
     ]
    }
   ],
   "source": [
    "X_3d_test, y_3d_test = get_slices_per_group_3d(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (241, 32, 180, 180, 1) 241\n",
      "Test: (61, 32, 180, 180, 1) 61\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\",X_3d_train.shape, len(y_3d_train))\n",
    "print(\"Test:\",X_3d_test.shape, len(y_3d_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, MaxPool3D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 32, 120, 120, 20)  560       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 32, 120, 120, 64)  34624     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 120, 120, 64)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (None, 16, 60, 60, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 16, 60, 60, 128)   221312    \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 16, 60, 60, 128)   442496    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 60, 60, 128)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 8, 30, 30, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 8, 30, 30, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 8, 30, 30, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 8, 30, 30, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 8, 30, 30, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 30, 30, 256)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 15, 15, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 4, 15, 15, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 4, 15, 15, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 4, 15, 15, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 4, 15, 15, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 15, 15, 512)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_13 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 3, 3, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              18878464  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 99,739,201\n",
      "Trainable params: 99,739,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(input_shape=(32,120,120,1),filters=20,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=64,kernel_size=3,padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv3D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_3d.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 32, 120, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32, 120, 120, 1), dtype=tf.float32, name='conv3d_input'), name='conv3d_input', description=\"created by layer 'conv3d_input'\"), but it was called on an input with incompatible shape (None, 32, 180, 180, 1).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\sequential.py:369 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\functional.py:414 call\n        return self._run_internal_graph(\n    c:\\python39\\lib\\site-packages\\keras\\engine\\functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 4608 but received input with shape (None, 12800)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12260/3070450791.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_3d_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_3d_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\python39\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\sequential.py:369 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\functional.py:414 call\n        return self._run_internal_graph(\n    c:\\python39\\lib\\site-packages\\keras\\engine\\functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    c:\\python39\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 4608 but received input with shape (None, 12800)\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_3d_train, y_3d_train, batch_size=10,epochs=10,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.savefig('3d_graph_13122021.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./vgg19_3d.h5\")\n",
    "test_results = model.evaluate(X_3d_test, y_3d_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTMlHtqbcTsm"
   },
   "source": [
    "## AXIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6KuVpJFev4t",
    "outputId": "c6f3ceb6-6a1b-437d-c93e-14c47265bf01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/241] Slices processed 31.\n",
      "-> [2/241] Slices processed 62.\n",
      "-> [3/241] Slices processed 90.\n",
      "-> [4/241] Slices processed 119.\n",
      "-> [5/241] Slices processed 149.\n",
      "-> [6/241] Slices processed 180.\n",
      "-> [7/241] Slices processed 205.\n",
      "-> [8/241] Slices processed 236.\n",
      "-> [9/241] Slices processed 262.\n",
      "-> [10/241] Slices processed 290.\n",
      "-> [11/241] Slices processed 321.\n",
      "-> [12/241] Slices processed 352.\n",
      "-> [13/241] Slices processed 383.\n",
      "-> [14/241] Slices processed 414.\n",
      "-> [15/241] Slices processed 444.\n",
      "-> [16/241] Slices processed 472.\n",
      "-> [17/241] Slices processed 503.\n",
      "-> [18/241] Slices processed 534.\n",
      "-> [19/241] Slices processed 564.\n",
      "-> [20/241] Slices processed 594.\n",
      "-> [21/241] Slices processed 625.\n",
      "-> [22/241] Slices processed 656.\n",
      "-> [23/241] Slices processed 683.\n",
      "-> [24/241] Slices processed 713.\n",
      "-> [25/241] Slices processed 743.\n",
      "-> [26/241] Slices processed 774.\n",
      "-> [27/241] Slices processed 804.\n",
      "-> [28/241] Slices processed 832.\n",
      "-> [29/241] Slices processed 863.\n",
      "-> [30/241] Slices processed 891.\n",
      "-> [31/241] Slices processed 921.\n",
      "-> [32/241] Slices processed 952.\n",
      "-> [33/241] Slices processed 978.\n",
      "-> [34/241] Slices processed 1009.\n",
      "-> [35/241] Slices processed 1039.\n",
      "-> [36/241] Slices processed 1070.\n",
      "-> [37/241] Slices processed 1099.\n",
      "-> [38/241] Slices processed 1130.\n",
      "-> [39/241] Slices processed 1159.\n",
      "-> [40/241] Slices processed 1188.\n",
      "-> [41/241] Slices processed 1218.\n",
      "-> [42/241] Slices processed 1246.\n",
      "-> [43/241] Slices processed 1271.\n",
      "-> [44/241] Slices processed 1302.\n",
      "-> [45/241] Slices processed 1332.\n",
      "-> [46/241] Slices processed 1363.\n",
      "-> [47/241] Slices processed 1394.\n",
      "-> [48/241] Slices processed 1424.\n",
      "-> [49/241] Slices processed 1450.\n",
      "-> [50/241] Slices processed 1480.\n",
      "-> [51/241] Slices processed 1510.\n",
      "-> [52/241] Slices processed 1541.\n",
      "-> [53/241] Slices processed 1571.\n",
      "-> [54/241] Slices processed 1599.\n",
      "-> [55/241] Slices processed 1628.\n",
      "-> [56/241] Slices processed 1657.\n",
      "-> [57/241] Slices processed 1686.\n",
      "-> [58/241] Slices processed 1712.\n",
      "-> [59/241] Slices processed 1743.\n",
      "-> [60/241] Slices processed 1772.\n",
      "-> [61/241] Slices processed 1802.\n",
      "-> [62/241] Slices processed 1831.\n",
      "-> [63/241] Slices processed 1862.\n",
      "-> [64/241] Slices processed 1890.\n",
      "-> [65/241] Slices processed 1921.\n",
      "-> [66/241] Slices processed 1952.\n",
      "-> [67/241] Slices processed 1980.\n",
      "-> [68/241] Slices processed 2011.\n",
      "-> [69/241] Slices processed 2042.\n",
      "-> [70/241] Slices processed 2071.\n",
      "-> [71/241] Slices processed 2102.\n",
      "-> [72/241] Slices processed 2128.\n",
      "-> [73/241] Slices processed 2155.\n",
      "-> [74/241] Slices processed 2182.\n",
      "-> [75/241] Slices processed 2213.\n",
      "-> [76/241] Slices processed 2242.\n",
      "-> [77/241] Slices processed 2270.\n",
      "-> [78/241] Slices processed 2301.\n",
      "-> [79/241] Slices processed 2331.\n",
      "-> [80/241] Slices processed 2356.\n",
      "-> [81/241] Slices processed 2384.\n",
      "-> [82/241] Slices processed 2415.\n",
      "-> [83/241] Slices processed 2443.\n",
      "-> [84/241] Slices processed 2473.\n",
      "-> [85/241] Slices processed 2501.\n",
      "-> [86/241] Slices processed 2527.\n",
      "-> [87/241] Slices processed 2555.\n",
      "-> [88/241] Slices processed 2584.\n",
      "-> [89/241] Slices processed 2613.\n",
      "-> [90/241] Slices processed 2643.\n",
      "-> [91/241] Slices processed 2674.\n",
      "-> [92/241] Slices processed 2705.\n",
      "-> [93/241] Slices processed 2735.\n",
      "-> [94/241] Slices processed 2764.\n",
      "-> [95/241] Slices processed 2795.\n",
      "-> [96/241] Slices processed 2826.\n",
      "-> [97/241] Slices processed 2857.\n",
      "-> [98/241] Slices processed 2885.\n",
      "-> [99/241] Slices processed 2915.\n",
      "-> [100/241] Slices processed 2940.\n",
      "-> [101/241] Slices processed 2969.\n",
      "-> [102/241] Slices processed 2995.\n",
      "-> [103/241] Slices processed 3026.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_11436/2714929318.py:9: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [104/241] Slices processed 3077.\n",
      "-> [105/241] Slices processed 3101.\n",
      "-> [106/241] Slices processed 3131.\n",
      "-> [107/241] Slices processed 3160.\n",
      "-> [108/241] Slices processed 3191.\n",
      "-> [109/241] Slices processed 3222.\n",
      "-> [110/241] Slices processed 3253.\n",
      "-> [111/241] Slices processed 3284.\n",
      "-> [112/241] Slices processed 3312.\n",
      "-> [113/241] Slices processed 3343.\n",
      "-> [114/241] Slices processed 3369.\n",
      "-> [115/241] Slices processed 3397.\n",
      "-> [116/241] Slices processed 3427.\n",
      "-> [117/241] Slices processed 3457.\n",
      "-> [118/241] Slices processed 3488.\n",
      "-> [119/241] Slices processed 3519.\n",
      "-> [120/241] Slices processed 3548.\n",
      "-> [121/241] Slices processed 3577.\n",
      "-> [122/241] Slices processed 3584.\n",
      "-> [123/241] Slices processed 3615.\n",
      "-> [124/241] Slices processed 3639.\n",
      "-> [125/241] Slices processed 3667.\n",
      "-> [126/241] Slices processed 3693.\n",
      "-> [127/241] Slices processed 3718.\n",
      "-> [128/241] Slices processed 3741.\n",
      "-> [129/241] Slices processed 3769.\n",
      "-> [130/241] Slices processed 3800.\n",
      "-> [131/241] Slices processed 3828.\n",
      "-> [132/241] Slices processed 3858.\n",
      "-> [133/241] Slices processed 3883.\n",
      "-> [134/241] Slices processed 3912.\n",
      "-> [135/241] Slices processed 3942.\n",
      "-> [136/241] Slices processed 3969.\n",
      "-> [137/241] Slices processed 3998.\n",
      "-> [138/241] Slices processed 4029.\n",
      "-> [139/241] Slices processed 4057.\n",
      "-> [140/241] Slices processed 4088.\n",
      "-> [141/241] Slices processed 4116.\n",
      "-> [142/241] Slices processed 4143.\n",
      "-> [143/241] Slices processed 4172.\n",
      "-> [144/241] Slices processed 4199.\n",
      "-> [145/241] Slices processed 4227.\n",
      "-> [146/241] Slices processed 4256.\n",
      "-> [147/241] Slices processed 4286.\n",
      "-> [148/241] Slices processed 4317.\n",
      "-> [149/241] Slices processed 4346.\n",
      "-> [150/241] Slices processed 4374.\n",
      "-> [151/241] Slices processed 4403.\n",
      "-> [152/241] Slices processed 4431.\n",
      "-> [153/241] Slices processed 4459.\n",
      "-> [154/241] Slices processed 4484.\n",
      "-> [155/241] Slices processed 4511.\n",
      "-> [156/241] Slices processed 4536.\n",
      "-> [157/241] Slices processed 4564.\n",
      "-> [158/241] Slices processed 4583.\n",
      "-> [159/241] Slices processed 4612.\n",
      "-> [160/241] Slices processed 4643.\n",
      "-> [161/241] Slices processed 4674.\n",
      "-> [162/241] Slices processed 4705.\n",
      "-> [163/241] Slices processed 4732.\n",
      "-> [164/241] Slices processed 4763.\n",
      "-> [165/241] Slices processed 4794.\n",
      "-> [166/241] Slices processed 4820.\n",
      "-> [167/241] Slices processed 4851.\n",
      "-> [168/241] Slices processed 4879.\n",
      "-> [169/241] Slices processed 4907.\n",
      "-> [170/241] Slices processed 4938.\n",
      "-> [171/241] Slices processed 4969.\n",
      "-> [172/241] Slices processed 5000.\n",
      "-> [173/241] Slices processed 5023.\n",
      "-> [174/241] Slices processed 5054.\n",
      "-> [175/241] Slices processed 5085.\n",
      "-> [176/241] Slices processed 5115.\n",
      "-> [177/241] Slices processed 5141.\n",
      "-> [178/241] Slices processed 5172.\n",
      "-> [179/241] Slices processed 5198.\n",
      "-> [180/241] Slices processed 5228.\n",
      "-> [181/241] Slices processed 5249.\n",
      "-> [182/241] Slices processed 5280.\n",
      "-> [183/241] Slices processed 5311.\n",
      "-> [184/241] Slices processed 5331.\n",
      "-> [185/241] Slices processed 5360.\n",
      "-> [186/241] Slices processed 5389.\n",
      "-> [187/241] Slices processed 5419.\n",
      "-> [188/241] Slices processed 5447.\n",
      "-> [189/241] Slices processed 5478.\n",
      "-> [190/241] Slices processed 5509.\n",
      "-> [191/241] Slices processed 5540.\n",
      "-> [192/241] Slices processed 5568.\n",
      "-> [193/241] Slices processed 5594.\n",
      "-> [194/241] Slices processed 5625.\n",
      "-> [195/241] Slices processed 5653.\n",
      "-> [196/241] Slices processed 5680.\n",
      "-> [197/241] Slices processed 5711.\n",
      "-> [198/241] Slices processed 5737.\n",
      "-> [199/241] Slices processed 5766.\n",
      "-> [200/241] Slices processed 5796.\n",
      "-> [201/241] Slices processed 5824.\n",
      "-> [202/241] Slices processed 5854.\n",
      "-> [203/241] Slices processed 5885.\n",
      "-> [204/241] Slices processed 5913.\n",
      "-> [205/241] Slices processed 5939.\n",
      "-> [206/241] Slices processed 5970.\n",
      "-> [207/241] Slices processed 6000.\n",
      "-> [208/241] Slices processed 6031.\n",
      "-> [209/241] Slices processed 6060.\n",
      "-> [210/241] Slices processed 6087.\n",
      "-> [211/241] Slices processed 6118.\n",
      "-> [212/241] Slices processed 6149.\n",
      "-> [213/241] Slices processed 6151.\n",
      "-> [214/241] Slices processed 6181.\n",
      "-> [215/241] Slices processed 6212.\n",
      "-> [216/241] Slices processed 6243.\n",
      "-> [217/241] Slices processed 6274.\n",
      "-> [218/241] Slices processed 6305.\n",
      "-> [219/241] Slices processed 6336.\n",
      "-> [220/241] Slices processed 6367.\n",
      "-> [221/241] Slices processed 6395.\n",
      "-> [222/241] Slices processed 6426.\n",
      "-> [223/241] Slices processed 6457.\n",
      "-> [224/241] Slices processed 6488.\n",
      "-> [225/241] Slices processed 6519.\n",
      "-> [226/241] Slices processed 6548.\n",
      "-> [227/241] Slices processed 6576.\n",
      "-> [228/241] Slices processed 6605.\n",
      "-> [229/241] Slices processed 6636.\n",
      "-> [230/241] Slices processed 6666.\n",
      "-> [231/241] Slices processed 6695.\n",
      "-> [232/241] Slices processed 6724.\n",
      "-> [233/241] Slices processed 6751.\n",
      "-> [234/241] Slices processed 6777.\n",
      "-> [235/241] Slices processed 6807.\n",
      "-> [236/241] Slices processed 6838.\n",
      "-> [237/241] Slices processed 6869.\n",
      "-> [238/241] Slices processed 6898.\n",
      "-> [239/241] Slices processed 6927.\n",
      "-> [240/241] Slices processed 6958.\n",
      "-> [241/241] Slices processed 6984.\n",
      "-> [1/61] Slices processed 28.\n",
      "-> [2/61] Slices processed 59.\n",
      "-> [3/61] Slices processed 90.\n",
      "-> [4/61] Slices processed 120.\n",
      "-> [5/61] Slices processed 151.\n",
      "-> [6/61] Slices processed 181.\n",
      "-> [7/61] Slices processed 212.\n",
      "-> [8/61] Slices processed 243.\n",
      "-> [9/61] Slices processed 268.\n",
      "-> [10/61] Slices processed 296.\n",
      "-> [11/61] Slices processed 324.\n",
      "-> [12/61] Slices processed 350.\n",
      "-> [13/61] Slices processed 381.\n",
      "-> [14/61] Slices processed 406.\n",
      "-> [15/61] Slices processed 434.\n",
      "-> [16/61] Slices processed 464.\n",
      "-> [17/61] Slices processed 492.\n",
      "-> [18/61] Slices processed 517.\n",
      "-> [19/61] Slices processed 547.\n",
      "-> [20/61] Slices processed 575.\n",
      "-> [21/61] Slices processed 606.\n",
      "-> [22/61] Slices processed 637.\n",
      "-> [23/61] Slices processed 665.\n",
      "-> [24/61] Slices processed 694.\n",
      "-> [25/61] Slices processed 725.\n",
      "-> [26/61] Slices processed 756.\n",
      "-> [27/61] Slices processed 785.\n",
      "-> [28/61] Slices processed 812.\n",
      "-> [29/61] Slices processed 843.\n",
      "-> [30/61] Slices processed 872.\n",
      "-> [31/61] Slices processed 901.\n",
      "-> [32/61] Slices processed 932.\n",
      "-> [33/61] Slices processed 963.\n",
      "-> [34/61] Slices processed 993.\n",
      "-> [35/61] Slices processed 1024.\n",
      "-> [36/61] Slices processed 1055.\n",
      "-> [37/61] Slices processed 1085.\n",
      "-> [38/61] Slices processed 1116.\n",
      "-> [39/61] Slices processed 1147.\n",
      "-> [40/61] Slices processed 1174.\n",
      "-> [41/61] Slices processed 1205.\n",
      "-> [42/61] Slices processed 1236.\n",
      "-> [43/61] Slices processed 1265.\n",
      "-> [44/61] Slices processed 1296.\n",
      "-> [45/61] Slices processed 1323.\n",
      "-> [46/61] Slices processed 1352.\n",
      "-> [47/61] Slices processed 1383.\n",
      "-> [48/61] Slices processed 1411.\n",
      "-> [49/61] Slices processed 1442.\n",
      "-> [50/61] Slices processed 1472.\n",
      "-> [51/61] Slices processed 1503.\n",
      "-> [52/61] Slices processed 1534.\n",
      "-> [53/61] Slices processed 1564.\n",
      "-> [54/61] Slices processed 1595.\n",
      "-> [55/61] Slices processed 1624.\n",
      "-> [56/61] Slices processed 1655.\n",
      "-> [57/61] Slices processed 1683.\n",
      "-> [58/61] Slices processed 1711.\n",
      "-> [59/61] Slices processed 1740.\n",
      "-> [60/61] Slices processed 1764.\n",
      "-> [61/61] Slices processed 1793.\n"
     ]
    }
   ],
   "source": [
    "X_axial_train, y_axial_train = get_slices_per_group_axial(X_train, y_train)\n",
    "X_axial_train = X_axial_train.reshape(-1, X_axial_train.shape[1], X_axial_train.shape[2], 1)\n",
    "\n",
    "X_axial_test, y_axial_test = get_slices_per_group_axial(X_test, y_test)\n",
    "X_axial_test = X_axial_test.reshape(-1, X_axial_train.shape[1], X_axial_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-36EzPmfjyA",
    "outputId": "e17efeb8-62c4-49ef-8446-1ec8863ff0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X:(6984, 120, 120, 1), y: 6984\n",
      "Test: X:(1793, 120, 120, 1), y: 1793\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_axial_train.shape[0],X_axial_train.shape[1],X_axial_train.shape[2],X_axial_train.shape[3], len(y_axial_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_axial_test.shape[0],X_axial_test.shape[1],X_axial_test.shape[2],X_axial_test.shape[3], len(y_axial_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265.5600960734453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import cv2\n",
    "\n",
    "i= 1\n",
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(X_axial_train[i, : , :, 0], cmap=\"gray\")\n",
    "print(X_axial_train[i, : , :, 0].sum())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7bK3grjmDsh"
   },
   "source": [
    "###VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "GmsZwEJRpg-t"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7Y7XVr5bl5MU",
    "outputId": "18ce578d-5d08-4ce3-f8cc-aad0bd5b537b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 120, 120, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 120, 120, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 120, 120, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 60, 60, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 60, 60, 128)       147584    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 60, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 30, 30, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 30, 30, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              18878464  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 59,781,009\n",
      "Trainable params: 59,781,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(120,120,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-ixtI5Tpsv0",
    "outputId": "07ba67f2-d3ea-4cd9-8074-212236f6b3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_30slices.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "559/559 [==============================] - 1667s 3s/step - loss: nan - accuracy: 0.6526 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67860, saving model to vgg19_30slices.h5\n",
      "Epoch 2/30\n",
      "559/559 [==============================] - 1719s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67860\n",
      "Epoch 3/30\n",
      "559/559 [==============================] - 1660s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67860\n",
      "Epoch 4/30\n",
      "559/559 [==============================] - 1666s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.67860\n",
      "Epoch 5/30\n",
      "559/559 [==============================] - 1662s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.67860\n",
      "Epoch 6/30\n",
      "559/559 [==============================] - 1661s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.67860\n",
      "Epoch 7/30\n",
      "559/559 [==============================] - 1662s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.67860\n",
      "Epoch 8/30\n",
      "559/559 [==============================] - 1666s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.67860\n",
      "Epoch 9/30\n",
      "559/559 [==============================] - 1657s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67860\n",
      "Epoch 10/30\n",
      "559/559 [==============================] - 1638s 3s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67860\n",
      "Epoch 11/30\n",
      "559/559 [==============================] - 3098s 6s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67860\n",
      "Epoch 12/30\n",
      "559/559 [==============================] - 2992s 5s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67860\n",
      "Epoch 13/30\n",
      "559/559 [==============================] - 2213s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67860\n",
      "Epoch 14/30\n",
      "559/559 [==============================] - 2076s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67860\n",
      "Epoch 15/30\n",
      "559/559 [==============================] - 2036s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67860\n",
      "Epoch 16/30\n",
      "559/559 [==============================] - 2036s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67860\n",
      "Epoch 17/30\n",
      "559/559 [==============================] - 2040s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67860\n",
      "Epoch 18/30\n",
      "559/559 [==============================] - 2058s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67860\n",
      "Epoch 19/30\n",
      "559/559 [==============================] - 2077s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67860\n",
      "Epoch 20/30\n",
      "559/559 [==============================] - 2085s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67860\n",
      "Epoch 21/30\n",
      "559/559 [==============================] - 2079s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67860\n",
      "Epoch 22/30\n",
      "559/559 [==============================] - 2149s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67860\n",
      "Epoch 23/30\n",
      "559/559 [==============================] - 2119s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67860\n",
      "Epoch 24/30\n",
      "559/559 [==============================] - 2115s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67860\n",
      "Epoch 25/30\n",
      "559/559 [==============================] - 2105s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.67860\n",
      "Epoch 26/30\n",
      "559/559 [==============================] - 2120s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.67860\n",
      "Epoch 27/30\n",
      "559/559 [==============================] - 2111s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.67860\n",
      "Epoch 28/30\n",
      "559/559 [==============================] - 2117s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.67860\n",
      "Epoch 29/30\n",
      "559/559 [==============================] - 2120s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.67860\n",
      "Epoch 30/30\n",
      "559/559 [==============================] - 2100s 4s/step - loss: nan - accuracy: 0.6603 - val_loss: nan - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.67860\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_axial_train, y_axial_train, batch_size=10,epochs=30,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "seDApqQk5FtY",
    "outputId": "fc45785c-eb2f-465f-eef0-94b3ffe8452c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 112s 2s/step - loss: nan - accuracy: 0.6642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.664249837398529]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = model.evaluate(X_axial_test, y_axial_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJxGks6FB7W8"
   },
   "source": [
    "# CORONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9C4njiq6B7XG",
    "outputId": "4a93da83-0133-4de3-c371-91d13555ce4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/173] Slices processed 67.\n",
      "-> [2/173] Slices processed 134.\n",
      "-> [3/173] Slices processed 160.\n",
      "-> [4/173] Slices processed 227.\n",
      "-> [5/173] Slices processed 294.\n",
      "-> [6/173] Slices processed 361.\n",
      "-> [7/173] Slices processed 428.\n",
      "-> [8/173] Slices processed 495.\n",
      "-> [9/173] Slices processed 562.\n",
      "-> [10/173] Slices processed 629.\n",
      "-> [11/173] Slices processed 696.\n",
      "-> [12/173] Slices processed 763.\n",
      "-> [13/173] Slices processed 830.\n",
      "-> [14/173] Slices processed 897.\n",
      "-> [15/173] Slices processed 964.\n",
      "-> [16/173] Slices processed 1031.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\Temp/ipykernel_22212/1790016269.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr = arr / arr.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [17/173] Slices processed 1212.\n",
      "-> [18/173] Slices processed 1279.\n",
      "-> [19/173] Slices processed 1346.\n",
      "-> [20/173] Slices processed 1413.\n",
      "-> [21/173] Slices processed 1480.\n",
      "-> [22/173] Slices processed 1547.\n",
      "-> [23/173] Slices processed 1570.\n",
      "-> [24/173] Slices processed 1637.\n",
      "-> [25/173] Slices processed 1704.\n",
      "-> [26/173] Slices processed 1771.\n",
      "-> [27/173] Slices processed 1838.\n",
      "-> [28/173] Slices processed 1905.\n",
      "-> [29/173] Slices processed 1972.\n",
      "-> [30/173] Slices processed 2039.\n",
      "-> [31/173] Slices processed 2106.\n",
      "-> [32/173] Slices processed 2173.\n",
      "-> [33/173] Slices processed 2240.\n",
      "-> [34/173] Slices processed 2307.\n",
      "-> [35/173] Slices processed 2374.\n",
      "-> [36/173] Slices processed 2441.\n",
      "-> [37/173] Slices processed 2508.\n",
      "-> [38/173] Slices processed 2575.\n",
      "-> [39/173] Slices processed 2642.\n",
      "-> [40/173] Slices processed 2709.\n",
      "-> [41/173] Slices processed 2776.\n",
      "-> [42/173] Slices processed 2843.\n",
      "-> [43/173] Slices processed 2910.\n",
      "-> [44/173] Slices processed 2977.\n",
      "-> [45/173] Slices processed 3044.\n",
      "-> [46/173] Slices processed 3111.\n",
      "-> [47/173] Slices processed 3178.\n",
      "-> [48/173] Slices processed 3245.\n",
      "-> [49/173] Slices processed 3312.\n",
      "-> [50/173] Slices processed 3379.\n",
      "-> [51/173] Slices processed 3446.\n",
      "-> [52/173] Slices processed 3449.\n",
      "-> [53/173] Slices processed 3516.\n",
      "-> [54/173] Slices processed 3583.\n",
      "-> [55/173] Slices processed 3650.\n",
      "-> [56/173] Slices processed 3717.\n",
      "-> [57/173] Slices processed 3784.\n",
      "-> [58/173] Slices processed 3851.\n",
      "-> [59/173] Slices processed 3918.\n",
      "-> [60/173] Slices processed 3985.\n",
      "-> [61/173] Slices processed 4052.\n",
      "-> [62/173] Slices processed 4119.\n",
      "-> [63/173] Slices processed 4186.\n",
      "-> [64/173] Slices processed 4253.\n",
      "-> [65/173] Slices processed 4320.\n",
      "-> [66/173] Slices processed 4387.\n",
      "-> [67/173] Slices processed 4454.\n",
      "-> [68/173] Slices processed 4521.\n",
      "-> [69/173] Slices processed 4588.\n",
      "-> [70/173] Slices processed 4655.\n",
      "-> [71/173] Slices processed 4722.\n",
      "-> [72/173] Slices processed 4789.\n",
      "-> [73/173] Slices processed 4856.\n",
      "-> [74/173] Slices processed 4923.\n",
      "-> [75/173] Slices processed 4990.\n",
      "-> [76/173] Slices processed 5057.\n",
      "-> [77/173] Slices processed 5124.\n",
      "-> [78/173] Slices processed 5191.\n",
      "-> [79/173] Slices processed 5258.\n",
      "-> [80/173] Slices processed 5325.\n",
      "-> [81/173] Slices processed 5392.\n",
      "-> [82/173] Slices processed 5459.\n",
      "-> [83/173] Slices processed 5526.\n",
      "-> [84/173] Slices processed 5593.\n",
      "-> [85/173] Slices processed 5660.\n",
      "-> [86/173] Slices processed 5727.\n",
      "-> [87/173] Slices processed 5794.\n",
      "-> [88/173] Slices processed 5861.\n",
      "-> [89/173] Slices processed 5928.\n",
      "-> [90/173] Slices processed 5995.\n",
      "-> [91/173] Slices processed 6062.\n",
      "-> [92/173] Slices processed 6129.\n",
      "-> [93/173] Slices processed 6196.\n",
      "-> [94/173] Slices processed 6263.\n",
      "-> [95/173] Slices processed 6330.\n",
      "-> [96/173] Slices processed 6397.\n",
      "-> [97/173] Slices processed 6464.\n",
      "-> [98/173] Slices processed 6531.\n",
      "-> [99/173] Slices processed 6598.\n",
      "-> [100/173] Slices processed 6665.\n",
      "-> [101/173] Slices processed 6732.\n",
      "-> [102/173] Slices processed 6799.\n",
      "-> [103/173] Slices processed 6866.\n",
      "-> [104/173] Slices processed 6933.\n",
      "-> [105/173] Slices processed 7000.\n",
      "-> [106/173] Slices processed 7067.\n",
      "-> [107/173] Slices processed 7134.\n",
      "-> [108/173] Slices processed 7201.\n",
      "-> [109/173] Slices processed 7268.\n",
      "-> [110/173] Slices processed 7335.\n",
      "-> [111/173] Slices processed 7402.\n",
      "-> [112/173] Slices processed 7469.\n",
      "-> [113/173] Slices processed 7536.\n",
      "-> [114/173] Slices processed 7603.\n",
      "-> [115/173] Slices processed 7670.\n",
      "-> [116/173] Slices processed 7737.\n",
      "-> [117/173] Slices processed 7804.\n",
      "-> [118/173] Slices processed 7871.\n",
      "-> [119/173] Slices processed 7938.\n",
      "-> [120/173] Slices processed 8005.\n",
      "-> [121/173] Slices processed 8072.\n",
      "-> [122/173] Slices processed 8139.\n",
      "-> [123/173] Slices processed 8206.\n",
      "-> [124/173] Slices processed 8273.\n",
      "-> [125/173] Slices processed 8340.\n",
      "-> [126/173] Slices processed 8407.\n",
      "-> [127/173] Slices processed 8474.\n",
      "-> [128/173] Slices processed 8541.\n",
      "-> [129/173] Slices processed 8608.\n",
      "-> [130/173] Slices processed 8675.\n",
      "-> [131/173] Slices processed 8742.\n",
      "-> [132/173] Slices processed 8809.\n",
      "-> [133/173] Slices processed 8876.\n",
      "-> [134/173] Slices processed 8943.\n",
      "-> [135/173] Slices processed 9010.\n",
      "-> [136/173] Slices processed 9077.\n",
      "-> [137/173] Slices processed 9144.\n",
      "-> [138/173] Slices processed 9211.\n",
      "-> [139/173] Slices processed 9278.\n",
      "-> [140/173] Slices processed 9345.\n",
      "-> [141/173] Slices processed 9412.\n",
      "-> [142/173] Slices processed 9479.\n",
      "-> [143/173] Slices processed 9546.\n",
      "-> [144/173] Slices processed 9613.\n",
      "-> [145/173] Slices processed 9680.\n",
      "-> [146/173] Slices processed 9747.\n",
      "-> [147/173] Slices processed 9814.\n",
      "-> [148/173] Slices processed 9881.\n",
      "-> [149/173] Slices processed 9948.\n",
      "-> [150/173] Slices processed 10015.\n",
      "-> [151/173] Slices processed 10082.\n",
      "-> [152/173] Slices processed 10149.\n",
      "-> [153/173] Slices processed 10216.\n",
      "-> [154/173] Slices processed 10283.\n",
      "-> [155/173] Slices processed 10350.\n",
      "-> [156/173] Slices processed 10417.\n",
      "-> [157/173] Slices processed 10484.\n",
      "-> [158/173] Slices processed 10551.\n",
      "-> [159/173] Slices processed 10618.\n",
      "-> [160/173] Slices processed 10685.\n",
      "-> [161/173] Slices processed 10752.\n",
      "-> [162/173] Slices processed 10819.\n",
      "-> [163/173] Slices processed 10886.\n",
      "-> [164/173] Slices processed 10953.\n",
      "-> [165/173] Slices processed 11020.\n",
      "-> [166/173] Slices processed 11087.\n",
      "-> [167/173] Slices processed 11154.\n",
      "-> [168/173] Slices processed 11221.\n",
      "-> [169/173] Slices processed 11288.\n",
      "-> [170/173] Slices processed 11355.\n",
      "-> [171/173] Slices processed 11422.\n",
      "-> [172/173] Slices processed 11489.\n",
      "-> [173/173] Slices processed 11556.\n"
     ]
    }
   ],
   "source": [
    "X_coronal_train, y_coronal_train = get_slices_per_group_coronal(X_train, y_train)\n",
    "X_coronal_train = X_coronal_train.reshape(-1, X_coronal_train.shape[1], X_coronal_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QMncXN8hITS-",
    "outputId": "12c8b938-1747-4d6d-e030-acb66e2990f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/44] Slices processed 67.\n",
      "-> [2/44] Slices processed 134.\n",
      "-> [3/44] Slices processed 198.\n",
      "-> [4/44] Slices processed 265.\n",
      "-> [5/44] Slices processed 332.\n",
      "-> [6/44] Slices processed 399.\n",
      "-> [7/44] Slices processed 466.\n",
      "-> [8/44] Slices processed 533.\n",
      "-> [9/44] Slices processed 600.\n",
      "-> [10/44] Slices processed 667.\n",
      "-> [11/44] Slices processed 734.\n",
      "-> [12/44] Slices processed 801.\n",
      "-> [13/44] Slices processed 868.\n",
      "-> [14/44] Slices processed 935.\n",
      "-> [15/44] Slices processed 1002.\n",
      "-> [16/44] Slices processed 1069.\n",
      "-> [17/44] Slices processed 1136.\n",
      "-> [18/44] Slices processed 1203.\n",
      "-> [19/44] Slices processed 1270.\n",
      "-> [20/44] Slices processed 1337.\n",
      "-> [21/44] Slices processed 1404.\n",
      "-> [22/44] Slices processed 1471.\n",
      "-> [23/44] Slices processed 1538.\n",
      "-> [24/44] Slices processed 1605.\n",
      "-> [25/44] Slices processed 1672.\n",
      "-> [26/44] Slices processed 1739.\n",
      "-> [27/44] Slices processed 1806.\n",
      "-> [28/44] Slices processed 1873.\n",
      "-> [29/44] Slices processed 1940.\n",
      "-> [30/44] Slices processed 2007.\n",
      "-> [31/44] Slices processed 2074.\n",
      "-> [32/44] Slices processed 2141.\n",
      "-> [33/44] Slices processed 2208.\n",
      "-> [34/44] Slices processed 2275.\n",
      "-> [35/44] Slices processed 2342.\n",
      "-> [36/44] Slices processed 2409.\n",
      "-> [37/44] Slices processed 2476.\n",
      "-> [38/44] Slices processed 2543.\n",
      "-> [39/44] Slices processed 2610.\n",
      "-> [40/44] Slices processed 2677.\n",
      "-> [41/44] Slices processed 2744.\n",
      "-> [42/44] Slices processed 2811.\n",
      "-> [43/44] Slices processed 2878.\n",
      "-> [44/44] Slices processed 2945.\n"
     ]
    }
   ],
   "source": [
    "X_coronal_test, y_coronal_test = get_slices_per_group_coronal(X_test, y_test)\n",
    "X_coronal_test = X_coronal_test.reshape(-1, X_coronal_train.shape[1], X_coronal_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viljIspWB7XG",
    "outputId": "fd32e79d-f158-463e-8507-4ffd28f3a3bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X:(11556, 224, 224, 1), y: 11556\n",
      "Test: X:(2945, 224, 224, 1), y: 2945\n"
     ]
    }
   ],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_coronal_train.shape[0],X_coronal_train.shape[1],X_coronal_train.shape[2],X_coronal_train.shape[3], len(y_coronal_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_coronal_test.shape[0],X_coronal_test.shape[1],X_coronal_test.shape[2],X_coronal_test.shape[3], len(y_coronal_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PURhal9KB7XG"
   },
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "O5ckKc9YB7XG"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import imageio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PknsV4akB7XG",
    "outputId": "a3b91a1b-36a8-4351-b9e3-466e0bfd7579",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 224, 224, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 1001      \n",
      "=================================================================\n",
      "Total params: 143,667,089\n",
      "Trainable params: 143,667,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#Dense layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBG1DJV4B7XG",
    "outputId": "6511ab56-e480-4dca-f6dc-180ae9486714"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"vgg19_coronal.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#fit_generator(steps_per_epoch=1,generator=traindata, validation_data= testdata, validation_steps=1,epochs=50,callbacks=[checkpoint])\n",
    "# hist = model.fit(traindata, testdata, batch_size=10, epochs=20, verbose=0, shuffle=True,validation_split=0.2,callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "afbB58ZAETXD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "928/928 [==============================] - 8392s 9s/step - loss: nan - accuracy: 0.5174 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62457, saving model to vgg19_coronal.h5\n",
      "Epoch 2/50\n",
      "928/928 [==============================] - 8386s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62457\n",
      "Epoch 3/50\n",
      "928/928 [==============================] - 8388s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62457\n",
      "Epoch 4/50\n",
      "928/928 [==============================] - 8408s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62457\n",
      "Epoch 5/50\n",
      "928/928 [==============================] - 8387s 9s/step - loss: nan - accuracy: 0.5164 - val_loss: nan - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62457\n",
      "Epoch 6/50\n",
      "928/928 [==============================] - ETA: 0s - loss: nan - accuracy: 0.5164"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_coronal_train, y_coronal_train, batch_size=10,epochs=50,validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2nzYIb4B7XG"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history[\"accuracy\"])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 561s 6s/step - loss: 0.6890 - accuracy: 0.4540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6889810562133789, 0.45398980379104614]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./vgg19_coronal.h5\")\n",
    "test_results = model.evaluate(X_coronal_test, y_coronal_test)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sagital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> [1/173] Slices processed 112.\n",
      "-> [2/173] Slices processed 228.\n",
      "-> [3/173] Slices processed 338.\n",
      "-> [4/173] Slices processed 452.\n",
      "-> [5/173] Slices processed 565.\n",
      "-> [6/173] Slices processed 679.\n",
      "-> [7/173] Slices processed 789.\n",
      "-> [8/173] Slices processed 900.\n",
      "-> [9/173] Slices processed 1011.\n",
      "-> [10/173] Slices processed 1126.\n",
      "-> [11/173] Slices processed 1249.\n",
      "-> [12/173] Slices processed 1364.\n",
      "-> [13/173] Slices processed 1476.\n",
      "-> [14/173] Slices processed 1590.\n",
      "-> [15/173] Slices processed 1710.\n",
      "-> [16/173] Slices processed 1821.\n",
      "-> [17/173] Slices processed 1934.\n",
      "-> [18/173] Slices processed 2049.\n",
      "-> [19/173] Slices processed 2155.\n",
      "-> [20/173] Slices processed 2266.\n",
      "-> [21/173] Slices processed 2379.\n",
      "-> [22/173] Slices processed 2493.\n",
      "-> [23/173] Slices processed 2609.\n",
      "-> [24/173] Slices processed 2724.\n",
      "-> [25/173] Slices processed 2843.\n",
      "-> [26/173] Slices processed 2957.\n",
      "-> [27/173] Slices processed 3072.\n",
      "-> [28/173] Slices processed 3187.\n",
      "-> [29/173] Slices processed 3298.\n",
      "-> [30/173] Slices processed 3413.\n",
      "-> [31/173] Slices processed 3529.\n",
      "-> [32/173] Slices processed 3646.\n",
      "-> [33/173] Slices processed 3766.\n",
      "-> [34/173] Slices processed 3872.\n",
      "-> [35/173] Slices processed 3994.\n",
      "-> [36/173] Slices processed 4106.\n",
      "-> [37/173] Slices processed 4179.\n",
      "-> [38/173] Slices processed 4287.\n",
      "-> [39/173] Slices processed 4411.\n",
      "-> [40/173] Slices processed 4525.\n",
      "-> [41/173] Slices processed 4633.\n",
      "-> [42/173] Slices processed 4746.\n",
      "-> [43/173] Slices processed 4866.\n",
      "-> [44/173] Slices processed 4978.\n",
      "-> [45/173] Slices processed 5086.\n",
      "-> [46/173] Slices processed 5206.\n",
      "-> [47/173] Slices processed 5322.\n",
      "-> [48/173] Slices processed 5430.\n",
      "-> [49/173] Slices processed 5549.\n",
      "-> [50/173] Slices processed 5664.\n",
      "-> [51/173] Slices processed 5780.\n",
      "-> [52/173] Slices processed 5896.\n",
      "-> [53/173] Slices processed 6013.\n",
      "-> [54/173] Slices processed 6128.\n",
      "-> [55/173] Slices processed 6248.\n",
      "-> [56/173] Slices processed 6362.\n",
      "-> [57/173] Slices processed 6480.\n",
      "-> [58/173] Slices processed 6593.\n",
      "-> [59/173] Slices processed 6704.\n",
      "-> [60/173] Slices processed 6821.\n",
      "-> [61/173] Slices processed 6939.\n",
      "-> [62/173] Slices processed 7045.\n",
      "-> [63/173] Slices processed 7152.\n",
      "-> [64/173] Slices processed 7258.\n",
      "-> [65/173] Slices processed 7373.\n",
      "-> [66/173] Slices processed 7490.\n",
      "-> [67/173] Slices processed 7599.\n",
      "-> [68/173] Slices processed 7716.\n",
      "-> [69/173] Slices processed 7829.\n",
      "-> [70/173] Slices processed 7934.\n",
      "-> [71/173] Slices processed 8049.\n",
      "-> [72/173] Slices processed 8156.\n",
      "-> [73/173] Slices processed 8270.\n",
      "-> [74/173] Slices processed 8386.\n",
      "-> [75/173] Slices processed 8495.\n",
      "-> [76/173] Slices processed 8610.\n",
      "-> [77/173] Slices processed 8729.\n",
      "-> [78/173] Slices processed 8841.\n",
      "-> [79/173] Slices processed 8951.\n",
      "-> [80/173] Slices processed 9056.\n",
      "-> [81/173] Slices processed 9169.\n",
      "-> [82/173] Slices processed 9272.\n",
      "-> [83/173] Slices processed 9380.\n",
      "-> [84/173] Slices processed 9494.\n",
      "-> [85/173] Slices processed 9610.\n",
      "-> [86/173] Slices processed 9729.\n",
      "-> [87/173] Slices processed 9846.\n",
      "-> [88/173] Slices processed 9959.\n",
      "-> [89/173] Slices processed 10078.\n",
      "-> [90/173] Slices processed 10194.\n",
      "-> [91/173] Slices processed 10323.\n",
      "-> [92/173] Slices processed 10436.\n",
      "-> [93/173] Slices processed 10549.\n",
      "-> [94/173] Slices processed 10669.\n",
      "-> [95/173] Slices processed 10785.\n",
      "-> [96/173] Slices processed 10898.\n"
     ]
    }
   ],
   "source": [
    "X_sagital_train, y_sagital_train = get_slices_per_group_sagital(X_train, y_train)\n",
    "X_sagital_train = X_sagital_train.reshape(-1, X_sagital_train.shape[1], X_sagital_train.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: X:(%d, %d, %d, %d), y: %d\" %(X_sagital_train.shape[0],X_sagital_train.shape[1],X_sagital_train.shape[2],X_sagital_train.shape[3], len(y_sagital_train)))\n",
    "print(\"Test: X:(%d, %d, %d, %d), y: %d\" %(X_sagital_test.shape[0],X_sagital_test.shape[1],X_sagital_test.shape[2],X_sagital_test.shape[3], len(y_sagital_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl1Z4kUYHNuR"
   },
   "source": [
    "#EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "FuHg_UWaoSrD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 217, 181) 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import cv2\n",
    "img = sitk.ReadImage(PD_file_paths[1], sitk.sitkFloat64)\n",
    "arr = sitk.GetArrayFromImage(img)\n",
    "print(arr.shape, arr.min())\n",
    "\n",
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(arr[38, : , :], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6oFQ-zSoGTni"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 217, 181) 0.0\n",
      "(224, 224) 0.0\n"
     ]
    }
   ],
   "source": [
    "arr_reshaped = cv2.resize(arr[:, : , 100], (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "arr_reshaped[arr_reshaped < 0] = 0\n",
    "print(arr_reshaped.shape, arr_reshaped.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8Rf70BKGtaSF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224) 0.0\n"
     ]
    }
   ],
   "source": [
    "arr_reshaped[arr_reshaped < 0] = 0\n",
    "print(arr_reshaped.shape, arr_reshaped.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "r5QBdyYNHOVD"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(num=\"MRI_demo\")\n",
    "ax.imshow(arr_reshaped, cmap=\"gray\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUY_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/BUY/*/ex_*.nii.gz\"))  #68 files\n",
    "EAT_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/EAT/*/ex_*.nii.gz\")) #81files\n",
    "GAMBLE_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/GAMBLE/*/ex_*.nii.gz\"))  #7 files\n",
    "SEX_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/SEX/*/ex_*.nii.gz\"))  #42 files\n",
    "\n",
    "PD_file_paths =  sorted(glob(\"E:/ESPOL/integradora/images_preprocessed/PD/*/ex_*.nii.gz\"))  #100 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "81 ['E:/ESPOL/integradora/images_preprocessed/EAT\\\\3002\\\\ex_3002.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/EAT\\\\3023\\\\ex_3023.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/EAT\\\\3062\\\\ex_3062.nii.gz']\n",
      "7 ['E:/ESPOL/integradora/images_preprocessed/GAMBLE\\\\3536\\\\ex_3536.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/GAMBLE\\\\3565\\\\ex_3565.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/GAMBLE\\\\3863\\\\ex_3863.nii.gz']\n",
      "22 ['E:/ESPOL/integradora/images_preprocessed/SEX\\\\3062\\\\ex_3062.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/SEX\\\\3068\\\\ex_3068.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/SEX\\\\3073\\\\ex_3073.nii.gz']\n",
      "116 ['E:/ESPOL/integradora/images_preprocessed/PD\\\\3006\\\\ex_3006.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/PD\\\\3012\\\\ex_3012.nii.gz', 'E:/ESPOL/integradora/images_preprocessed/PD\\\\3014\\\\ex_3014.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(len(BUY_file_paths), BUY_file_paths[:3])\n",
    "print(len(EAT_file_paths), EAT_file_paths[:3])\n",
    "print(len(GAMBLE_file_paths), GAMBLE_file_paths[:3])\n",
    "print(len(SEX_file_paths), SEX_file_paths[:3])\n",
    "\n",
    "print(len(PD_file_paths), PD_file_paths[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "destiny = \"E:/ESPOL/integradora/desorders/PREPROCESSED/\" + \"BUY/\"\n",
    "\n",
    "for file in BUY_file_paths:\n",
    "    id = file.split(\"\\\\\")[1]\n",
    "    shutil.copyfile(file, destiny + id + \".nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PvAOESUMZ3vC"
   ],
   "name": "Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
